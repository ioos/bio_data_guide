% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Darwin Core Marine Example Compendium},
  pdfauthor={By: Standardizing Marine Biological Data Working Group},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Darwin Core Marine Example Compendium}
\author{By: \href{https://github.com/ioos/bio_data_guide/graphs/contributors}{Standardizing Marine Biological Data Working Group}}
\date{Updated: 2024-09-04}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

This book contains a collection of examples and resources related to mobilizing marine biological data to the
\href{https://dwc.tdwg.org/}{Darwin Core standard} for sharing though \href{https://obis.org/}{OBIS}. This book has been developed
by the Standardizing Marine Biological Data Working Group (SMBD). The working group is an open community of practitioners,
experts, and scientists looking to learn and educate the community on standardizing and sharing marine biological data.

If you would like to join the SMBD or learn more, checkout this \href{https://github.com/ioos/bio_data_guide/blob/main/README.md}{README}.

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

The world of standardizing marine biological data can seem complex for the naive oceanographer, biologist, scientist, or
programmer. This book intends to ease the burden of learning about the \href{https://dwc.tdwg.org/}{Darwin Core standard} by
compiling a list of example applications and tools for translating source data into Darwin Core. This collection of
resources does not replace the Darwin Core standards documentation (\url{https://dwc.tdwg.org/}) or the OBIS Manual (\url{https://manual.obis.org/}),
but instead it supplements those resources with examples of real world applications.

In this book we cover:

\begin{itemize}
\tightlist
\item
  \href{https://ioos.github.io/bio_data_guide/applications.html}{Applications} - These are the real world examples of aligning data to Darwin Core.
\item
  \href{https://ioos.github.io/bio_data_guide/frequently-asked-questions.html}{Frequently Asked Questions} - A collection of Frequently Asked Questions.
\item
  \href{https://ioos.github.io/bio_data_guide/tools.html}{Tools} - A collection of useful tools, packages, and programs for working with marine biological data.
\item
  \href{https://ioos.github.io/bio_data_guide/extras.html}{Extras} - Some useful extra tidbits about metadata and using GitHub to debug data issues.
\end{itemize}

If you would like to learn more about standardizing biological data (not only marine), the
\href{https://wiki.esipfed.org/Biological_Data_Standards_Cluster}{Earth Science Information Partners (ESIP) Biological Data Standards Cluster} developed
\href{https://doi.org/10.6084/m9.figshare.16806712.v1}{this primer} for managers of biological data to provide a quick, easy
resource for navigating a selection of the standards that exist. The goal of the primer is to spread awareness about
existing standards and is intended to be shared online and at conferences to increase the adoption of standards for
biological data and make them \href{https://www.go-fair.org/fair-principles/}{FAIR}.

\hypertarget{applications}{%
\chapter{Applications}\label{applications}}

This chapter contains a series of example applications to convert source data to the Darwin Core standard. You can find
these examples (and more!) in the GitHub repository under the \href{https://github.com/ioos/bio_data_guide/tree/main/datasets}{\texttt{datasets/}}
directory.

\hypertarget{aligning-data-to-darwin-core---event-core-with-extended-measurement-or-fact}{%
\section{Aligning Data to Darwin Core - Event Core with Extended Measurement or Fact}\label{aligning-data-to-darwin-core---event-core-with-extended-measurement-or-fact}}

Abby Benson\\
January 9, 2022

\hypertarget{general-information-about-this-notebook}{%
\subsection{General information about this notebook}\label{general-information-about-this-notebook}}

Script to process the Texas Parks and Wildlife Department (TPWD) Aransas Bay bag seine data from
the format used by the Houston Advanced Research Center (HARC) for bays in Texas. Taxonomy was processed using a separate script (\href{https://www.sciencebase.gov/catalog/file/get/53a887f4e4b075096c60cfdd?f=__disk__ab\%2F6e\%2Ff8\%2Fab6ef8426ea328cb6c54d13ee7b6b7ce791d23f8}{TPWD\_Taxonomy.R}) using a taxa list pulled from the pdf ``\href{https://www.sciencebase.gov/catalog/file/get/53a887f4e4b075096c60cfdd?f=__disk__d9\%2Ff6\%2F46\%2Fd9f646b40cf7c6cc3fa77d1e7aebe88f46cf7145}{2009 Resource Monitoring Operations Manual}''. All original data, processed data and scripts are stored on \href{https://www.sciencebase.gov/catalog/item/53a887f4e4b075096c60cfdd}{an item} in USGS ScienceBase.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load some of the libraries}
\FunctionTok{library}\NormalTok{(reshape2)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(readr)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the data}
\NormalTok{BagSeine }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"https://www.sciencebase.gov/catalog/file/get/53a887f4e4b075096c60cfdd?f=\_\_disk\_\_6e\%2F6a\%2F67\%2F6e6a678c41cf928e025fd30339789cc8b893a815\&allowOpen=true"}\NormalTok{, }\AttributeTok{stringsAsFactors=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{strip.white =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that if not already done you'll need to run the \href{https://www.sciencebase.gov/catalog/file/get/53a887f4e4b075096c60cfdd?f=__disk__ab\%2F6e\%2Ff8\%2Fab6ef8426ea328cb6c54d13ee7b6b7ce791d23f8}{TPWD\_Taxonomy.R} script to get the taxaList file squared away or load the taxonomy file to the World Register of Marine Species Taxon Match Tool \url{https://www.marinespecies.org/aphia.php?p=match}

\hypertarget{event-file}{%
\subsection{Event file}\label{event-file}}

To start we will create the Darwin Core \textbf{Event} file. This is the file that will have all the information about the sampling event such as date, location, depth, sampling protocol. Basically anything about the cruise or the way the sampling was done will go in this file. You can see all the Darwin Core terms that are part of the event file here \url{http://tools.gbif.org/dwca-validator/extension.do?id=dwc:Event}.

The original format for these TPWD HARC files has all of the information associated as the event in the first approximately 50 columns and then all of the information about the occurrence (species) as columns for each species. We will need to start by limiting to the event information only.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{event }\OtherTok{\textless{}{-}}\NormalTok{ BagSeine[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{47}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Next there are several pieces of information that need
1) to be added like the geodeticDatum
2) to be pieced together from multiple columns like datasetID or
3) minor changes like the minimum and maximum depth.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{event }\OtherTok{\textless{}{-}}\NormalTok{ event }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"Event"}\NormalTok{,}
         \AttributeTok{modified =}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{today}\NormalTok{(),}
         \AttributeTok{language =} \StringTok{"en"}\NormalTok{,}
         \AttributeTok{license =} \StringTok{"http://creativecommons.org/publicdomain/zero/1.0/legalcode"}\NormalTok{,}
         \AttributeTok{institutionCode =} \StringTok{"TPWD"}\NormalTok{,}
         \AttributeTok{ownerInstitutionCode =} \StringTok{"HARC"}\NormalTok{,}
         \AttributeTok{coordinateUncertaintyInMeters =} \StringTok{"100"}\NormalTok{,}
         \AttributeTok{geodeticDatum =} \StringTok{"WGS84"}\NormalTok{,}
         \AttributeTok{georeferenceProtocol =} \StringTok{"Handheld GPS"}\NormalTok{,}
         \AttributeTok{country =} \StringTok{"United States"}\NormalTok{,}
         \AttributeTok{countryCode =} \StringTok{"US"}\NormalTok{,}
         \AttributeTok{stateProvince =} \StringTok{"Texas"}\NormalTok{,}
         \AttributeTok{datasetID =} \FunctionTok{gsub}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"TPWD\_HARC\_Texas"}\NormalTok{, event}\SpecialCharTok{$}\NormalTok{Bay, event}\SpecialCharTok{$}\NormalTok{Gear\_Type)),}
         \AttributeTok{eventID =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Station"}\NormalTok{, event}\SpecialCharTok{$}\NormalTok{station\_code, }\StringTok{"Date"}\NormalTok{, event}\SpecialCharTok{$}\NormalTok{completion\_dttm, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{),}
         \AttributeTok{sampleSizeUnit =} \StringTok{"hectares"}\NormalTok{,}
         \AttributeTok{CompDate =}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{mdy\_hms}\NormalTok{(event}\SpecialCharTok{$}\NormalTok{CompDate, }\AttributeTok{tz=}\StringTok{"America/Chicago"}\NormalTok{), }
         \AttributeTok{StartDate =}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{mdy\_hms}\NormalTok{(event}\SpecialCharTok{$}\NormalTok{StartDate, }\AttributeTok{tz=}\StringTok{"America/Chicago"}\NormalTok{),}
         \AttributeTok{minimumDepthInMeters =} \FunctionTok{ifelse}\NormalTok{(start\_shallow\_water\_depth\_num }\SpecialCharTok{\textless{}}\NormalTok{ start\_deep\_water\_depth\_num, }
\NormalTok{                                       start\_shallow\_water\_depth\_num, start\_deep\_water\_depth\_num),}
         \AttributeTok{maximumDepthInMeters =} \FunctionTok{ifelse}\NormalTok{(start\_deep\_water\_depth\_num }\SpecialCharTok{\textgreater{}}\NormalTok{ start\_shallow\_water\_depth\_num,}
\NormalTok{                                       start\_deep\_water\_depth\_num, start\_shallow\_water\_depth\_num))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(event[,}\DecValTok{48}\SpecialCharTok{:}\DecValTok{64}\NormalTok{], }\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\NormalTok{    type   modified language                                                    license institutionCode}
\DecValTok{1}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{2}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{3}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{4}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{5}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{6}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{7}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{8}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{9}\NormalTok{  Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\DecValTok{10}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD}
\NormalTok{   ownerInstitutionCode coordinateUncertaintyInMeters geodeticDatum georeferenceProtocol       country}
\DecValTok{1}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{2}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{3}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{4}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{5}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{6}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{7}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{8}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{9}\NormalTok{                  HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\DecValTok{10}\NormalTok{                 HARC                           }\DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States}
\NormalTok{   countryCode stateProvince                             datasetID                                eventID}
\DecValTok{1}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_95\_Date\_09JAN1997}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{2}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_95\_Date\_18AUG2000}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{3}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_28JUN2005}\SpecialCharTok{:}\DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{4}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_23AUG2006}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{5}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_17OCT2006}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{6}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_19FEB1996}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{7}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_11JUN2001}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{12}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{8}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_16MAR1992}\SpecialCharTok{:}\DecValTok{09}\SpecialCharTok{:}\DecValTok{46}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{9}\NormalTok{           US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_25SEP1996}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{28}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{10}\NormalTok{          US         Texas TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_08MAY1997}\SpecialCharTok{:}\DecValTok{13}\SpecialCharTok{:}\DecValTok{20}\SpecialCharTok{:}\FloatTok{00.000}
\NormalTok{   sampleSizeUnit minimumDepthInMeters maximumDepthInMeters}
\DecValTok{1}\NormalTok{        hectares                  }\FloatTok{0.0}                  \FloatTok{0.6}
\DecValTok{2}\NormalTok{        hectares                  }\FloatTok{0.1}                  \FloatTok{0.5}
\DecValTok{3}\NormalTok{        hectares                  }\FloatTok{0.4}                  \FloatTok{0.6}
\DecValTok{4}\NormalTok{        hectares                  }\FloatTok{0.2}                  \FloatTok{0.4}
\DecValTok{5}\NormalTok{        hectares                  }\FloatTok{0.7}                  \FloatTok{0.8}
\DecValTok{6}\NormalTok{        hectares                  }\FloatTok{0.1}                  \FloatTok{0.3}
\DecValTok{7}\NormalTok{        hectares                  }\FloatTok{0.4}                  \FloatTok{0.5}
\DecValTok{8}\NormalTok{        hectares                  }\FloatTok{0.0}                  \FloatTok{0.4}
\DecValTok{9}\NormalTok{        hectares                  }\FloatTok{0.3}                  \FloatTok{0.7}
\DecValTok{10}\NormalTok{       hectares                  }\FloatTok{0.4}                  \FloatTok{0.6}
\end{Highlighting}
\end{Shaded}

For this dataset there was a start timestamp and end timestamp that we can use to identify the sampling effort which can be really valuable information for downstream users when trying to reuse data from multiple projects.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Calculate duration of bag seine event}
\NormalTok{event}\SpecialCharTok{$}\NormalTok{samplingEffort }\OtherTok{\textless{}{-}} \StringTok{""}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(event))\{}
\NormalTok{  event[i,]}\SpecialCharTok{$}\NormalTok{samplingEffort }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(lubridate}\SpecialCharTok{::}\FunctionTok{as.duration}\NormalTok{(event[i,]}\SpecialCharTok{$}\NormalTok{CompDate }\SpecialCharTok{{-}}\NormalTok{ event[i,]}\SpecialCharTok{$}\NormalTok{StartDate))}
\NormalTok{\}}
\NormalTok{event}\SpecialCharTok{$}\NormalTok{samplingEffort }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(event}\SpecialCharTok{$}\NormalTok{samplingEffort, }\StringTok{"seconds"}\NormalTok{, }\AttributeTok{sep =} \StringTok{" "}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finally there were a few columns that were a direct match to a Darwin Core term and therefore just need to be renamed to follow the standard.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{event }\OtherTok{\textless{}{-}}\NormalTok{ event }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{samplingProtocol =}\NormalTok{ Gear\_Type,}
         \AttributeTok{locality =}\NormalTok{ Estuary,}
         \AttributeTok{waterBody =}\NormalTok{ SubBay,}
         \AttributeTok{decimalLatitude =}\NormalTok{ Latitude,}
         \AttributeTok{decimalLongitude =}\NormalTok{ Longitude,}
         \AttributeTok{sampleSizeValue =}\NormalTok{ surface\_area\_num,}
         \AttributeTok{eventDate =}\NormalTok{ CompDate)}
\end{Highlighting}
\end{Shaded}

\hypertarget{occurrence-file}{%
\subsection{Occurrence file}\label{occurrence-file}}

The next file we need to create is the \textbf{Occurrence} file. This file includes all the information about the species that were observed. An occurrence in Darwin Core is the intersection of an organism at a time and a place. We have already done the work to identify the time and place in the event file so we don't need to do that again here. What we do need to is identify all the information about the organisms. Another piece of information that goes in here is basisOfRecord which is a required field and has a controlled vocabulary. For the data we work with you'll usually put \texttt{HumanObservation} or \texttt{MachineObservation}. If it's eDNA data you'll use \texttt{MaterialSample}. If your data are part of a museum collection you'll use \texttt{PreservedSpecimen}.

Important to note that there is overlap in the Darwin Core terms that ``allowed'' to be in the event file and in the occurrence file. This is because data can be submitted as ``Occurrence Only'' where you don't have a separate event file. In that case, the location and date information will need to be included in the occurrence file. Since we are formatting this dataset as a sampling event we will not include location and date information in the occurrence file. To see all the Darwin Core terms that can go in the occurrence file go here \url{https://tools.gbif.org/dwca-validator/extension.do?id=dwc:occurrence}.

This dataset in its original format is in ``wide format''. All that means is that data that we would expect to be encoded as values in the rows are instead column headers. We have to pull all the scientific names out of the column headers and turn them into actual values in the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrence }\OtherTok{\textless{}{-}} \FunctionTok{melt}\NormalTok{(BagSeine, }\AttributeTok{id=}\DecValTok{1}\SpecialCharTok{:}\DecValTok{47}\NormalTok{, }\AttributeTok{measure=}\DecValTok{48}\SpecialCharTok{:}\DecValTok{109}\NormalTok{, }\AttributeTok{variable.name=}\StringTok{"vernacularName"}\NormalTok{, }\AttributeTok{value.name=}\StringTok{"relativeAbundance"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You'll notice when we did that step we went from 5481 obs (or rows) in the data to 334341 obs. We went from wide to long.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(BagSeine)}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{5481}  \DecValTok{109}
\FunctionTok{dim}\NormalTok{(occurrence)}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{334341}     \DecValTok{49}
\end{Highlighting}
\end{Shaded}

Now as with the event file we have several pieces of information that need to be added or changed to make sure the data are following Darwin Core. We always want to include as much information as possible to make the data as reusable as possible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrence }\OtherTok{\textless{}{-}}\NormalTok{ occurrence }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{vernacularName =} \FunctionTok{gsub}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{."}\NormalTok{,}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{, vernacularName),}
         \AttributeTok{eventID =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Station"}\NormalTok{, station\_code, }\StringTok{"Date"}\NormalTok{, completion\_dttm, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{),}
         \AttributeTok{occurrenceStatus =} \FunctionTok{ifelse}\NormalTok{(relativeAbundance }\SpecialCharTok{==} \DecValTok{0}\NormalTok{, }\StringTok{"Absent"}\NormalTok{, }\StringTok{"Present"}\NormalTok{),}
         \AttributeTok{basisOfRecord =} \StringTok{"HumanObservation"}\NormalTok{,}
         \AttributeTok{organismQuantityType =} \StringTok{"Relative Abundance"}\NormalTok{,}
         \AttributeTok{collectionCode =} \FunctionTok{paste}\NormalTok{(Bay, Gear\_Type, }\AttributeTok{sep =} \StringTok{" "}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We will match the taxa list with our occurrence file data to bring in the taxonomic information that we pulled from WoRMS. To save time you'll just import the processed taxa list which includes the taxonomic hierarchy and the required term scientificNameID which is one of the most important pieces of information to include for OBIS.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{taxaList }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"https://www.sciencebase.gov/catalog/file/get/53a887f4e4b075096c60cfdd?f=\_\_disk\_\_49\%2F0a\%2F73\%2F490a7337fa94039715809496b22f5d003b8a79a2\&allowOpen=true"}\NormalTok{, }\AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}\NormalTok{)}
\DocumentationTok{\#\# Merge taxaList with occurrence}
\NormalTok{occurrence }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(occurrence, taxaList, }\AttributeTok{by =} \StringTok{"vernacularName"}\NormalTok{, }\AttributeTok{all.x =}\NormalTok{ T)}
\DocumentationTok{\#\# Test that all the vernacularNames found a match in taxaList\_updated}
\NormalTok{Hmisc}\SpecialCharTok{::}\FunctionTok{describe}\NormalTok{(occurrence}\SpecialCharTok{$}\NormalTok{scientificNameID)}
\NormalTok{       n  missing distinct }
  \DecValTok{334341}        \DecValTok{0}       \DecValTok{61} 

\NormalTok{lowest }\SpecialCharTok{:}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{105792}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{107034}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{107379}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{126983}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{127089}
\NormalTok{highest}\SpecialCharTok{:}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{367528}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{396707}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{421784}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{422069}\NormalTok{ urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{443955}
\end{Highlighting}
\end{Shaded}

For that last line of code we are expecting to see no missing values for scientificNameID. Every row in the file should have a value in scientificNameID which should be a WoRMS LSID that look like this \texttt{urn:lsid:marinespecies.org:taxname:144531}

We need to create a unique ID for each row in the occurrence file. This is known as the \texttt{occurrenceID} and is a required term. The \texttt{occurrenceID} needs to be globally unique and needs to be permanent and kept in place if any updates to the dataset are made. You should not create brand new occurrenceIDs when you update a dataset. To facilitate this I like to build the \texttt{occurrenceID} from pieces of information available in the dataset to create a unique ID for each row in the occurrence file. For this dataset I used the \texttt{eventID} (Station + Date) plus the scientific name. This only works if there is only one scientific name per station per date so if you have different ages or sexes of species at the same station and date this method of creating the occurrenceID won't work for you.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrence}\SpecialCharTok{$}\NormalTok{occurrenceID }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(occurrence}\SpecialCharTok{$}\NormalTok{eventID, }\FunctionTok{gsub}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{,occurrence}\SpecialCharTok{$}\NormalTok{scientificName), }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
\NormalTok{occurrence[}\DecValTok{1}\NormalTok{,]}\SpecialCharTok{$}\NormalTok{occurrenceID}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\StringTok{"Station\_95\_Date\_09JAN1997:14:35:00.000\_Atractosteus\_spatula"}
\end{Highlighting}
\end{Shaded}

For the occurrence file we only have one column to rename. We could have avoided this step if we had named it \texttt{organismQuantity} up above but I kept this to remind me what the data providers had called this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrence }\OtherTok{\textless{}{-}}\NormalTok{ occurrence }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{organismQuantity =}\NormalTok{ relativeAbundance)}
\end{Highlighting}
\end{Shaded}

\hypertarget{extended-measurement-or-fact-extension-file}{%
\subsection{Extended Measurement or Fact extension file}\label{extended-measurement-or-fact-extension-file}}

The final file we are going to create is the \textbf{Extended Measurement or Fact extension (emof)}. This is a bit like a catch all for any measurements or facts that are not captured in Darwin Core. Darwin Core does not have terms for things like temperature, salinity, gear type, cruise number, length, weight, etc. We are going to create a long format file where each of these is a set of rows in the extended measurement or fact file. You can find all the terms in this extension here \url{https://tools.gbif.org/dwca-validator/extension.do?id=http://rs.iobis.org/obis/terms/ExtendedMeasurementOrFact}.

OBIS uses the BODC NERC Vocabulary Server to provide explicit definitions for each of the measurements \url{https://vocab.nerc.ac.uk/search_nvs/}.

For this dataset I was only able to find code definitions provided by the data providers for some of the measurements. I included the ones that I was able to find code definitions and left out any that I couldn't find those for. The ones I was able to find code definitions for were \texttt{Total.Of.Samples\_Count}, \texttt{gear\_size}, \texttt{start\_wind\_speed\_num}, \texttt{start\_barometric\_pressure\_num}, \texttt{start\_temperature\_num}, \texttt{start\_salinity\_num}, \texttt{start\_dissolved\_oxygen\_num}. All the others I left out.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{totalOfSamples }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"Total.Of.Samples\_Count"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{totalOfSamples }\OtherTok{\textless{}{-}}\NormalTok{ totalOfSamples[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(totalOfSamples}\SpecialCharTok{$}\NormalTok{Total.Of.Samples\_Count)),]}
\NormalTok{totalOfSamples }\OtherTok{\textless{}{-}}\NormalTok{ totalOfSamples }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"Total number of samples used to calculate relative abundance"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{""}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ Total.Of.Samples\_Count)}

\NormalTok{gear\_size }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"gear\_size"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{gear\_size }\OtherTok{\textless{}{-}}\NormalTok{ gear\_size[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gear\_size}\SpecialCharTok{$}\NormalTok{gear\_size)),]}
\NormalTok{gear\_size }\OtherTok{\textless{}{-}}\NormalTok{ gear\_size }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"gear size"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"meters"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/MTHAREA1/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/ULAA/"}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ gear\_size)}

\NormalTok{start\_wind\_speed\_num }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"start\_wind\_speed\_num"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{start\_wind\_speed\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_wind\_speed\_num[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(start\_wind\_speed\_num}\SpecialCharTok{$}\NormalTok{start\_wind\_speed\_num)),]}
\NormalTok{start\_wind\_speed\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_wind\_speed\_num }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"wind speed"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"not provided"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/EWSBZZ01/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ start\_wind\_speed\_num)}

\NormalTok{start\_barometric\_pressure\_num }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"start\_barometric\_pressure\_num"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{start\_barometric\_pressure\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_barometric\_pressure\_num[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(start\_barometric\_pressure\_num}\SpecialCharTok{$}\NormalTok{start\_barometric\_pressure\_num)),]}
\NormalTok{start\_barometric\_pressure\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_barometric\_pressure\_num }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"barometric pressure"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"not provided"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P07/current/CFSN0015/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ start\_barometric\_pressure\_num)}

\NormalTok{start\_temperature\_num }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"start\_temperature\_num"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{start\_temperature\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_temperature\_num[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(start\_temperature\_num}\SpecialCharTok{$}\NormalTok{start\_temperature\_num)),]}
\NormalTok{start\_temperature\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_temperature\_num }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"water temperature"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"Celsius"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/TEMPPR01/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UPAA/"}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ start\_temperature\_num)}

\NormalTok{start\_salinity\_num }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"start\_salinity\_num"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{start\_salinity\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_salinity\_num[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(start\_salinity\_num}\SpecialCharTok{$}\NormalTok{start\_salinity\_num)),]}
\NormalTok{start\_salinity\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_salinity\_num }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"salinity"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"ppt"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/ODSDM021/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UPPT/"}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ start\_salinity\_num)}

\NormalTok{start\_dissolved\_oxygen\_num }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"start\_dissolved\_oxygen\_num"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{start\_dissolved\_oxygen\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_dissolved\_oxygen\_num[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(start\_dissolved\_oxygen\_num}\SpecialCharTok{$}\NormalTok{start\_dissolved\_oxygen\_num)),]}
\NormalTok{start\_dissolved\_oxygen\_num }\OtherTok{\textless{}{-}}\NormalTok{ start\_dissolved\_oxygen\_num }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"dissolved oxygen"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{"ppm"}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P09/current/DOX2/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UPPM/"}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ start\_dissolved\_oxygen\_num)}

\NormalTok{alternate\_station\_code }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"alternate\_station\_code"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{)]}
\NormalTok{alternate\_station\_code }\OtherTok{\textless{}{-}}\NormalTok{ alternate\_station\_code[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(alternate\_station\_code}\SpecialCharTok{$}\NormalTok{alternate\_station\_code)),]}
\NormalTok{alternate\_station\_code }\OtherTok{\textless{}{-}}\NormalTok{ alternate\_station\_code }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"alternate station code"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{""}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{""}\NormalTok{,}
         \AttributeTok{occurrenceID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ alternate\_station\_code)}

\NormalTok{organismQuantity }\OtherTok{\textless{}{-}}\NormalTok{ occurrence[}\FunctionTok{c}\NormalTok{(}\StringTok{"organismQuantity"}\NormalTok{, }\StringTok{"eventID"}\NormalTok{, }\StringTok{"occurrenceID"}\NormalTok{)]}
\NormalTok{organismQuantity }\OtherTok{\textless{}{-}}\NormalTok{ organismQuantity[}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(organismQuantity}\SpecialCharTok{$}\NormalTok{organismQuantity)),]}
\NormalTok{organismQuantity }\OtherTok{\textless{}{-}}\NormalTok{ organismQuantity }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"relative abundance"}\NormalTok{,}
         \AttributeTok{measurementUnit =} \StringTok{""}\NormalTok{,}
         \AttributeTok{measurementTypeID =} \StringTok{"http://vocab.nerc.ac.uk/collection/S06/current/S0600020/"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementValue =}\NormalTok{ organismQuantity)}

\CommentTok{\# Bind the separate measurements together into one file  }
\NormalTok{mof }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(totalOfSamples, start\_barometric\_pressure\_num, start\_dissolved\_oxygen\_num, }
\NormalTok{             start\_salinity\_num, start\_temperature\_num, start\_wind\_speed\_num, gear\_size,}
\NormalTok{             alternate\_station\_code, organismQuantity)}
\FunctionTok{head}\NormalTok{(mof)}
\NormalTok{ measurementValue                                eventID}
\DecValTok{1}               \DecValTok{18}\NormalTok{ Station\_95\_Date\_09JAN1997}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{2}              \DecValTok{103}\NormalTok{ Station\_95\_Date\_18AUG2000}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{3}              \DecValTok{401}\NormalTok{ Station\_96\_Date\_28JUN2005}\SpecialCharTok{:}\DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{4}               \DecValTok{35}\NormalTok{ Station\_96\_Date\_23AUG2006}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{5}               \DecValTok{57}\NormalTok{ Station\_96\_Date\_17OCT2006}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\FloatTok{00.000}
\DecValTok{6}                \DecValTok{5}\NormalTok{ Station\_96\_Date\_19FEB1996}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\FloatTok{00.000}
\NormalTok{                                               measurementType measurementUnit measurementTypeID}
\DecValTok{1}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\DecValTok{2}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\DecValTok{3}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\DecValTok{4}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\DecValTok{5}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\DecValTok{6}\NormalTok{ Total number of samples used to calculate relative abundance                                  }
\NormalTok{  measurementUnitID occurrenceID}
\DecValTok{1}                               
\DecValTok{2}                               
\DecValTok{3}                               
\DecValTok{4}                               
\DecValTok{5}                               
\DecValTok{6}                               
\FunctionTok{tail}\NormalTok{(mof)}
\NormalTok{       measurementValue                                 eventID    measurementType measurementUnit}
\DecValTok{334336}        \FloatTok{0.0000000}\NormalTok{ Station\_217\_Date\_03APR2003}\SpecialCharTok{:}\DecValTok{13}\SpecialCharTok{:}\DecValTok{28}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\DecValTok{334337}        \FloatTok{0.0000000}\NormalTok{ Station\_217\_Date\_24FEB2006}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{12}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\DecValTok{334338}        \FloatTok{0.1428571}\NormalTok{ Station\_217\_Date\_23JUN2001}\SpecialCharTok{:}\DecValTok{12}\SpecialCharTok{:}\DecValTok{28}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\DecValTok{334339}        \FloatTok{0.0000000}\NormalTok{ Station\_212\_Date\_23MAY1990}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{43}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\DecValTok{334340}        \FloatTok{0.1224490}\NormalTok{ Station\_212\_Date\_24JUL1990}\SpecialCharTok{:}\DecValTok{09}\SpecialCharTok{:}\DecValTok{34}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\DecValTok{334341}        \FloatTok{0.0000000}\NormalTok{ Station\_212\_Date\_21MAR2001}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{52}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{ relative abundance                }
\NormalTok{                                              measurementTypeID measurementUnitID}
\DecValTok{334336}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\DecValTok{334337}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\DecValTok{334338}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\DecValTok{334339}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\DecValTok{334340}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\DecValTok{334341}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{vocab.nerc.ac.uk}\SpecialCharTok{/}\NormalTok{collection}\SpecialCharTok{/}\NormalTok{S06}\SpecialCharTok{/}\NormalTok{current}\SpecialCharTok{/}\NormalTok{S0600020}\SpecialCharTok{/}                  
\NormalTok{                                                        occurrenceID}
\DecValTok{334336}\NormalTok{ Station\_217\_Date\_03APR2003}\SpecialCharTok{:}\DecValTok{13}\SpecialCharTok{:}\DecValTok{28}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}
\DecValTok{334337}\NormalTok{ Station\_217\_Date\_24FEB2006}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{12}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}
\DecValTok{334338}\NormalTok{ Station\_217\_Date\_23JUN2001}\SpecialCharTok{:}\DecValTok{12}\SpecialCharTok{:}\DecValTok{28}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}
\DecValTok{334339}\NormalTok{ Station\_212\_Date\_23MAY1990}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{43}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}
\DecValTok{334340}\NormalTok{ Station\_212\_Date\_24JUL1990}\SpecialCharTok{:}\DecValTok{09}\SpecialCharTok{:}\DecValTok{34}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}
\DecValTok{334341}\NormalTok{ Station\_212\_Date\_21MAR2001}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{52}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Litopenaeus\_setiferus}

\CommentTok{\# Write out the file}
\FunctionTok{write.csv}\NormalTok{(mof, }\AttributeTok{file =}\NormalTok{ (}\FunctionTok{paste0}\NormalTok{(event[}\DecValTok{1}\NormalTok{,]}\SpecialCharTok{$}\NormalTok{datasetID, }\StringTok{"\_mof\_"}\NormalTok{, lubridate}\SpecialCharTok{::}\FunctionTok{today}\NormalTok{(),}\StringTok{".csv"}\NormalTok{)), }\AttributeTok{fileEncoding =} \StringTok{"UTF{-}8"}\NormalTok{, }\AttributeTok{row.names =}\NormalTok{ F, }\AttributeTok{na =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{cleaning-up-event-and-occurrence-files}{%
\subsection{Cleaning up Event and Occurrence files}\label{cleaning-up-event-and-occurrence-files}}

Now that we have all of our files created we can clean up the \textbf{Event} and \textbf{Occurrence} files to remove the columns that are not following Darwin Core. We had to leave the extra bits in before because we needed them to create the \textbf{emof} file above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{event }\OtherTok{\textless{}{-}}\NormalTok{ event[}\FunctionTok{c}\NormalTok{(}\StringTok{"samplingProtocol"}\NormalTok{,}\StringTok{"locality"}\NormalTok{,}\StringTok{"waterBody"}\NormalTok{,}\StringTok{"decimalLatitude"}\NormalTok{,}\StringTok{"decimalLongitude"}\NormalTok{,}
                 \StringTok{"eventDate"}\NormalTok{,}\StringTok{"sampleSizeValue"}\NormalTok{,}\StringTok{"minimumDepthInMeters"}\NormalTok{,}
                 \StringTok{"maximumDepthInMeters"}\NormalTok{,}\StringTok{"type"}\NormalTok{,}\StringTok{"modified"}\NormalTok{,}\StringTok{"language"}\NormalTok{,}\StringTok{"license"}\NormalTok{,}\StringTok{"institutionCode"}\NormalTok{,}
                 \StringTok{"ownerInstitutionCode"}\NormalTok{,}\StringTok{"coordinateUncertaintyInMeters"}\NormalTok{,}
                 \StringTok{"geodeticDatum"}\NormalTok{, }\StringTok{"georeferenceProtocol"}\NormalTok{,}\StringTok{"country"}\NormalTok{,}\StringTok{"countryCode"}\NormalTok{,}\StringTok{"stateProvince"}\NormalTok{,}
                 \StringTok{"datasetID"}\NormalTok{,}\StringTok{"eventID"}\NormalTok{,}\StringTok{"sampleSizeUnit"}\NormalTok{,}\StringTok{"samplingEffort"}\NormalTok{)]}
\FunctionTok{head}\NormalTok{(event)}
\NormalTok{  samplingProtocol                locality   waterBody decimalLatitude decimalLongitude}
\DecValTok{1}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13472}        \SpecialCharTok{{-}}\FloatTok{97.00833}
\DecValTok{2}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13528}        \SpecialCharTok{{-}}\FloatTok{97.00722}
\DecValTok{3}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13444}        \SpecialCharTok{{-}}\FloatTok{96.99611}
\DecValTok{4}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13444}        \SpecialCharTok{{-}}\FloatTok{96.99611}
\DecValTok{5}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13444}        \SpecialCharTok{{-}}\FloatTok{96.99611}
\DecValTok{6}\NormalTok{        Bag Seine Mission}\SpecialCharTok{{-}}\NormalTok{Aransas Estuary Aransas Bay        }\FloatTok{28.13472}        \SpecialCharTok{{-}}\FloatTok{96.99583}
\NormalTok{            eventDate sampleSizeValue minimumDepthInMeters maximumDepthInMeters  type   modified language}
\DecValTok{1} \DecValTok{1997{-}01{-}09} \DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.0}                  \FloatTok{0.6}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\DecValTok{2} \DecValTok{2000{-}08{-}18} \DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.1}                  \FloatTok{0.5}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\DecValTok{3} \DecValTok{2005{-}06{-}28} \DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.4}                  \FloatTok{0.6}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\DecValTok{4} \DecValTok{2006{-}08{-}23} \DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.2}                  \FloatTok{0.4}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\DecValTok{5} \DecValTok{2006{-}10{-}17} \DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.7}                  \FloatTok{0.8}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\DecValTok{6} \DecValTok{1996{-}02{-}19} \DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\DecValTok{00}            \FloatTok{0.03}                  \FloatTok{0.1}                  \FloatTok{0.3}\NormalTok{ Event }\DecValTok{2022{-}01{-}09}\NormalTok{       en}
\NormalTok{                                                     license institutionCode ownerInstitutionCode}
\DecValTok{1}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\DecValTok{2}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\DecValTok{3}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\DecValTok{4}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\DecValTok{5}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\DecValTok{6}\NormalTok{ http}\SpecialCharTok{:}\ErrorTok{//}\NormalTok{creativecommons.org}\SpecialCharTok{/}\NormalTok{publicdomain}\SpecialCharTok{/}\NormalTok{zero}\SpecialCharTok{/}\FloatTok{1.0}\SpecialCharTok{/}\NormalTok{legalcode            TPWD                 HARC}
\NormalTok{  coordinateUncertaintyInMeters geodeticDatum georeferenceProtocol       country countryCode stateProvince}
\DecValTok{1}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\DecValTok{2}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\DecValTok{3}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\DecValTok{4}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\DecValTok{5}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\DecValTok{6}                           \DecValTok{100}\NormalTok{         WGS84         Handheld GPS United States          US         Texas}
\NormalTok{                              datasetID                                eventID sampleSizeUnit}
\DecValTok{1}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_95\_Date\_09JAN1997}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\DecValTok{2}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_95\_Date\_18AUG2000}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\DecValTok{3}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_28JUN2005}\SpecialCharTok{:}\DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\DecValTok{4}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_23AUG2006}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\DecValTok{5}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_17OCT2006}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\DecValTok{6}\NormalTok{ TPWD\_HARC\_Texas\_Aransas\_Bay\_Bag\_Seine Station\_96\_Date\_19FEB1996}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{       hectares}
\NormalTok{  samplingEffort}
\DecValTok{1}    \DecValTok{120}\NormalTok{ seconds}
\DecValTok{2}    \DecValTok{120}\NormalTok{ seconds}
\DecValTok{3}    \DecValTok{120}\NormalTok{ seconds}
\DecValTok{4}    \DecValTok{120}\NormalTok{ seconds}
\DecValTok{5}    \DecValTok{120}\NormalTok{ seconds}
\DecValTok{6}    \DecValTok{120}\NormalTok{ seconds}

\FunctionTok{write.csv}\NormalTok{(event, }\AttributeTok{file =} \FunctionTok{paste0}\NormalTok{(event[}\DecValTok{1}\NormalTok{,]}\SpecialCharTok{$}\NormalTok{datasetID, }\StringTok{"\_event\_"}\NormalTok{, lubridate}\SpecialCharTok{::}\FunctionTok{today}\NormalTok{(),}\StringTok{".csv"}\NormalTok{), }\AttributeTok{fileEncoding =} \StringTok{"UTF{-}8"}\NormalTok{, }\AttributeTok{row.names =}\NormalTok{ F, }\AttributeTok{na =} \StringTok{""}\NormalTok{)                    }

\NormalTok{occurrence }\OtherTok{\textless{}{-}}\NormalTok{ occurrence[}\FunctionTok{c}\NormalTok{(}\StringTok{"vernacularName"}\NormalTok{,}\StringTok{"eventID"}\NormalTok{,}\StringTok{"occurrenceStatus"}\NormalTok{,}\StringTok{"basisOfRecord"}\NormalTok{,}
                           \StringTok{"scientificName"}\NormalTok{,}\StringTok{"scientificNameID"}\NormalTok{,}\StringTok{"kingdom"}\NormalTok{,}\StringTok{"phylum"}\NormalTok{,}\StringTok{"class"}\NormalTok{,}
                           \StringTok{"order"}\NormalTok{,}\StringTok{"family"}\NormalTok{,}\StringTok{"genus"}\NormalTok{,}
                           \StringTok{"scientificNameAuthorship"}\NormalTok{,}\StringTok{"taxonRank"}\NormalTok{, }\StringTok{"organismQuantity"}\NormalTok{,}
                           \StringTok{"organismQuantityType"}\NormalTok{, }\StringTok{"occurrenceID"}\NormalTok{,}\StringTok{"collectionCode"}\NormalTok{)]}
\FunctionTok{head}\NormalTok{(occurrence)}
\NormalTok{  vernacularName                                eventID occurrenceStatus    basisOfRecord}
\DecValTok{1}\NormalTok{  Alligator gar Station\_95\_Date\_09JAN1997}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\DecValTok{2}\NormalTok{  Alligator gar Station\_95\_Date\_18AUG2000}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\DecValTok{3}\NormalTok{  Alligator gar Station\_96\_Date\_28JUN2005}\SpecialCharTok{:}\DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\DecValTok{4}\NormalTok{  Alligator gar Station\_96\_Date\_23AUG2006}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\DecValTok{5}\NormalTok{  Alligator gar Station\_96\_Date\_17OCT2006}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\DecValTok{6}\NormalTok{  Alligator gar Station\_96\_Date\_19FEB1996}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{           Absent HumanObservation}
\NormalTok{        scientificName                          scientificNameID  kingdom   phylum       class}
\DecValTok{1}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\DecValTok{2}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\DecValTok{3}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\DecValTok{4}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\DecValTok{5}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\DecValTok{6}\NormalTok{ Atractosteus spatula urn}\SpecialCharTok{:}\NormalTok{lsid}\SpecialCharTok{:}\NormalTok{marinespecies.org}\SpecialCharTok{:}\NormalTok{taxname}\SpecialCharTok{:}\DecValTok{279822}\NormalTok{ Animalia Chordata Actinopteri}
\NormalTok{             order        family        genus scientificNameAuthorship taxonRank organismQuantity}
\DecValTok{1}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\DecValTok{2}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\DecValTok{3}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\DecValTok{4}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\DecValTok{5}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\DecValTok{6}\NormalTok{ Lepisosteiformes Lepisosteidae }\FunctionTok{Atractosteus}\NormalTok{         (Lacepède, }\DecValTok{1803}\NormalTok{)   Species                }\DecValTok{0}
\NormalTok{  organismQuantityType                                                occurrenceID        collectionCode}
\DecValTok{1}\NormalTok{   Relative Abundance Station\_95\_Date\_09JAN1997}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{35}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
\DecValTok{2}\NormalTok{   Relative Abundance Station\_95\_Date\_18AUG2000}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{02}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
\DecValTok{3}\NormalTok{   Relative Abundance Station\_96\_Date\_28JUN2005}\SpecialCharTok{:}\DecValTok{08}\SpecialCharTok{:}\DecValTok{41}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
\DecValTok{4}\NormalTok{   Relative Abundance Station\_96\_Date\_23AUG2006}\SpecialCharTok{:}\DecValTok{11}\SpecialCharTok{:}\DecValTok{47}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
\DecValTok{5}\NormalTok{   Relative Abundance Station\_96\_Date\_17OCT2006}\SpecialCharTok{:}\DecValTok{14}\SpecialCharTok{:}\DecValTok{23}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
\DecValTok{6}\NormalTok{   Relative Abundance Station\_96\_Date\_19FEB1996}\SpecialCharTok{:}\DecValTok{10}\SpecialCharTok{:}\DecValTok{27}\SpecialCharTok{:}\FloatTok{00.000}\NormalTok{\_Atractosteus\_spatula Aransas Bay Bag Seine}
                           
\FunctionTok{write.csv}\NormalTok{(occurrence, }\AttributeTok{file =} \FunctionTok{paste0}\NormalTok{(event[}\DecValTok{1}\NormalTok{,]}\SpecialCharTok{$}\NormalTok{datasetID, }\StringTok{"\_occurrence\_"}\NormalTok{,lubridate}\SpecialCharTok{::}\FunctionTok{today}\NormalTok{(),}\StringTok{".csv"}\NormalTok{), }\AttributeTok{fileEncoding =} \StringTok{"UTF{-}8"}\NormalTok{, }\AttributeTok{row.names =}\NormalTok{ F, }\AttributeTok{na =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{salmon-ocean-ecology-data}{%
\section{Salmon Ocean Ecology Data}\label{salmon-ocean-ecology-data}}

\hypertarget{intro-1}{%
\subsection{Intro}\label{intro-1}}

One of the goals of the Hakai Institute and the Canadian Integrated Ocean Observing System (CIOOS) is to facilitate Open Science and FAIR (findable, accessible, interoperable, reusable) ecological and oceanographic data. In a concerted effort to adopt or establish how best to do that, several Hakai and CIOOS staff attended an International Ocean Observing System (IOOS) Code Sprint in Ann Arbour, Michigan between October 7--11, 2019, to discuss how to implement FAIR data principles for biological data collected in the marine environment.

The \href{https://dwc.tdwg.org}{Darwin Core} is a highly structured data format that standardizes data table relations, vocabularies, and defines field names. The Darwin Core defines three table types: \texttt{event}, \texttt{occurrence}, and \texttt{measurementOrFact}. This intuitively captures the way most ecologists conduct their research. Typically, a survey (event) is conducted and measurements, counts, or observations (collectively measurementOrFacts) are made regarding a specific habitat or species (occurrence).

In the following script I demonstrate how I go about converting a subset of the data collected from the Hakai Institute Juvenile Salmon Program and discuss challenges, solutions, pros and cons, and when and what's worthwhile to convert to Darwin Core.

The conversion of a dataset to Darwin Core is much easier if your data are already tidy (normalized) in which you represent your data in separate tables that reflect the hierarchical and related nature of your observations. If your data are not already in a consistent and structured format, the conversion would likely be very arduos and not intuitive.

\hypertarget{event}{%
\subsection{event}\label{event}}

The first step is to consider what you will define as an event in your data set. I defined the capture of fish using a purse seine net as the \texttt{event}. Therefore, each row in the \texttt{event} table is one deployment of a seine net and is assigned a unique \texttt{eventID}.

My process for conversion was to make a new table called \texttt{event} and map the standard Darwin Core column names to pre-existing columns that serve the same purpose in my original \texttt{seine\_data} table and populate the other required fields.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{event }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ survey\_seines}\SpecialCharTok{$}\NormalTok{seine\_id,}
                \AttributeTok{eventDate =} \FunctionTok{date}\NormalTok{(survey\_seines}\SpecialCharTok{$}\NormalTok{survey\_date),}
                \AttributeTok{decimalLatitude =}\NormalTok{ survey\_seines}\SpecialCharTok{$}\NormalTok{lat,}
                \AttributeTok{decimalLongitude =}\NormalTok{ survey\_seines}\SpecialCharTok{$}\NormalTok{long,}
                \AttributeTok{geodeticDatum =} \StringTok{"EPSG:4326 WGS84"}\NormalTok{,}
                \AttributeTok{minimumDepthInMeters =} \DecValTok{0}\NormalTok{,}
                \AttributeTok{maximumDepthInMeters =} \DecValTok{9}\NormalTok{, }\CommentTok{\# seine depth is 9 m}
                \AttributeTok{samplingProtocol =} \StringTok{"http://dx.doi.org/10.21966/1.566666"} \CommentTok{\# This is the DOI for the Hakai Salmon Data Package that contains the smnpling protocol, as well as the complete data package}
\NormalTok{               ) }

\FunctionTok{write\_csv}\NormalTok{(event, here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"datasets"}\NormalTok{, }\StringTok{"hakai\_salmon\_data"}\NormalTok{, }\StringTok{"event.csv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{occurrence}{%
\subsection{occurrence}\label{occurrence}}

Next you'll want to determine what constitutes an occurrence for your data set. Because each event caputers fish, I consider each fish to be an occurrence. Therefore, the unit of observation (each row) in the occurrence table is a fish. To link each occurence to an event you need to include the \texttt{eventID} column for every occurrence so that you know what seine (event) each fish (occurrence) came from. You must also provide a globally unique identifier for each occurrence. I already have a locally unique identifier for each fish in the original \texttt{fish\_data} table called \texttt{ufn}. To make it globally unique I pre-pend the organization and research program metadata to the \texttt{ufn} column.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#TODO: Include bycatch data as well}

\DocumentationTok{\#\# make table long first}
\NormalTok{seines\_total\_long }\OtherTok{\textless{}{-}}\NormalTok{ survey\_seines }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(seine\_id, so\_total, pi\_total, cu\_total, co\_total, he\_total, ck\_total) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{seine\_id, }\AttributeTok{names\_to =} \StringTok{"scientificName"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"n"}\NormalTok{)}

\NormalTok{seines\_total\_long}\SpecialCharTok{$}\NormalTok{scientificName }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(seines\_total\_long}\SpecialCharTok{$}\NormalTok{scientificName, }\AttributeTok{so\_total =} \StringTok{"Oncorhynchus nerka"}\NormalTok{, }\AttributeTok{pi\_total =} \StringTok{"Oncorhynchus gorbushca"}\NormalTok{, }\AttributeTok{cu\_total =} \StringTok{"Oncorhynchus keta"}\NormalTok{, }\AttributeTok{co\_total =} \StringTok{"Oncorhynchus kisutch"}\NormalTok{, }\AttributeTok{ck\_total =} \StringTok{"Oncorhynchus tshawytscha"}\NormalTok{, }\AttributeTok{he\_total =} \StringTok{"Clupea pallasii"}\NormalTok{) }

\NormalTok{seines\_taken\_long }\OtherTok{\textless{}{-}}\NormalTok{ survey\_seines }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(seine\_id, so\_taken, pi\_taken, cu\_taken, co\_taken, he\_taken, ck\_taken) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{seine\_id, }\AttributeTok{names\_to =} \StringTok{"scientificName"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"n\_taken"}\NormalTok{) }

\NormalTok{seines\_taken\_long}\SpecialCharTok{$}\NormalTok{scientificName }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(seines\_taken\_long}\SpecialCharTok{$}\NormalTok{scientificName, }\AttributeTok{so\_taken =} \StringTok{"Oncorhynchus nerka"}\NormalTok{, }\AttributeTok{pi\_taken =} \StringTok{"Oncorhynchus gorbushca"}\NormalTok{, }\AttributeTok{cu\_taken =} \StringTok{"Oncorhynchus keta"}\NormalTok{, }\AttributeTok{co\_taken =} \StringTok{"Oncorhynchus kisutch"}\NormalTok{, }\AttributeTok{ck\_taken =} \StringTok{"Oncorhynchus tshawytscha"}\NormalTok{, }\AttributeTok{he\_taken =} \StringTok{"Clupea pallasii"}\NormalTok{) }

\DocumentationTok{\#\# remove records that have already been assigned an ID  }
\NormalTok{seines\_long }\OtherTok{\textless{}{-}}  \FunctionTok{full\_join}\NormalTok{(seines\_total\_long, seines\_taken\_long, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"seine\_id"}\NormalTok{, }\StringTok{"scientificName"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{drop\_na}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{n\_not\_taken =}\NormalTok{ n }\SpecialCharTok{{-}}\NormalTok{ n\_taken) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\#so\_total includes the number taken so I subtract n\_taken to get n\_not\_taken}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n\_taken, }\SpecialCharTok{{-}}\NormalTok{n) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(n\_not\_taken }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}

\NormalTok{all\_fish\_caught }\OtherTok{\textless{}{-}}
\NormalTok{  seines\_long[}\FunctionTok{rep}\NormalTok{(}\FunctionTok{seq.int}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(seines\_long)), seines\_long}\SpecialCharTok{$}\NormalTok{n\_not\_taken), }\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n\_not\_taken) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prefix =} \StringTok{"hakai{-}jsp{-}"}\NormalTok{,}
         \AttributeTok{suffix =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(.),}
         \AttributeTok{occurrenceID =} \FunctionTok{paste0}\NormalTok{(prefix, suffix)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{prefix, }\SpecialCharTok{{-}}\NormalTok{suffix)}

\CommentTok{\#}

\CommentTok{\# Change species names to full Scientific names }
\NormalTok{latin }\OtherTok{\textless{}{-}} \FunctionTok{fct\_recode}\NormalTok{(fish\_data}\SpecialCharTok{$}\NormalTok{species, }\StringTok{"Oncorhynchus nerka"} \OtherTok{=} \StringTok{"SO"}\NormalTok{, }\StringTok{"Oncorhynchus gorbuscha"} \OtherTok{=} \StringTok{"PI"}\NormalTok{, }\StringTok{"Oncorhynchus keta"} \OtherTok{=} \StringTok{"CU"}\NormalTok{, }\StringTok{"Oncorhynchus kisutch"} \OtherTok{=} \StringTok{"CO"}\NormalTok{, }\StringTok{"Clupea pallasii"} \OtherTok{=} \StringTok{"HE"}\NormalTok{, }\StringTok{"Oncorhynchus tshawytscha"} \OtherTok{=} \StringTok{"CK"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.character}\NormalTok{()}

\NormalTok{fish\_retained\_data }\OtherTok{\textless{}{-}}\NormalTok{ fish\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{scientificName =}\NormalTok{ latin) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{species) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prefix =} \StringTok{"hakai{-}jsp{-}"}\NormalTok{,}
         \AttributeTok{occurrenceID =} \FunctionTok{paste0}\NormalTok{(prefix, ufn)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{semsp\_id, }\SpecialCharTok{{-}}\NormalTok{prefix, }\SpecialCharTok{{-}}\NormalTok{ufn, }\SpecialCharTok{{-}}\NormalTok{fork\_length\_field, }\SpecialCharTok{{-}}\NormalTok{fork\_length, }\SpecialCharTok{{-}}\NormalTok{weight, }\SpecialCharTok{{-}}\NormalTok{weight\_field)}

\NormalTok{occurrence }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(all\_fish\_caught, fish\_retained\_data) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{basisOfRecord =} \StringTok{"HumanObservation"}\NormalTok{,}
        \AttributeTok{occurenceStatus =} \StringTok{"present"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ seine\_id)}
\end{Highlighting}
\end{Shaded}

For each occuerence of the six different fish species that I caught I need to match the species name that I provide with the official \texttt{scientificName} that is part of the World Register of Marine Species database \url{http://www.marinespecies.org/}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# I went directly to the WoRMS webite (http://www.marinespecies.org/) to download the full taxonomic levels for the salmon species I have and put the WoRMS output (species\_matched.xls) table in this project directory which is read in below and joined with the occurrence table}

\NormalTok{species\_matched }\OtherTok{\textless{}{-}}\NormalTok{ readxl}\SpecialCharTok{::}\FunctionTok{read\_excel}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"datasets"}\NormalTok{, }\StringTok{"hakai\_salmon\_data"}\NormalTok{, }\StringTok{"raw\_data"}\NormalTok{, }\StringTok{"species\_matched.xls"}\NormalTok{))}

\NormalTok{occurrence }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(occurrence, species\_matched, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"scientificName"} \OtherTok{=} \StringTok{"ScientificName"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(occurrenceID, basisOfRecord, scientificName, eventID, }\AttributeTok{occurrenceStatus =}\NormalTok{ occurenceStatus, Kingdom, Phylum, Class, Order, Family, Genus, Species)}

\FunctionTok{write\_csv}\NormalTok{(occurrence, here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"datasets"}\NormalTok{, }\StringTok{"hakai\_salmon\_data"}\NormalTok{, }\StringTok{"occurrence.csv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{measurementorfact}{%
\subsection{measurementOrFact}\label{measurementorfact}}

To convert all your measurements or facts from your normal format to Darwin Core you essentially need to put all your measurements into one column called measurementType and a corresponding column called MeasurementValue. This standardizes the column names are in the \texttt{measurementOrFact} table. There are a number of predefined \texttt{measurementType}s listed on the \href{https://www.bodc.ac.uk/resources/vocabularies/}{NERC} database that should be used where possible. I found it difficult to navigate this page to find the correct \texttt{measurementType}.

Here I convert length, and weight measurements that relate to an event and an occurrence and call those \texttt{measurementTypes} as \texttt{length} and \texttt{weight}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fish\_data}\SpecialCharTok{$}\NormalTok{weight }\OtherTok{\textless{}{-}} \FunctionTok{coalesce}\NormalTok{(fish\_data}\SpecialCharTok{$}\NormalTok{weight, fish\_data}\SpecialCharTok{$}\NormalTok{weight\_field)}
\NormalTok{fish\_data}\SpecialCharTok{$}\NormalTok{fork\_length }\OtherTok{\textless{}{-}} \FunctionTok{coalesce}\NormalTok{(fish\_data}\SpecialCharTok{$}\NormalTok{fork\_length, fish\_data}\SpecialCharTok{$}\NormalTok{fork\_length\_field)}

\NormalTok{fish\_length }\OtherTok{\textless{}{-}}\NormalTok{ fish\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{occurrenceID =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"hakai{-}jsp{-}"}\NormalTok{, ufn)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(occurrenceID, }\AttributeTok{eventID =}\NormalTok{ seine\_id, fork\_length, weight) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"fork length"}\NormalTok{, }\AttributeTok{measurementValue =}\NormalTok{ fork\_length) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(eventID, occurrenceID, measurementType, measurementValue) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementUnit =} \StringTok{"millimeters"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UXMM/"}\NormalTok{)}

\NormalTok{fish\_weight }\OtherTok{\textless{}{-}}\NormalTok{ fish\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{occurrenceID =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"hakai{-}jsp{-}"}\NormalTok{, ufn)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(occurrenceID, }\AttributeTok{eventID =}\NormalTok{ seine\_id, fork\_length, weight) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementType =} \StringTok{"mass"}\NormalTok{, }\AttributeTok{measurementValue =}\NormalTok{ weight) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(eventID, occurrenceID, measurementType, measurementValue) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{measurementUnit =} \StringTok{"grams"}\NormalTok{,}
         \AttributeTok{measurementUnitID =} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UGRM/"}\NormalTok{)}

\NormalTok{measurementOrFact }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(fish\_length, fish\_weight) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{drop\_na}\NormalTok{(measurementValue)}

\FunctionTok{rm}\NormalTok{(fish\_length, fish\_weight)}

\FunctionTok{write\_csv}\NormalTok{(measurementOrFact, here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"datasets"}\NormalTok{, }\StringTok{"hakai\_salmon\_data"}\NormalTok{, }\StringTok{"measurementOrFact.csv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{hakai-seagrass}{%
\section{Hakai Seagrass}\label{hakai-seagrass}}

\hypertarget{setup}{%
\subsection{Setup}\label{setup}}

This section clears the workspace, checks the working directory, and
installs packages (if required) and loads packages, and loads necessary
datasets

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"knitr"}\NormalTok{)}
\CommentTok{\# Knitr global chunk options}
\NormalTok{opts\_chunk}\SpecialCharTok{$}\FunctionTok{set}\NormalTok{(}\AttributeTok{message =} \ConstantTok{FALSE}\NormalTok{,}
               \AttributeTok{warning =} \ConstantTok{FALSE}\NormalTok{,}
               \AttributeTok{error   =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{load-data}{%
\subsubsection{Load Data}\label{load-data}}

First load the seagrass density survey data, set variable classes, and have a quick look

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load density data}
\NormalTok{seagrassDensity }\OtherTok{\textless{}{-}} 
  \FunctionTok{read.csv}\NormalTok{(}\StringTok{"raw\_data/seagrass\_density\_survey.csv"}\NormalTok{,}
           \AttributeTok{colClass =} \StringTok{"character"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date             =} \FunctionTok{ymd}\NormalTok{(date),}
         \AttributeTok{depth            =} \FunctionTok{as.numeric}\NormalTok{(depth),}
         \AttributeTok{transect\_dist    =} \FunctionTok{factor}\NormalTok{(transect\_dist),}
         \AttributeTok{collected\_start  =} \FunctionTok{ymd\_hms}\NormalTok{(collected\_start),}
         \AttributeTok{collected\_end    =} \FunctionTok{ymd\_hms}\NormalTok{(collected\_end),}
         \AttributeTok{density          =} \FunctionTok{as.numeric}\NormalTok{(density),}
         \AttributeTok{density\_msq      =} \FunctionTok{as.numeric}\NormalTok{(density\_msq),}
         \AttributeTok{canopy\_height\_cm =} \FunctionTok{as.numeric}\NormalTok{(canopy\_height\_cm),}
         \AttributeTok{flowering\_shoots =} \FunctionTok{as.numeric}\NormalTok{(flowering\_shoots)) }\SpecialCharTok{\%T\textgreater{}\%}
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 3,031
## Columns: 22
## $ X                <chr> "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "1~
## $ organization     <chr> "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI",~
## $ work_area        <chr> "CALVERT", "CALVERT", "CALVERT", "CALVERT", "CALVERT"~
## $ project          <chr> "MARINEGEO", "MARINEGEO", "MARINEGEO", "MARINEGEO", "~
## $ survey           <chr> "PRUTH_BAY", "PRUTH_BAY", "PRUTH_BAY", "PRUTH_BAY", "~
## $ site_id          <chr> "PRUTH_BAY_INTERIOR4", "PRUTH_BAY_INTERIOR4", "PRUTH_~
## $ date             <date> 2016-05-13, 2016-05-13, 2016-05-13, 2016-05-13, 2016~
## $ sampling_bout    <chr> "4", "4", "4", "4", "4", "4", "4", "6", "6", "6", "6"~
## $ dive_supervisor  <chr> "Zach", "Zach", "Zach", "Zach", "Zach", "Zach", "Zach~
## $ collector        <chr> "Derek", "Derek", "Derek", "Derek", "Derek", "Derek",~
## $ hakai_id         <chr> "2016-05-13_PRUTH_BAY_INTERIOR4_0", "2016-05-13_PRUTH~
## $ sample_type      <chr> "seagrass_density", "seagrass_density", "seagrass_den~
## $ depth            <dbl> 6.0, 6.0, 6.0, 6.0, 5.0, 6.0, 6.0, 9.1, 9.0, 8.9, 9.0~
## $ transect_dist    <fct> 0, 5, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 0, 5, 1~
## $ collected_start  <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ collected_end    <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ density          <dbl> 13, 10, 18, 22, 16, 31, 9, 5, 6, 6, 6, 3, 13, 30, 23,~
## $ density_msq      <dbl> 208, 160, 288, 352, 256, 496, 144, 80, 96, 96, 96, 48~
## $ canopy_height_cm <dbl> 60, 63, 80, 54, 55, 50, 63, 85, 80, 90, 95, 75, 60, 6~
## $ flowering_shoots <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 0, 0, 0, 0, NA, NA, NA~
## $ comments         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ quality_log      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
\end{verbatim}

Next, load the habitat survey data, and same as above, set variable classes as necessary,
and have a quick look.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load habitat data, set variable classes, have a quick look}
\NormalTok{seagrassHabitat }\OtherTok{\textless{}{-}}
  \FunctionTok{read.csv}\NormalTok{(}\StringTok{"raw\_data/seagrass\_habitat\_survey.csv"}\NormalTok{,}
           \AttributeTok{colClasses =} \StringTok{"character"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}  
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date            =} \FunctionTok{ymd}\NormalTok{(date),}
         \AttributeTok{depth           =} \FunctionTok{as.numeric}\NormalTok{(depth),}
         \AttributeTok{hakai\_id        =} \FunctionTok{str\_pad}\NormalTok{(hakai\_id, }\DecValTok{5}\NormalTok{, }\AttributeTok{pad =} \StringTok{"0"}\NormalTok{),}
         \AttributeTok{transect\_dist   =} \FunctionTok{factor}\NormalTok{(transect\_dist),}
         \AttributeTok{collected\_start =} \FunctionTok{ymd\_hms}\NormalTok{(collected\_start),}
         \AttributeTok{collected\_end   =} \FunctionTok{ymd\_hms}\NormalTok{(collected\_end)) }\SpecialCharTok{\%T\textgreater{}\%}
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 2,052
## Columns: 28
## $ X                <chr> "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "1~
## $ organization     <chr> "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI",~
## $ work_area        <chr> "CALVERT", "CALVERT", "CALVERT", "CALVERT", "CALVERT"~
## $ project          <chr> "MARINEGEO", "MARINEGEO", "MARINEGEO", "MARINEGEO", "~
## $ survey           <chr> "CHOKED_PASS", "CHOKED_PASS", "CHOKED_PASS", "CHOKED_~
## $ site_id          <chr> "CHOKED_PASS_INTERIOR6", "CHOKED_PASS_INTERIOR6", "CH~
## $ date             <date> 2017-11-22, 2017-11-22, 2017-11-22, 2017-11-22, 2017~
## $ sampling_bout    <chr> "6", "6", "6", "6", "6", "6", "1", "1", "1", "1", "1"~
## $ dive_supervisor  <chr> "gillian", "gillian", "gillian", "gillian", "gillian"~
## $ collector        <chr> "zach", "zach", "zach", "zach", "zach", "zach", "kyle~
## $ hakai_id         <chr> "10883", "2017-11-22_CHOKED_PASS_INTERIOR6_5 - 10", "~
## $ sample_type      <chr> "seagrass_habitat", "seagrass_habitat", "seagrass_hab~
## $ depth            <dbl> 9.2, 9.4, 9.3, 9.0, 9.2, 9.2, 3.4, 3.4, 3.4, 3.4, 3.4~
## $ transect_dist    <fct> 0 - 5, 10-May, 15-Oct, 15 - 20, 20 - 25, 25 - 30, 0 -~
## $ collected_start  <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ collected_end    <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ bag_uid          <chr> "10883", NA, NA, "11094", NA, "11182", "7119", NA, "7~
## $ bag_number       <chr> "3557", NA, NA, "3520", NA, "903", "800", NA, "318", ~
## $ density_range    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ substrate        <chr> "sand,shell hash", "sand,shell hash", "sand,shell has~
## $ patchiness       <chr> "< 1", "< 1", "02-Jan", "< 1", "< 1", "< 1", "< 1", "~
## $ adj_habitat_1    <chr> "seagrass", "seagrass", "seagrass", "seagrass", "seag~
## $ adj_habitat_2    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ sample_collected <chr> "TRUE", "FALSE", "FALSE", "TRUE", "FALSE", "TRUE", "T~
## $ vegetation_1     <chr> NA, NA, NA, NA, NA, NA, "des", NA, "des", NA, NA, NA,~
## $ vegetation_2     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ comments         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ quality_log      <chr> "1: Flowering shoots 0 for entire transects", NA, NA,~
\end{verbatim}

Finally, load coordinate data for surveys, and subset necessary variables

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coordinates }\OtherTok{\textless{}{-}} 
  \FunctionTok{read.csv}\NormalTok{(}\StringTok{"raw\_data/seagrassCoordinates.csv"}\NormalTok{,}
           \AttributeTok{colClass =} \FunctionTok{c}\NormalTok{(}\StringTok{"Point.Name"} \OtherTok{=} \StringTok{"character"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(Point.Name, Decimal.Lat, Decimal.Long) }\SpecialCharTok{\%T\textgreater{}\%}
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 70
## Columns: 3
## $ Point.Name   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ Decimal.Lat  <dbl> 52.06200, 52.05200, 51.92270, 51.92500, 51.80900, 51.8090~
## $ Decimal.Long <dbl> -128.4120, -128.4030, -128.4648, -128.4540, -128.2360, -1~
\end{verbatim}

\hypertarget{merge-datasets}{%
\subsubsection{Merge Datasets}\label{merge-datasets}}

Now all the datasets have been loaded, and briefly formatted, we'll join
together the habitat and density surveys, and the coordinates for these.

The seagrass density surveys collect data at discrete points (ie. 5 metres)
along the transects, while the habitat surveys collect data over sections
(ie. 0 - 5 metres) along the transects. In order to fit these two surveys
together, we'll narrow the habitat surveys from a range to a point so the
locations will match. Based on how the habitat data is collected, the point
the habitat survey is applied to will be the distance at the end of the
swath (ie. 10-15m will become 15m). To account for no preceeding distance,
the 0m distance will use the 0-5m section of the survey.

First, well make the necessary transformations to the habitat dataset.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reformat seagrassHabitat to merge with seagrassDensity}
\DocumentationTok{\#\# replicate 0 {-} 5m transect dist to match with 0m in density survey;}
\DocumentationTok{\#\# rest of habitat bins can map one to one with density (ie. 5 {-} 10m {-}\textgreater{} 10m)}
\NormalTok{seagrass0tmp }\OtherTok{\textless{}{-}} 
\NormalTok{  seagrassHabitat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(transect\_dist }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"0 {-} 5"}\NormalTok{, }\StringTok{"0 {-} 2.5"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{transect\_dist =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{))}

\DocumentationTok{\#\# collapse various levels to match with seagrassDensity transect\_dist}
\NormalTok{seagrassHabitat}\SpecialCharTok{$}\NormalTok{transect\_dist }\OtherTok{\textless{}{-}} 
  \FunctionTok{fct\_collapse}\NormalTok{(seagrassHabitat}\SpecialCharTok{$}\NormalTok{transect\_dist,}
               \StringTok{"5"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"0 {-} 5"}\NormalTok{, }\StringTok{"2.5 {-} 7.5"}\NormalTok{),}
               \StringTok{"10"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"5 {-} 10"}\NormalTok{, }\StringTok{"7.5 {-} 12.5"}\NormalTok{),}
               \StringTok{"15"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"10 {-} 15"}\NormalTok{, }\StringTok{"12.5 {-} 17.5"}\NormalTok{),}
               \StringTok{"20"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"15 {-} 20"}\NormalTok{, }\StringTok{"17.5 {-} 22.5"}\NormalTok{),}
               \StringTok{"25"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"20 {-} 25"}\NormalTok{, }\StringTok{"22.5 {-} 27.5"}\NormalTok{),}
               \StringTok{"30"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"25 {-} 30"}\NormalTok{, }\StringTok{"27.5 {-} 30"}\NormalTok{))}

\DocumentationTok{\#\# merge seagrass0tmp into seagrassHabitat to account for 0m samples,}
\DocumentationTok{\#\# set class for date, datetime variables}
\NormalTok{seagrassHabitatFull }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(seagrass0tmp, seagrassHabitat) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(transect\_dist }\SpecialCharTok{!=} \StringTok{"0 {-} 2.5"}\NormalTok{)  }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# already captured in seagrass0tmp }
  \FunctionTok{droplevels}\NormalTok{(.)  }\CommentTok{\# remove now unused factor levels}
\end{Highlighting}
\end{Shaded}

With the distances of habitat and density surveys now corresponding, we can
now merge these two datasets plus there coordinates together, combine
redundant fields, and remove unnecessary fields.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Merge seagrassHabitatFull with seagrassDensity, then coordinates}
\NormalTok{seagrass }\OtherTok{\textless{}{-}} 
  \FunctionTok{full\_join}\NormalTok{(seagrassHabitatFull, seagrassDensity, }
            \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"organization"}\NormalTok{,}
                   \StringTok{"work\_area"}\NormalTok{,}
                   \StringTok{"project"}\NormalTok{,}
                   \StringTok{"survey"}\NormalTok{,}
                   \StringTok{"site\_id"}\NormalTok{, }
                   \StringTok{"date"}\NormalTok{,}
                   \StringTok{"transect\_dist"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# merge hakai\_id.x and hakai\_id.y into single variable field;}
  \CommentTok{\# use combination of date, site\_id, transect\_dist, and field uid (hakai\_id }
  \CommentTok{\# when present)}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{field\_uid =} \FunctionTok{ifelse}\NormalTok{(sample\_collected }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{, hakai\_id.x, }\StringTok{"NA"}\NormalTok{),}
         \AttributeTok{hakai\_id =} \FunctionTok{paste}\NormalTok{(date, }\StringTok{"HAKAI:CALVERT"}\NormalTok{, site\_id, transect\_dist, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \CommentTok{\# below, aggregate metadata that didn\textquotesingle{}t merge naturally (ie. due to minor }
         \CommentTok{\# differences in watch time or depth gauges)}
         \AttributeTok{dive\_supervisor =}\NormalTok{ dive\_supervisor.x,}
         \AttributeTok{collected\_start =} \FunctionTok{ymd\_hms}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(collected\_start.x),}
\NormalTok{                                          collected\_start.y, }
\NormalTok{                                          collected\_start.x)),}
         \AttributeTok{collected\_end   =} \FunctionTok{ymd\_hms}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(collected\_start.x),}
\NormalTok{                                          collected\_start.y,}
\NormalTok{                                          collected\_start.x)),}
         \AttributeTok{depth\_m         =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(depth.x), depth.y, depth.x),}
         \AttributeTok{sampling\_bout   =}\NormalTok{ sampling\_bout.x) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(., coordinates,  }\CommentTok{\# add coordinates}
            \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"site\_id"} \OtherTok{=} \StringTok{"Point.Name"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{( }\SpecialCharTok{{-}} \FunctionTok{c}\NormalTok{(X.x, X.y, hakai\_id.x, hakai\_id.y,  }\CommentTok{\# remove unnecessary variables}
\NormalTok{              dive\_supervisor.x, dive\_supervisor.y,}
\NormalTok{              collected\_start.x, collected\_start.y,}
\NormalTok{              collected\_end.x, collected\_end.y,}
\NormalTok{              depth.x, depth.y,}
\NormalTok{              sampling\_bout.x, sampling\_bout.y)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{density\_msq =} \FunctionTok{as.character}\NormalTok{(density\_msq),}
         \AttributeTok{canopy\_height\_cm =} \FunctionTok{as.character}\NormalTok{(canopy\_height\_cm),}
         \AttributeTok{flowering\_shoots =} \FunctionTok{as.character}\NormalTok{(flowering\_shoots),}
         \AttributeTok{depth\_m =} \FunctionTok{as.character}\NormalTok{(depth\_m)) }\SpecialCharTok{\%T\textgreater{}\%}
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 3,743
## Columns: 38
## $ organization     <chr> "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI", "HAKAI",~
## $ work_area        <chr> "CALVERT", "CALVERT", "CALVERT", "CALVERT", "CALVERT"~
## $ project          <chr> "MARINEGEO", "MARINEGEO", "MARINEGEO", "MARINEGEO", "~
## $ survey           <chr> "CHOKED_PASS", "CHOKED_PASS", "CHOKED_PASS", "PRUTH_B~
## $ site_id          <chr> "CHOKED_PASS_INTERIOR6", "CHOKED_PASS_EDGE1", "CHOKED~
## $ date             <date> 2017-11-22, 2017-05-19, 2017-05-19, 2017-07-03, 2017~
## $ collector.x      <chr> "zach", "kyle", NA, "tanya", "zach", "zach", "zach", ~
## $ sample_type.x    <chr> "seagrass_habitat", "seagrass_habitat", "seagrass_hab~
## $ transect_dist    <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ bag_uid          <chr> "10883", "7119", "7031", "2352", "10255", "10023", "1~
## $ bag_number       <chr> "3557", "800", "301", "324", "3506", "3555", "3534", ~
## $ density_range    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ substrate        <chr> "sand,shell hash", "sand,shell hash", "sand,shell has~
## $ patchiness       <chr> "< 1", "< 1", "< 1", "< 1", "< 1", "05-Apr", "04-Mar"~
## $ adj_habitat_1    <chr> "seagrass", "sand", "standing kelp", "seagrass", "sea~
## $ adj_habitat_2    <chr> NA, NA, NA, NA, NA, NA, "standing kelp", NA, NA, NA, ~
## $ sample_collected <chr> "TRUE", "TRUE", "TRUE", "TRUE", "TRUE", "TRUE", "TRUE~
## $ vegetation_1     <chr> NA, "des", "des", "zm", "des", NA, NA, NA, NA, NA, NA~
## $ vegetation_2     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "~
## $ comments.x       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ quality_log.x    <chr> "1: Flowering shoots 0 for entire transects", NA, NA,~
## $ collector.y      <chr> "derek", "ondine", "ondine", "derek", "derek", "derek~
## $ sample_type.y    <chr> "seagrass_density", "seagrass_density", "seagrass_den~
## $ density          <dbl> 4, 10, 6, 13, 6, 1, 2, 6, 21, 3, 7, 4, 3, 14, 17, 11,~
## $ density_msq      <chr> "64", "160", "96", "208", "96", "16", "32", "96", "33~
## $ canopy_height_cm <chr> "80", "80", "110", "60", "125", "100", "100", "125", ~
## $ flowering_shoots <chr> "0", NA, NA, NA, NA, NA, NA, "0", NA, NA, NA, "0", NA~
## $ comments.y       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~
## $ quality_log.y    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "~
## $ field_uid        <chr> "10883", "07119", "07031", "02352", "10255", "10023",~
## $ hakai_id         <chr> "2017-11-22:HAKAI:CALVERT:CHOKED_PASS_INTERIOR6:0", "~
## $ dive_supervisor  <chr> "gillian", "gillian,gillian.sadlierbrown", "gillian,g~
## $ collected_start  <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ collected_end    <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ depth_m          <chr> "9.2", "3.4", "4.8", "2.4", "5.3", "5.6", "4.4", "2.5~
## $ sampling_bout    <chr> "6", "1", "3", "5", "5", "3", "5", "2", "1", "2", "6"~
## $ Decimal.Lat      <dbl> 51.67482, 51.67882, 51.67493, 51.64532, 51.67349, 51.~
## $ Decimal.Long     <dbl> -128.1195, -128.1148, -128.1237, -128.1193, -128.1180~
\end{verbatim}

\hypertarget{convert-data-to-darwin-core---extended-measurement-or-fact-format}{%
\subsection{Convert Data to Darwin Core - Extended Measurement or Fact format}\label{convert-data-to-darwin-core---extended-measurement-or-fact-format}}

The Darwin Core ExtendedMeasurementOrFact (eMoF) extension bases records
around a core event (rather than occurrence as in standard Darwin Core),
allowing for additional measurement variables to be associated with
occurrence data.

\hypertarget{add-event-id-and-occurrence-id-variables-to-dataset}{%
\subsubsection{Add Event ID and Occurrence ID variables to dataset}\label{add-event-id-and-occurrence-id-variables-to-dataset}}

As this dataset will be annually updated, rather than using
natural keys (ie. using package::uuid to autogenerate) for event and
occurence IDs, here we will use surrogate keys made up of a concatenation
of date survey, transect location, observation distance, and sample ID
(for occurrenceID, when a sample is present).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create and populate eventID variable}
\DocumentationTok{\#\# currently only event is used, but additional surveys and abiotic data}
\DocumentationTok{\#\# are associated with parent events that may be included at a later date}
\NormalTok{seagrass}\SpecialCharTok{$}\NormalTok{eventID }\OtherTok{\textless{}{-}}\NormalTok{ seagrass}\SpecialCharTok{$}\NormalTok{hakai\_id}

\CommentTok{\# create and populate occurrenceID; combine eventID with transect\_dist }
\CommentTok{\# and field\_uid}
\DocumentationTok{\#\# in the event of \textless{}NA\textgreater{} field\_uid, no sample was collected, but}
\DocumentationTok{\#\# measurements and occurrence are still taken; no further subsamples}
\DocumentationTok{\#\# are associated with \textless{}NA\textgreater{} field\_uids}
\NormalTok{seagrass}\SpecialCharTok{$}\NormalTok{occurrenceID }\OtherTok{\textless{}{-}} 
  \FunctionTok{with}\NormalTok{(seagrass, }
       \FunctionTok{paste}\NormalTok{(eventID, transect\_dist, field\_uid, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{create-event-occurrence-and-emof-tables}{%
\subsubsection{Create Event, Occurrence, and eMoF tables}\label{create-event-occurrence-and-emof-tables}}

Now that we've created eventIDs and occurrenceIDs to connect all the
variables together, we can begin to create the Event, Occurrence,
and extended Measurement or Fact table necessary for DarwinCore
compliant datasets

\hypertarget{event-table}{%
\paragraph{Event Table}\label{event-table}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# subset seagrass to create event table}
\NormalTok{seagrassEvent }\OtherTok{\textless{}{-}}
\NormalTok{  seagrass }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  distinct }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# some duplicates in data stemming from database conflicts}
  \FunctionTok{select}\NormalTok{(date,}
\NormalTok{         Decimal.Lat, Decimal.Long, transect\_dist,}
\NormalTok{         depth\_m, eventID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{eventDate                     =}\NormalTok{ date,}
         \AttributeTok{decimalLatitude               =}\NormalTok{ Decimal.Lat,}
         \AttributeTok{decimalLongitude              =}\NormalTok{ Decimal.Long,}
         \AttributeTok{coordinateUncertaintyInMeters =}\NormalTok{ transect\_dist,}
         \AttributeTok{minimumDepthInMeters          =}\NormalTok{ depth\_m,}
         \AttributeTok{maximumDepthInMeters          =}\NormalTok{ depth\_m) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{geodeticDatum  =} \StringTok{"WGS84"}\NormalTok{,}
         \AttributeTok{samplingEffort =} \StringTok{"30 metre transect"}\NormalTok{) }\SpecialCharTok{\%T\textgreater{}\%}\NormalTok{ glimpse}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 3,659
## Columns: 8
## $ eventDate                     <date> 2017-11-22, 2017-05-19, 2017-05-19, 201~
## $ decimalLatitude               <dbl> 51.67482, 51.67882, 51.67493, 51.64532, ~
## $ decimalLongitude              <dbl> -128.1195, -128.1148, -128.1237, -128.11~
## $ coordinateUncertaintyInMeters <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~
## $ maximumDepthInMeters          <chr> "9.2", "3.4", "4.8", "2.4", "5.3", "5.6"~
## $ eventID                       <chr> "2017-11-22:HAKAI:CALVERT:CHOKED_PASS_IN~
## $ geodeticDatum                 <chr> "WGS84", "WGS84", "WGS84", "WGS84", "WGS~
## $ samplingEffort                <chr> "30 metre transect", "30 metre transect"~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# save event table to csv}
\FunctionTok{write.csv}\NormalTok{(seagrassEvent, }\StringTok{"processed\_data/hakaiSeagrassDwcEvent.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{occurrence-table}{%
\paragraph{Occurrence Table}\label{occurrence-table}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# subset seagrass to create occurrence table}
\NormalTok{seagrassOccurrence }\OtherTok{\textless{}{-}}
\NormalTok{  seagrass }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  distinct }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# some duplicates in data stemming from database conflicts}
  \FunctionTok{select}\NormalTok{(eventID, occurrenceID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{basisOfRecord =} \StringTok{"HumanObservation"}\NormalTok{,}
         \AttributeTok{scientificName   =} \StringTok{"Zostera subg. Zostera marina"}\NormalTok{,}
         \AttributeTok{occurrenceStatus =} \StringTok{"present"}\NormalTok{)}

\CommentTok{\# Taxonomic name matching}
\CommentTok{\# in addition to the above metadata, DarwinCore format requires further}
\CommentTok{\# taxonomic data that can be acquired through the WoRMS register.}
\DocumentationTok{\#\# Load taxonomic info, downloaded via WoRMS tool}
\CommentTok{\# zmWorms \textless{}{-} }
\CommentTok{\#   read.delim("raw\_data/zmworms\_matched.txt",}
\CommentTok{\#              header = TRUE,}
\CommentTok{\#              nrows  = 1)}

\NormalTok{zmWorms }\OtherTok{\textless{}{-}} \FunctionTok{wm\_record}\NormalTok{(}\AttributeTok{id =} \DecValTok{145795}\NormalTok{)}

\CommentTok{\# join WoRMS name with seagrassOccurrence create above}
\NormalTok{seagrassOccurrence }\OtherTok{\textless{}{-}} 
  \FunctionTok{full\_join}\NormalTok{(seagrassOccurrence, zmWorms, }
            \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"scientificName"} \OtherTok{=} \StringTok{"scientificname"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(eventID, occurrenceID, basisOfRecord, scientificName, occurrenceStatus, AphiaID,}
\NormalTok{         url, authority, status, unacceptreason, taxonRankID, rank,}
\NormalTok{         valid\_AphiaID, valid\_name, valid\_authority, parentNameUsageID,}
\NormalTok{         kingdom, phylum, class, order, family, genus, citation, lsid,}
\NormalTok{         isMarine, match\_type, modified) }\SpecialCharTok{\%T\textgreater{}\%}
\NormalTok{  glimpse}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 3,659
## Columns: 27
## $ eventID           <chr> "2017-11-22:HAKAI:CALVERT:CHOKED_PASS_INTERIOR6:0", ~
## $ occurrenceID      <chr> "2017-11-22:HAKAI:CALVERT:CHOKED_PASS_INTERIOR6:0:0:~
## $ basisOfRecord     <chr> "HumanObservation", "HumanObservation", "HumanObserv~
## $ scientificName    <chr> "Zostera subg. Zostera marina", "Zostera subg. Zoste~
## $ occurrenceStatus  <chr> "present", "present", "present", "present", "present~
## $ AphiaID           <int> 145795, 145795, 145795, 145795, 145795, 145795, 1457~
## $ url               <chr> "https://www.marinespecies.org/aphia.php?p=taxdetail~
## $ authority         <chr> "Linnaeus, 1753", "Linnaeus, 1753", "Linnaeus, 1753"~
## $ status            <chr> "accepted", "accepted", "accepted", "accepted", "acc~
## $ unacceptreason    <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ taxonRankID       <int> 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 22~
## $ rank              <chr> "Species", "Species", "Species", "Species", "Species~
## $ valid_AphiaID     <int> 145795, 145795, 145795, 145795, 145795, 145795, 1457~
## $ valid_name        <chr> "Zostera subg. Zostera marina", "Zostera subg. Zoste~
## $ valid_authority   <chr> "Linnaeus, 1753", "Linnaeus, 1753", "Linnaeus, 1753"~
## $ parentNameUsageID <int> 370435, 370435, 370435, 370435, 370435, 370435, 3704~
## $ kingdom           <chr> "Plantae", "Plantae", "Plantae", "Plantae", "Plantae~
## $ phylum            <chr> "Tracheophyta", "Tracheophyta", "Tracheophyta", "Tra~
## $ class             <chr> "Magnoliopsida", "Magnoliopsida", "Magnoliopsida", "~
## $ order             <chr> "Alismatales", "Alismatales", "Alismatales", "Alisma~
## $ family            <chr> "Zosteraceae", "Zosteraceae", "Zosteraceae", "Zoster~
## $ genus             <chr> "Zostera", "Zostera", "Zostera", "Zostera", "Zostera~
## $ citation          <chr> "WoRMS (2024). Zostera subg. Zostera marina Linnaeus~
## $ lsid              <chr> "urn:lsid:marinespecies.org:taxname:145795", "urn:ls~
## $ isMarine          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~
## $ match_type        <chr> "exact", "exact", "exact", "exact", "exact", "exact"~
## $ modified          <chr> "2008-12-09T10:03:16.140Z", "2008-12-09T10:03:16.140~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# save occurrence table to csv}
\FunctionTok{write.csv}\NormalTok{(seagrassOccurrence, }\StringTok{"processed\_data/hakaiSeagrassDwcOccurrence.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{extended-measurementorfact-table}{%
\paragraph{Extended MeasurementOrFact table}\label{extended-measurementorfact-table}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{seagrassMof }\OtherTok{\textless{}{-}}
\NormalTok{  seagrass }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# select variables for eMoF table}
  \FunctionTok{select}\NormalTok{(date,}
\NormalTok{         eventID, survey, site\_id, transect\_dist,}
\NormalTok{         substrate, patchiness, adj\_habitat\_1, adj\_habitat\_2,}
\NormalTok{         vegetation\_1, vegetation\_2,}
\NormalTok{         density\_msq, canopy\_height\_cm, flowering\_shoots) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# split substrate into two variables (currently holds two substrate type in same variable)}
  \FunctionTok{separate}\NormalTok{(substrate, }\AttributeTok{sep =} \StringTok{","}\NormalTok{, }\AttributeTok{into =} \FunctionTok{c}\NormalTok{(}\StringTok{"substrate\_1"}\NormalTok{, }\StringTok{"substrate\_2"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# change variables names to match NERC database (or to be more descriptive where none exist)}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{measurementDeterminedDate   =}\NormalTok{ date,}
         \AttributeTok{SubstrateTypeA              =}\NormalTok{ substrate\_1,}
         \AttributeTok{SubstrateTypeB              =}\NormalTok{ substrate\_2,}
         \AttributeTok{BarePatchLengthWithinSeagrass =}\NormalTok{ patchiness,}
         \AttributeTok{PrimaryAdjacentHabitat      =}\NormalTok{ adj\_habitat\_1,}
         \AttributeTok{SecondaryAdjacentHabitat    =}\NormalTok{ adj\_habitat\_2,}
         \AttributeTok{PrimaryAlgaeSp              =}\NormalTok{ vegetation\_1,}
         \AttributeTok{SecondaryAlgaeSp            =}\NormalTok{ vegetation\_2,}
         \AttributeTok{BedAbund                    =}\NormalTok{ density\_msq,}
         \AttributeTok{CanopyHeight                =}\NormalTok{ canopy\_height\_cm,}
         \AttributeTok{FloweringBedAbund           =}\NormalTok{ flowering\_shoots) }\SpecialCharTok{\%\textgreater{}\%}  
  \CommentTok{\# reformat variables into DwC MeasurementOrFact format}
  \CommentTok{\# (single values variable, with measurement type, unit, etc. variables)}
  \FunctionTok{pivot\_longer}\NormalTok{( }\SpecialCharTok{{-}} \FunctionTok{c}\NormalTok{(measurementDeterminedDate, eventID, survey, site\_id, transect\_dist),}
                \AttributeTok{names\_to =} \StringTok{"measurementType"}\NormalTok{,}
                \AttributeTok{values\_to =} \StringTok{"measurementValue"}\NormalTok{,}
                \AttributeTok{values\_ptypes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{measurementValue =} \StringTok{"character"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# use measurement type to fill in remainder of variables relating to }
  \CommentTok{\# NERC vocabulary and metadata fields}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{measurementTypeID =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/SDBIOL02/"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"CanopyHeight"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/OBSMAXLX/"}\NormalTok{,}
      \CommentTok{\# measurementType == "BarePatchWithinSeagrass" \textasciitilde{} "",}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"FloweringBedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P01/current/SDBIOL02/"}\NormalTok{),}
    \AttributeTok{measurementUnit =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Number per square metre"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"CanopyHeight"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Centimetres"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BarePatchhLengthWithinSeagrass"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Metres"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"FloweringBedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Number per square metre"}\NormalTok{),}
    \AttributeTok{measurementUnitID =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UPMS/"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"CanopyHeight"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/ULCM/"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BarePatchhLengthWithinSeagrass"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/ULAA/2/"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"FloweringBedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://vocab.nerc.ac.uk/collection/P06/current/UPMS/"}\NormalTok{),}
    \AttributeTok{measurementAccuracy =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"CanopyHeight"} \SpecialCharTok{\textasciitilde{}} \DecValTok{5}\NormalTok{),}
    \AttributeTok{measurementMethod =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"25cmx25cm quadrat count"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"CanopyHeight"} \SpecialCharTok{\textasciitilde{}} \StringTok{"in situ with ruler"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"BarePatchhLengthWithinSeagrass"} \SpecialCharTok{\textasciitilde{}} \StringTok{"estimated along transect line"}\NormalTok{,}
\NormalTok{      measurementType }\SpecialCharTok{==} \StringTok{"FloweringBedAbund"} \SpecialCharTok{\textasciitilde{}} \StringTok{"25cmx25cm quadrat count"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(eventID, measurementDeterminedDate, measurementType, measurementValue,}
\NormalTok{         measurementTypeID, measurementUnit, measurementUnitID, measurementAccuracy,}
\NormalTok{         measurementMethod) }\SpecialCharTok{\%T\textgreater{}\%}
\CommentTok{\#  select(!c(survey, site\_id, transect\_dist)) \%T\textgreater{}\%}
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 37,430
## Columns: 9
## $ eventID                   <chr> "2017-11-22:HAKAI:CALVERT:CHOKED_PASS_INTERI~
## $ measurementDeterminedDate <date> 2017-11-22, 2017-11-22, 2017-11-22, 2017-11~
## $ measurementType           <chr> "SubstrateTypeA", "SubstrateTypeB", "BarePat~
## $ measurementValue          <chr> "sand", "shell hash", "< 1", "seagrass", NA,~
## $ measurementTypeID         <chr> NA, NA, NA, NA, NA, NA, NA, "http://vocab.ne~
## $ measurementUnit           <chr> NA, NA, NA, NA, NA, NA, NA, "Number per squa~
## $ measurementUnitID         <chr> NA, NA, NA, NA, NA, NA, NA, "http://vocab.ne~
## $ measurementAccuracy       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, N~
## $ measurementMethod         <chr> NA, NA, NA, NA, NA, NA, NA, "25cmx25cm quadr~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# save eMoF table to csv}
\FunctionTok{write.csv}\NormalTok{(seagrassMof, }\StringTok{"processed\_data/hakaiSeagrassDwcEmof.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{session-info}{%
\subsection{Session Info}\label{session-info}}

Print session information below in case necessary for future reference

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Print Session Info for future reference}
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## R version 4.1.1 (2021-08-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] worrms_0.4.3    magrittr_2.0.3  knitr_1.42      here_1.0.1     
##  [5] lubridate_1.9.3 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.2    
##  [9] purrr_1.0.1     readr_2.1.5     tidyr_1.3.0     tibble_3.2.1   
## [13] ggplot2_3.4.2   tidyverse_2.0.0
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.2.1  xfun_0.39         colorspace_2.1-0  vctrs_0.6.5      
##  [5] generics_0.1.3    htmltools_0.5.5   yaml_2.3.7        utf8_1.2.3       
##  [9] rlang_1.1.1       pillar_1.9.0      glue_1.6.2        httpcode_0.3.0   
## [13] withr_2.5.0       bit64_4.0.5       readxl_1.4.3      lifecycle_1.0.3  
## [17] munsell_0.5.0     gtable_0.3.3      cellranger_1.1.0  evaluate_0.21    
## [21] tzdb_0.3.0        fastmap_1.1.1     parallel_4.1.1    curl_5.0.0       
## [25] fansi_1.0.4       triebeard_0.4.1   urltools_1.7.3    Rcpp_1.0.10      
## [29] scales_1.2.1      jsonlite_1.8.4    vroom_1.6.3       bit_4.0.5        
## [33] hms_1.1.3         digest_0.6.31     stringi_1.7.12    bookdown_0.40    
## [37] grid_4.1.1        rprojroot_2.0.4   cli_3.6.1         tools_4.1.1      
## [41] crul_1.5.0        crayon_1.5.2      pkgconfig_2.0.3   timechange_0.3.0 
## [45] rmarkdown_2.21    rstudioapi_0.16.0 R6_2.5.1          compiler_4.1.1
\end{verbatim}

\hypertarget{trawl-data}{%
\section{Trawl Data}\label{trawl-data}}

One of the more common datasets that can be standardized to Darwin Core and integrated within OBIS is catch data from e.g.~a trawl sampling event, or a zooplankton net tow. Of special concern here are datasets that include both a total (species-specific) catch weight, in addition to individual measurements (for a subset of the overall data). In this case, through our standardization to Darwin Core, we want to ensure that data users understand that the individual measurements are a part of, or subset of, the overall (species-specific) record, whilst at the same time ensure that data providers are not duplicating occurrence records to OBIS.

The GitHub issue related to application is can be found \href{https://github.com/iobis/env-data/issues/10}{here}

\hypertarget{workflow-overview}{%
\subsection{Workflow Overview}\label{workflow-overview}}

In our current setup, this relationship between the overall catch data and subsetted information is provided in the \href{https://tools.gbif.org/dwca-validator/extension.do?id=dwc:ResourceRelationship}{resourceRelationship} extension. This extension \emph{cannot} currently be harvested by GBIF. The required terms for this extension are \texttt{resourceID}, \texttt{relatedResourceID}, \texttt{resourceRelationshipID} and \texttt{relationshipOfResource}. The \texttt{relatedResourceID} here refers to the \emph{object} of the relationship, whereas the \texttt{resourceID} refers to the \emph{subject} of the relationship:

\begin{itemize}
\tightlist
\item
  resourceRelationshipID: a unique identifier for the relationship between one resource (the subject) and another (relatedResource, object).
\item
  resourceID: a unique identifier for the resource that is the subject of the relationship.
\item
  relatedResourceID: a unique identifier for the resource that is the object of the relationship.
\item
  relationshipOfResource: The relationship of the subject (identified by the resourceID) to the object (relatedResourceID). The relationshipOfResource is a free text field.
\end{itemize}

A few resources have been published to OBIS that contain the resourceRelationship extension (examples). Here, I'll lay out the process and coding used for the \href{http://ipt.iobis.org/obiscanada/resource?r=trawl-catch-and-species-abundance-from-the-2019-gulf-of-alaska-international-year-of-the-salmon-expedition}{Trawl Catch and Species Abundance from the 2019 Gulf of Alaska International Year of the Salmon Expedition}. In the following code chunks some details are omitted to improve the readability - the overall code to standardize the catch data can be found \href{https://github.com/HakaiInstitute/iys-oos/blob/develop/datasets/GoA_2019/Trawl/2019/data_wrangle_trawl2019.Rmd}{here}. This dataset includes species-specific total catch data at multiple stations (sampling events). From each catch, individual measurements were also taken. Depending on the number of individual caught in the trawl, this was either the total number of species individuals caught, or only a subset (in case of large numbers of individuals caught).

In this specific data record, we created a single Event Core with three extensions: an \emph{occurrence} extension, \emph{measurement or fact} extension, and the \emph{resourceRelationship} extension. However, in this walk-through I'll only touch on the Event Core, occurrence extension and resourceRelationship extension.

The trawl data is part of a larger project collecting various data types related to salmon ocean ecology. Therefore, in our Event Core we nested information related to the sampling event in the specific layer. (include a visual representation of the schema). Prior to creating the Event Core, we ensured that e.g.~dates and times followed the correct ISO-8601 standards, and converted to the correct time zone.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Time is recorded numerically (1037 instead of 10:37), so need to change these columns:}
\NormalTok{trawl2019}\SpecialCharTok{$}\NormalTok{END\_DEPLOYMENT\_TIME }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(}\FunctionTok{as.POSIXct}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%04.0f"}\NormalTok{, trawl2019}\SpecialCharTok{$}\NormalTok{END\_DEPLOYMENT\_TIME), }\AttributeTok{format =} \StringTok{"\%H\%M"}\NormalTok{), }\DecValTok{12}\NormalTok{, }\DecValTok{16}\NormalTok{)}
\NormalTok{trawl2019}\SpecialCharTok{$}\NormalTok{BEGIN\_RETRIEVAL\_TIME }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(}\FunctionTok{as.POSIXct}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%04.0f"}\NormalTok{, trawl2019}\SpecialCharTok{$}\NormalTok{BEGIN\_RETRIEVAL\_TIME), }\AttributeTok{format =} \StringTok{"\%H\%M"}\NormalTok{), }\DecValTok{12}\NormalTok{, }\DecValTok{16}\NormalTok{)}
\CommentTok{\# Additionally, the vessel time is recorded in \textquotesingle{}Vladivostok\textquotesingle{} according to the metadata tab. This has to be converted to UTC.  }
\NormalTok{trawl2019 }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{eventDate\_start =} \FunctionTok{format\_iso\_8601}\NormalTok{(}\FunctionTok{as.POSIXct}\NormalTok{(}\FunctionTok{paste}\NormalTok{(EVENT\_DATE\_START, END\_DEPLOYMENT\_TIME),}
                                                      \AttributeTok{tz =} \StringTok{"Asia/Vladivostok"}\NormalTok{)),}
         \AttributeTok{eventDate\_start =} \FunctionTok{str\_replace}\NormalTok{(eventDate\_start, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{+00:00"}\NormalTok{, }\StringTok{"Z"}\NormalTok{),}
         \AttributeTok{eventDate\_finish =} \FunctionTok{format\_iso\_8601}\NormalTok{(}\FunctionTok{as.POSIXct}\NormalTok{(}\FunctionTok{paste}\NormalTok{(EVENT\_DATE\_FINISH, BEGIN\_RETRIEVAL\_TIME),}
                                                       \AttributeTok{tz =} \StringTok{"Asia/Vladivostok"}\NormalTok{)),}
         \AttributeTok{eventDate\_finish =} \FunctionTok{str\_replace}\NormalTok{(eventDate\_finish, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{+00:00"}\NormalTok{, }\StringTok{"Z"}\NormalTok{),}
         \AttributeTok{eventDate =} \FunctionTok{paste}\NormalTok{(eventDate\_start, eventDate\_finish, }\AttributeTok{sep =} \StringTok{"/"}\NormalTok{),}
         \AttributeTok{project =} \StringTok{"IYS"}\NormalTok{,}
         \AttributeTok{cruise =} \FunctionTok{paste}\NormalTok{(project, }\StringTok{"GoA2019"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{), }
         \AttributeTok{station =} \FunctionTok{paste}\NormalTok{(cruise, TOW\_NUMBER, }\AttributeTok{sep=}\StringTok{":Stn"}\NormalTok{),}
         \AttributeTok{trawl =} \FunctionTok{paste}\NormalTok{(station, }\StringTok{"trawl"}\NormalTok{, }\AttributeTok{sep=}\StringTok{":"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Then we created the various layers of our Event Core. We created these layers/data frames from two separate datasets that data are pulled from - one dataset that contains the \emph{overall} catch data, and one dataset that contains the \emph{specimen} data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trawl2019\_allCatch }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"Trawl"}\NormalTok{, }\StringTok{"2019"}\NormalTok{, }\StringTok{"raw\_data"}\NormalTok{, }
                                      \StringTok{"2019\_GoA\_Fish\_Trawl\_catchdata.xlsx"}\NormalTok{), }\AttributeTok{sheet =} \StringTok{"CATCH\_FINAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{project =} \StringTok{"IYS"}\NormalTok{,}
         \AttributeTok{cruise =} \FunctionTok{paste}\NormalTok{(project, }\StringTok{"GoA2019"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{station =} \FunctionTok{paste}\NormalTok{(cruise, }\StringTok{\textasciigrave{}}\AttributeTok{TOW\_NUMBER (number)}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{sep =} \StringTok{":Stn"}\NormalTok{),}
         \AttributeTok{trawl =} \FunctionTok{paste}\NormalTok{(station, }\StringTok{"trawl"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{))}

\NormalTok{trawl2019\_specimen }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"Trawl"}\NormalTok{, }\StringTok{"2019"}\NormalTok{, }\StringTok{"raw\_data"}\NormalTok{, }\StringTok{"2019\_GoA\_Fish\_Specimen\_data.xlsx"}\NormalTok{), }
                                 \AttributeTok{sheet =} \StringTok{"SPECIMEN\_FINAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{project =} \StringTok{"IYS"}\NormalTok{,}
         \AttributeTok{cruise =} \FunctionTok{paste}\NormalTok{(project, }\StringTok{"GoA2019"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{station =} \FunctionTok{paste}\NormalTok{(cruise, TOW\_NUMBER, }\AttributeTok{sep =} \StringTok{":Stn"}\NormalTok{),}
         \AttributeTok{trawl =} \FunctionTok{paste}\NormalTok{(station, }\StringTok{"trawl"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{sample =} \FunctionTok{paste}\NormalTok{(trawl, }\StringTok{"sample"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{sample =} \FunctionTok{paste}\NormalTok{(sample, }\FunctionTok{row\_number}\NormalTok{(), }\AttributeTok{sep =} \StringTok{""}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Next we created the Event Core, ensuring that we connect the data to the right layer (i.e.~date and time should be connected to the layer associated with the sampling event). Please note that because we are creating multiple layers and nesting information, and then at a later stage combining different tables, this results in cells being populated with \texttt{NA}. These have to be removed prior to publishing the Event Core through the IPT.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trawl2019\_project }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ project) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{distinct}\NormalTok{(eventID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"project"}\NormalTok{)}

\NormalTok{trawl2019\_cruise }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ cruise,}
         \AttributeTok{parentEventID =}\NormalTok{ project) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{distinct}\NormalTok{(eventID, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"cruise"}\NormalTok{)}

\NormalTok{trawl2019\_station }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ station,}
         \AttributeTok{parentEventID =}\NormalTok{ cruise) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{distinct}\NormalTok{(eventID, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"station"}\NormalTok{)}

\CommentTok{\# The coordinates associated to the trawl need to be presented in a LINESTRING.}
\CommentTok{\# END\_LONGITUDE\_DD needs to be inverted (has to be between {-}180 and 180, inclusive). }
\NormalTok{trawl2019\_coordinates }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ trawl,}
\NormalTok{         START\_LATITUDE\_DD,}
\NormalTok{         longitude,}
\NormalTok{         END\_LATITUDE\_DD,}
\NormalTok{         END\_LONGITUDE\_DD) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{END\_LONGITUDE\_DD =}\NormalTok{ END\_LONGITUDE\_DD }\SpecialCharTok{*} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}
         \AttributeTok{footprintWKT =} \FunctionTok{paste}\NormalTok{(}\StringTok{"LINESTRING ("}\NormalTok{, longitude, START\_LATITUDE\_DD, }\StringTok{","}\NormalTok{, }
\NormalTok{                              END\_LONGITUDE\_DD, END\_LATITUDE\_DD, }\StringTok{")"}\NormalTok{)) }
\NormalTok{trawl2019\_linestring }\OtherTok{\textless{}{-}}\NormalTok{ obistools}\SpecialCharTok{::}\FunctionTok{calculate\_centroid}\NormalTok{(trawl2019\_coordinates}\SpecialCharTok{$}\NormalTok{footprintWKT)}
\NormalTok{trawl2019\_linestring }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(trawl2019\_coordinates, trawl2019\_linestring) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(eventID, footprintWKT, decimalLatitude, decimalLongitude, coordinateUncertaintyInMeters)}

\NormalTok{trawl2019\_trawl }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ trawl,}
         \AttributeTok{parentEventID =}\NormalTok{ station,}
\NormalTok{         eventDate,}
\NormalTok{         year,}
\NormalTok{         month,}
\NormalTok{         day) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{minimumDepthInMeters =} \DecValTok{0}\NormalTok{, }\CommentTok{\# headrope was at the surface}
         \AttributeTok{maximumDepthInMeters =}\NormalTok{ trawl2019}\SpecialCharTok{$}\NormalTok{MOUTH\_OPENING\_HEIGHT,}
         \AttributeTok{samplingProtocol =} \StringTok{"midwater trawl"}\NormalTok{, }\CommentTok{\# when available add DOI to paper here}
         \AttributeTok{locality =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{           trawl2019}\SpecialCharTok{$}\NormalTok{EVENT\_SUB\_TYPE }\SpecialCharTok{==} \StringTok{"Can EEZ"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Canadian EEZ"}\NormalTok{),}
         \AttributeTok{locationID =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{           trawl2019}\SpecialCharTok{$}\NormalTok{EVENT\_SUB\_TYPE }\SpecialCharTok{==} \StringTok{"Can EEZ"} \SpecialCharTok{\textasciitilde{}} \StringTok{"http://marineregions.org/mrgid/8493"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(trawl2019\_linestring, }\AttributeTok{by =} \StringTok{"eventID"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{distinct}\NormalTok{(eventID, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"midwater trawl"}\NormalTok{)}
  
\NormalTok{trawl2019\_sample }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019\_specimen }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ sample,}
         \AttributeTok{parentEventID =}\NormalTok{ trawl) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{distinct}\NormalTok{(eventID, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"individual sample"}\NormalTok{)}

\NormalTok{trawl2019\_event }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(trawl2019\_project, }
\NormalTok{                             trawl2019\_cruise,}
\NormalTok{                             trawl2019\_station,}
\NormalTok{                             trawl2019\_trawl,}
\NormalTok{                             trawl2019\_sample) }

\CommentTok{\# Remove NAs from the Event Core:}
\NormalTok{trawl2019\_event }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(trawl2019\_event, as.character)}
\NormalTok{trawl2019\_event[}\FunctionTok{is.na}\NormalTok{(trawl2019\_event)] }\OtherTok{\textless{}{-}} \StringTok{""}
\NormalTok{trawl2019\_event }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(trawl2019\_event)}
\end{Highlighting}
\end{Shaded}

\textbf{TO DO: Add visual of e.g.~the top 10 rows of the Event Core.}

Now that we created the Event Core, we create the occurrence extension. To do this, we create two separate occurrence data tables: one that includes the occurrence data for the \emph{total} catch, and one data table for the \emph{specimen} data. Finally, the Occurrence extension is created by combining these two data frames. Personally, I prefer to re-order it so it makes visual sense to me (nest the specimen occurrence records under their respective overall catch data).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trawl2019\_allCatch\_worms }\OtherTok{\textless{}{-}}\NormalTok{ worrms}\SpecialCharTok{::}\FunctionTok{wm\_records\_names}\NormalTok{(}\FunctionTok{unique}\NormalTok{(trawl2019\_allCatch}\SpecialCharTok{$}\NormalTok{scientificname))}
\NormalTok{trawl2019\_occ }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(trawl2019\_allCatch, trawl2019\_allCatch\_worms, }\AttributeTok{by =} \StringTok{"scientificname"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{eventID =}\NormalTok{ trawl,}
         \AttributeTok{specificEpithet =}\NormalTok{ species,}
         \AttributeTok{scientificNameAuthorship =}\NormalTok{ authority,}
         \AttributeTok{taxonomicStatus =}\NormalTok{ status,}
         \AttributeTok{taxonRank =}\NormalTok{ rank,}
         \AttributeTok{scientificName =}\NormalTok{ scientificname,}
         \AttributeTok{scientificNameID =}\NormalTok{ lsid,}
         \AttributeTok{individualCount =} \StringTok{\textasciigrave{}}\AttributeTok{CATCH\_COUNT (pieces)(**includes Russian expansion for some species)}\StringTok{\textasciigrave{}}\NormalTok{,}
         \AttributeTok{occurrenceRemarks =}\NormalTok{ COMMENTS) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{occurrenceID =} \FunctionTok{paste}\NormalTok{(eventID, }\StringTok{"occ"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{occurrenceID =} \FunctionTok{paste}\NormalTok{(occurrenceID, }\FunctionTok{row\_number}\NormalTok{(), }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{occurrenceStatus =} \StringTok{"present"}\NormalTok{,}
         \AttributeTok{sex =} \StringTok{""}\NormalTok{)}

\NormalTok{trawl2019\_catch\_ind\_worms }\OtherTok{\textless{}{-}}\NormalTok{ worrms}\SpecialCharTok{::}\FunctionTok{wm\_records\_names}\NormalTok{(}\FunctionTok{unique}\NormalTok{(trawl2019\_catch\_ind}\SpecialCharTok{$}\NormalTok{scientificname)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_rows}\NormalTok{()}
\NormalTok{trawl2019\_catch\_ind\_occ }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(trawl2019\_catch\_ind, trawl2019\_catch\_ind\_worms, }\AttributeTok{by =} \StringTok{"scientificname"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{scientificNameAuthorship =}\NormalTok{ authority,}
         \AttributeTok{taxonomicStatus =}\NormalTok{ status,}
         \AttributeTok{taxonRank =}\NormalTok{ rank,}
         \AttributeTok{scientificName =}\NormalTok{ scientificname,}
         \AttributeTok{scientificNameID =}\NormalTok{ lsid) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{occurrenceID =} \FunctionTok{paste}\NormalTok{(eventID, }\StringTok{"occ"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{occurrenceStatus =} \StringTok{"present"}\NormalTok{,}
         \AttributeTok{individualCount =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# Combine the two occurrence data frames:}
\NormalTok{trawl2019\_occ\_ext }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{bind\_rows}\NormalTok{(trawl2019\_occ\_fnl, trawl2019\_catch\_ind\_fnl)}

\CommentTok{\# To re{-}order the occurrenceID, use following code:}
\NormalTok{order }\OtherTok{\textless{}{-}}\NormalTok{ stringr}\SpecialCharTok{::}\FunctionTok{str\_sort}\NormalTok{(trawl2019\_occ\_ext}\SpecialCharTok{$}\NormalTok{occurrenceID, }\AttributeTok{numeric=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{trawl2019\_occ\_ext }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019\_occ\_ext[}\FunctionTok{match}\NormalTok{(order, trawl2019\_occ\_ext}\SpecialCharTok{$}\NormalTok{occurrenceID),] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{basisOfRecord =} \StringTok{"HumanObservation"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{TO DO: Add visual of e.g.~the top 10 rows of the Occurrence extension.}

\textbf{Please note} that in the \emph{overall} species-specific occurrence data frame, \emph{individualCount} was not included. This term should not be used for abundance studies, but to avoid confusion and the appearance that the specimen records are an additional observation on top of the overall catch record, the \emph{individualCount} term was left blank for the overall catch data.

A resource relationship extension is created to further highlight that the individual samples in the occurrence extension are part of a larger overall catch that was also listed in the occurrence extension. In this extension, we wanted to make sure to highlight that the \emph{specimen} occurrence records are \emph{a subset of} the \emph{overall} catch data through the field \texttt{relationshipOfResource1}. Each of these relationships gets a unique \texttt{resourceRelationshipID}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trawl\_resourceRelationship }\OtherTok{\textless{}{-}}\NormalTok{ trawl2019\_occ\_ext }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(eventID, occurrenceID, scientificName) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{resourceID =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{grepl}\NormalTok{(}\StringTok{"sample"}\NormalTok{, trawl2019\_occ\_ext}\SpecialCharTok{$}\NormalTok{occurrenceID), trawl2019\_occ\_ext}\SpecialCharTok{$}\NormalTok{occurrenceID, }\ConstantTok{NA}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{eventID =} \FunctionTok{gsub}\NormalTok{(}\StringTok{":sample.*"}\NormalTok{, }\StringTok{""}\NormalTok{, trawl2019\_occ\_ext}\SpecialCharTok{$}\NormalTok{eventID)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(eventID, scientificName) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{n}\NormalTok{() }\SpecialCharTok{!=} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\NormalTok{trawl\_resourceRelationship }\OtherTok{\textless{}{-}}\NormalTok{ trawl\_resourceRelationship }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{relatedResourceID =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{grepl}\NormalTok{(}\StringTok{"sample"}\NormalTok{, trawl\_resourceRelationship}\SpecialCharTok{$}\NormalTok{occurrenceID), }\ConstantTok{NA}\NormalTok{, trawl\_resourceRelationship}\SpecialCharTok{$}\NormalTok{occurrenceID)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{relationshipOfResource =} \FunctionTok{ifelse}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(resourceID), }\StringTok{"is a subset of"}\NormalTok{, }\ConstantTok{NA}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(eventID, scientificName) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fill}\NormalTok{(relatedResourceID) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(resourceID))}

\NormalTok{order }\OtherTok{\textless{}{-}}\NormalTok{ stringr}\SpecialCharTok{::}\FunctionTok{str\_sort}\NormalTok{(trawl\_resourceRelationship}\SpecialCharTok{$}\NormalTok{resourceID, }\AttributeTok{numeric =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{trawl\_resourceRelationship }\OtherTok{\textless{}{-}}\NormalTok{ trawl\_resourceRelationship[}\FunctionTok{match}\NormalTok{(order, trawl\_resourceRelationship}\SpecialCharTok{$}\NormalTok{resourceID),]}

\NormalTok{trawl\_resourceRelationship }\OtherTok{\textless{}{-}}\NormalTok{ trawl\_resourceRelationship }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{resourceRelationshipID =} \FunctionTok{paste}\NormalTok{(relatedResourceID, }\StringTok{"rr"}\NormalTok{, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{),}
         \AttributeTok{ID =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%03d"}\NormalTok{, }\FunctionTok{row\_number}\NormalTok{()),}
         \AttributeTok{resourceRelationshipID =} \FunctionTok{paste}\NormalTok{(resourceRelationshipID, ID, }\AttributeTok{sep =} \StringTok{":"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(eventID, resourceRelationshipID, resourceID, relationshipOfResource, relatedResourceID)}
\end{Highlighting}
\end{Shaded}

\textbf{TO DO: Add visual of e.g.~the top 10 rows of the ResourceRelationship extension.}

\hypertarget{faq}{%
\subsection{FAQ}\label{faq}}

\textbf{Q1}. Why not use the terms \emph{associatedOccurrence} or \emph{associatedTaxa}?
\textbf{A}. There seems to be a movement away from the term \emph{associatedOccurrence} as the \texttt{resourceRelationship} extension has a much broader use case. Some issues that were raised on GitHub exemplify this, see e.g.~\href{https://github.com/tdwg/dwc/issues/324}{here}. \emph{associatedTaxa} is used to provide identifiers or names of taxa and the associations of an Occurrence with them. This term is not apt for establishing relationships between taxa, only between specific Occurrences of an organism with other taxa. As noted on the \href{https://dwc.tdwg.org/terms/\#dwc:associatedTaxa}{TDWG website}, \emph{{[}\ldots{]} Note that the ResourceRelationship class is an alternative means of representing associations, and with more detail.} See also e.g.~\href{https://github.com/tdwg/dwc/issues/331}{this issue}.

\hypertarget{dataset-edna}{%
\section{dataset-edna}\label{dataset-edna}}

By \href{https://github.com/dianalg}{Diana LaScala-Gruenewald}

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

\textbf{Rationale:}

DNA derived data are increasingly being used to document taxon
occurrences. To ensure these data are useful to the broadest possible
community, \href{https://www.gbif.org/}{GBIF} published a guide entitled ``\href{https://docs.gbif-uat.org/publishing-dna-derived-data/1.0/en/}{Publishing DNA-derived
data through biodiversity data platforms}.''
This guide is supported by the \href{https://tools.gbif.org/dwca-validator/extension.do?id=http://rs.gbif.org/terms/1.0/DNADerivedData}{DNA derived data extension}
for \href{https://dwc.tdwg.org/}{Darwin Core}, which incorporates \href{https://gensc.org/mixs/}{MIxS}
terms into the Darwin Core standard.

This use case draws on both the guide and the extension to illustrate
how to incorporate a DNA derived data extension file into a Darwin Core
archive.

For further information on this use case and the DNA Derived data extension
in general, see the recording of the \href{https://obis.org/2021/10/13/gendatawebinar/}{OBIS Webinar on Genetic Data}.

\textbf{Project abstract:}

The example data employed in this use case are from marine
filtered seawater samples collected at a nearshore station in
Monterey Bay, California, USA. They were collected by CTD
rosette and filtered by a peristaltic pump system. Subsequently,
they underwent metabarcoding for the 18S V9 region. The resulting
ASVs, their assigned taxonomy, and the metadata associated with their
collection are the input data for the conversion scripts
presented here.

A selection of samples from this collection were included in the
publication ``\href{https://www.nature.com/articles/s41467-019-14105-1}{Environmental DNA reveals seasonal shifts and potential
interactions in a marine community}''
which was published with open access in \emph{Nature Communications} in 2020.

\textbf{Contacts:}
- Francisco Chavez - Principle Investigator (\url{chfr@mbari.org})
- Kathleen Pitz - Research Associate (\url{kpitz@mbari.org})
- Diana LaScala-Gruenewald - Point of Contact (\url{dianalg@mbari.org})

\hypertarget{published-data}{%
\subsection{Published data}\label{published-data}}

\begin{itemize}
\tightlist
\item
  \href{https://www.gbif.org/dataset/e0b59ee7-19ae-4eb0-9217-33317fb50d47}{GBIF}
\item
  \href{https://obis.org/dataset/62b97724-da17-4ca7-9b26-b2a22aeaab51}{OBIS}
\end{itemize}

\hypertarget{repo-structure}{%
\subsection{Repo structure}\label{repo-structure}}

\begin{verbatim}
.
+-- README.md                   :Description of this repository
+-- LICENSE                     :Repository license
+-- .gitignore                  :Files and directories to be ignored by git
|
+-- raw
|   +-- asv_table.csv           :Source data containing ASV sequences and number of reads
|   +-- taxa_table.csv          :Source data containing taxon matches for each ASV
|   +-- metadata_table.csv      :Source data containing metadata about samples (e.g. collection information)
|
+-- src
|   +-- conversion_code.py      :Darwin Core mapping script
|   +-- conversion_code.ipynb   :Darwin Core mapping Jupyter Notebook
|   +-- WoRMS.py                :Functions for querying the World Register of Marine Species
|
+-- processed
|   +-- occurrence.csv          :Occurrence file, generated by conversion_code
|   +-- dna_extension.csv       :DNA Derived Data Extension file, generated by conversion_code
\end{verbatim}

\hypertarget{converting-atn-netcdf-file-to-dawrin-core}{%
\section{Converting ATN netCDF file to Dawrin Core}\label{converting-atn-netcdf-file-to-dawrin-core}}

Created: 2022-03-23
Updated: 2023-11-16

Credit: Stephen Formel, Mathew Biddle

This notebook walks through downloading an example netCDF file from the an Archive package at NCEI and translating it to a Darwin Core Archive compliant package for easy loading and publishing via the Integrated Publishing Toolkit (IPT). The example file follows a specific specification for ATN satellite trajectory observations as documented \href{https://github.com/ioos/ioos-atn-data/blob/main/templates/atn_trajectory_template.cdl}{here}. More information about the ATN netCDF specification can be found in the repository \url{https://github.com/ioos/ioos-atn-data}.

This example uses the \href{https://ropensci.org/blog/2019/11/05/tidync/}{tidync} package to work with netCDF data.

Data used in this notebook are available from NCEI at the following link \url{https://www.ncei.noaa.gov/archive/accession/0282699}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Load libraries}

\FunctionTok{library}\NormalTok{(tidync)}
\FunctionTok{library}\NormalTok{(obistools)}
\FunctionTok{library}\NormalTok{(ncdf4)}
\FunctionTok{library}\NormalTok{(tidyverse) }\CommentTok{\#includes stringr}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(maps)}
\FunctionTok{library}\NormalTok{(mapdata)}
\end{Highlighting}
\end{Shaded}

\hypertarget{downloading-and-preprocessing-the-source-data}{%
\subsection{Downloading and preprocessing the source data}\label{downloading-and-preprocessing-the-source-data}}

See \url{https://www.ncei.noaa.gov/archive/accession/0282699}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{=} \StringTok{\textquotesingle{}https://www.nodc.noaa.gov/archive/arc0217/0282699/1.1/data/0{-}data/atn\_45866\_great{-}white{-}shark\_trajectory\_20090923{-}20091123.nc\textquotesingle{}}

\CommentTok{\#fname = str\_split\_i(url, "/", i={-}1)}
\NormalTok{fname }\OtherTok{=} \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}data/src/\textquotesingle{}}\NormalTok{,}\FunctionTok{basename}\NormalTok{(url))}

\FunctionTok{download.file}\NormalTok{(url, fname, }\AttributeTok{mode =} \StringTok{"wb"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{open-the-netcdf-file}{%
\subsubsection{Open the netCDF file}\label{open-the-netcdf-file}}

Once the file is opened, we print out the details of what the netCDF file contains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atn }\OtherTok{\textless{}{-}} \FunctionTok{nc\_open}\NormalTok{(fname)}
\NormalTok{atn}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## File data/src/ atn_45866_great-white-shark_trajectory_20090923-20091123.nc (NC_FORMAT_NETCDF4):
## 
##      36 variables (excluding dimension variables):
##         string deploy_id[]   (Contiguous storage)  
##             long_name: id for this deployment. This is typically the tag ptt
##             comment: Friendly name given to the tag by the user. If no specific friendly name is given, this is the PTT id.
##             coordinates: time z lon lat
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: referenceInformation
##             _FillValue: -9999
##         double time[obs]   (Contiguous storage)  
##             units: seconds since 1990-01-01 00:00:00Z
##             standard_name: time
##             axis: T
##             _CoordinateAxisType: Time
##             calendar: standard
##             long_name: Time of the measurement, in seconds since 1990-01-01
##             actual_min: 2009-09-23T00:00:00Z
##             actual_max: 2009-11-23T05:12:00Z
##             ancillary_variables: qartod_time_flag qartod_rollup_flag qartod_speed_flag
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: coordinate
##             _FillValue: NaN
##         int z[obs]   (Contiguous storage)  
##             _FillValue: -9999
##             axis: Z
##             long_name: depth of measurement
##             positive: down
##             standard_name: depth
##             units: m
##             actual_min: 0
##             actual_max: 0
##             instrument: 
##             platform: animal
##             comment: This variable is synthetically generated to represent the depth of observations
##             coverage_content_type: coordinate
##         double lat[obs]   (Contiguous storage)  
##             axis: Y
##             _CoordinateAxisType: Lat
##             long_name: Latitude portion of location in decimal degrees North
##             standard_name: latitude
##             units: degrees_north
##             valid_max: 90
##             valid_min: -90
##             actual_min: 23.59
##             actual_max: 34.045
##             ancillary_variables: qartod_location_flag qartod_rollup_flag qartod_speed_flag error_radius semi_major_axis semi_minor_axis ellipse_orientation offset offset_orientation
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: coordinate
##             _FillValue: NaN
##         double lon[obs]   (Contiguous storage)  
##             axis: X
##             _CoordinateAxisType: Lon
##             long_name: Longitude portion of location in decimal degrees East
##             standard_name: longitude
##             units: degrees_east
##             valid_max: 180
##             valid_min: -180
##             actual_min: -166.18
##             actual_max: -118.504
##             ancillary_variables: qartod_location_flag qartod_rollup_flag qartod_speed_flag error_radius semi_major_axis semi_minor_axis ellipse_orientation offset offset_orientation
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: coordinate
##             _FillValue: NaN
##         int ptt[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Platform Transmitter Terminal (PTT) id used for Argos transmissions
##             comment: PTT id for this deployment. PTT ids may be used on multiple deployments, but not concurrently. When combined with deployment dates, PTTs can uniquely identify a deployment.
##             coverage_content_type: referenceInformation
##             instrument: instrument_location
##             platform: animal
##         string instrument[obs]   (Contiguous storage)  
##             coordinates: time z lon lat
##             comment: Wildlife Computers instrument family. Variable may report manufacturer default values (e.g., Mk10) and may not match correctly defined instrument_location or instrument_tag variables and attributes.
##             long_name: Instrument family
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: referenceInformation
##         string type[obs]   (Contiguous storage)  
##             coordinates: time z lon lat
##             comment: Type of location: Argos, FastGPS or User
##             long_name: Type of location information - Argos, GPS satellite or user provided location
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: referenceInformation
##         string location_class[obs]   (Contiguous storage)  
##             coordinates: time z lon lat
##             standard_name: quality_flag
##             comment: Quality codes from the ARGOS satellite (in meters): G,3,2,1,0,A,B,Z. See http://www.argos-system.org/manual/3-location/34_location_classes.htm
##             long_name: Location Quality Code from ARGOS satellite system
##             code_values: G,3,2,1,0,A,B,Z
##             code_meanings: estimated error less than 100m and 1+ messages received per satellite pass, estimated error less than 250m and 4+ messages received per satellite pass, estimated error between 250m and 500m and 4+ messages per satellite pass, estimated error between 500m and 1500m and 4+ messages per satellite pass, estimated error greater than 1500m and 4+ messages received per satellite pass, no least squares estimated error or unbounded kalman filter estimated error and 3 messages received per satellite pass, no least squares estimated error or unbounded kalman filter estimated error and 1 or 2 messages received per satellite pass, invalid location (available for Service Plus or Auxilliary Location Processing)
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon
##             coverage_content_type: qualityInformation
##         int error_radius[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error radius
##             units: m
##             comment: If the position is best represented as a circle, this field gives the radius of that circle in meters.
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon offset offset_orientation
##             coverage_content_type: qualityInformation
##         int semi_major_axis[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error - ellipse semi-major axis
##             units: m
##             comment: If the estimated position error is best expressed as an ellipse, this field gives the length in meters of the semi-major elliptical axis (one half of the major axis).
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon ellipse_orientation offset offset_orientation
##             coverage_content_type: qualityInformation
##         int semi_minor_axis[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error - ellipse semi-minor axis
##             units: m
##             comment: If the estimated position error is best expressed as an ellipse, this field gives the length in meters of the semi-minor elliptical axis (one half of the minor axis).
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon ellipse_orientation offset offset_orientation
##             coverage_content_type: qualityInformation
##         int ellipse_orientation[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error - ellipse orientation in degrees clockwise from true north
##             units: degrees
##             comment: The angle in degrees of the ellipse from true north, proceeding clockwise (0 to 360). A blank field represents 0 degrees.
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon semi_major_axis semi_minor_axis offset offset_orientation
##             coverage_content_type: qualityInformation
##         int offset[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error - offset in meters to center of error ellipse or circle
##             units: m
##             comment: This field is non-zero if the circle or ellipse are not centered on the (Latitude, Longitude) values on this row. "Offset" gives the distance in meters from (Latitude, Longitude) to the center of the ellipse.
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon error_radius semi_major_axis semi_minor_axis offset_orientation
##             coverage_content_type: qualityInformation
##         int offset_orientation[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             long_name: Error - offset orientation angle to ellipse center
##             units: degrees
##             comment: If the "Offset" field is non-zero, this field is the angle in degrees from (Latitude, Longitude) to the center of the ellipse. Zero degrees is true north; a blank field represents 0 degrees.
##             instrument: instrument_location
##             platform: animal
##             ancillary_variables: lat lon error_radius semi_major_axis semi_minor_axis offset
##             coverage_content_type: qualityInformation
##         double gpe_msd[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             coordinates: time z lon lat
##             comment: Historical. No longer applicable.
##             long_name: 
##             units: 
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: auxillaryInformation
##             _FillValue: NaN
##         double gpe_u[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             coordinates: time z lon lat
##             comment: Historical. No longer applicable.
##             long_name: 
##             units: 
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: auxillaryInformation
##             _FillValue: NaN
##         int count[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: -9999
##             coordinates: time z lon lat
##             comment: Total number of times a particular data item was received, verified, and successfully decoded.
##             long_name: Count
##             units: count
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: auxillaryInformation
##         unsigned byte qartod_time_flag[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: 241
##             coordinates: time z lon lat
##             standard_name: gross_range_test_quality_flag
##             long_name: Time QC test - gross range test
##             implementation: https://github.com/ioos/ioos_qc/
##             flag_meanings: PASS NOT_EVALUATED SUSPECT FAIL MISSING
##             flag_values: 1
##              flag_values: 2
##              flag_values: 3
##              flag_values: 4
##              flag_values: 9
##             references: https://cdn.ioos.noaa.gov/media/2020/03/QARTOD_TS_Manual_Update2_200324_final.pdf
##             coverage_content_type: qualityInformation
##         unsigned byte qartod_speed_flag[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: 241
##             coordinates: time z lon lat
##             standard_name: gross_range_test_quality_flag
##             long_name: Speed QC test - gross range test
##             references: https://cdn.ioos.noaa.gov/media/2020/03/QARTOD_TS_Manual_Update2_200324_final.pdf
##             implementation: https://github.com/ioos/ioos_qc/
##             flag_meanings: PASS NOT_EVALUATED SUSPECT FAIL MISSING
##             flag_values: 1
##              flag_values: 2
##              flag_values: 3
##              flag_values: 4
##              flag_values: 9
##             coverage_content_type: qualityInformation
##         unsigned byte qartod_location_flag[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: 241
##             coordinates: time z lon lat
##             standard_name: location_test_quality_flag
##             long_name: Location QC test - Location test
##             implementation: https://github.com/ioos/ioos_qc/
##             flag_meanings: PASS NOT_EVALUATED SUSPECT FAIL MISSING
##             flag_values: 1
##              flag_values: 2
##              flag_values: 3
##              flag_values: 4
##              flag_values: 9
##             references: https://cdn.ioos.noaa.gov/media/2020/03/QARTOD_TS_Manual_Update2_200324_final.pdf
##             coverage_content_type: qualityInformation
##         unsigned byte qartod_rollup_flag[obs]   (Chunking: [29])  (Compression: shuffle,level 1)
##             _FillValue: 241
##             coordinates: time z lon lat
##             standard_name: aggregate_quality_flag
##             long_name: Aggregate QC value
##             implementation: https://github.com/ioos/ioos_qc/
##             flag_meanings: PASS NOT_EVALUATED SUSPECT FAIL MISSING
##             flag_values: 1
##              flag_values: 2
##              flag_values: 3
##              flag_values: 4
##              flag_values: 9
##             references: https://cdn.ioos.noaa.gov/media/2020/03/QARTOD_TS_Manual_Update2_200324_final.pdf
##             coverage_content_type: qualityInformation
##         int crs[]   (Contiguous storage)  
##             epsg_code: EPSG:4326
##             grid_mapping_name: latitude_longitude
##             inverse_flattening: 298.257223563
##             long_name: Coordinate Reference System - http://www.opengis.net/def/crs/EPSG/0/4326
##             semi_major_axis: 6378137
##             coverage_content_type: referenceInformation
##         string trajectory[]   (Contiguous storage)  
##             cf_role: trajectory_id
##             long_name: trajectory identifier
##         int animal_age[]   (Contiguous storage)  
##             _FillValue: -9999
##             units: 
##             long_name: age of the animal as measured or estimated at deployment
##             coverage_content_type: referenceInformation
##             animal_age: Not provided
##         string animal_life_stage[]   (Contiguous storage)  
##             animal_life_stage: juvenile
##             long_name: Lifestage of the animal at time of deployment 
##             coverage_content_type: referenceInformation
##         string animal_sex[]   (Contiguous storage)  
##             animal_sex: male
##             long_name: sex of the animal at time of tag deployment
##             coverage_content_type: referenceInformation
##         float animal_weight[]   (Contiguous storage)  
##             _FillValue: NaN
##             units: kg
##             long_name: mass of the animal as measured or estimated at deployment
##             animal_weight: Not provided
##             coverage_content_type: referenceInformation
##         float animal_length[]   (Contiguous storage)  
##             _FillValue: NaN
##             animal_length_type: total length
##             units: cm
##             animal_length: 213.0 (cm) total length
##             long_name: length of the animal as measured or estimated at deployment
##             coverage_content_type: referenceInformation
##         float animal_length_2[]   (Contiguous storage)  
##             _FillValue: NaN
##             animal_length_2_type: Not provided
##             units: 
##             animal_length_2: Not provided
##             long_name: length of the animal as measured or estimated at deployment
##             coverage_content_type: referenceInformation
##         string animal[]   (Contiguous storage)  
##             rank: Species
##             infraorder: 
##             scientificname: Carcharodon carcharias
##             long_name: tagged animal id
##             superdomain: Biota
##             order: Lamniformes
##             authority: (Linnaeus, 1758)
##             kingdom: Animalia
##             species: Carcharodon carcharias
##             genus: Carcharodon
##             megaclass: 
##             family: Lamnidae
##             taxonRankID: 220
##             class: Elasmobranchii
##             cf_role: trajectory_id
##             coverage_content_type: referenceInformation
##             subphylum: Vertebrata
##             phylum: Chordata
##             AphiaID: 105838
##             valid_name: Carcharodon carcharias
##             infraphylum: Gnathostomata
##             subclass: Neoselachii
##             suborder: 
##         string instrument_tag[]   (Contiguous storage)  
##             manufacturer: Wildlife Computers
##             make_model: SPOT5
##             serial_number: 07S0230
##             long_name: telemetry tag applied to animal
##             coverage_content_type: referenceInformation
##             calibration_date: Not Provided
##         string instrument_location[]   (Contiguous storage)  
##             manufacturer: Wildlife Computers
##             make_model: SPOT5
##             serial_number: 07S0230
##             long_name: Wildlife Computers SPOT5
##             location_type: argos / modeled
##             comment: Location
##             coverage_content_type: referenceInformation
##             calibration_date: Not Provided
##         string taxon_name[]   (Contiguous storage)  
##             standard_name: biological_taxon_name
##             long_name: most precise taxonomic classification for the tagged animal
##             coverage_content_type: referenceInformation
##             source: Froese, R. and D. Pauly. Editors. (2023). FishBase. Carcharodon carcharias (Linnaeus, 1758). Accessed through: World Register of Marine Species at: https://www.marinespecies.org/aphia.php?p=taxdetails&id=105838 on 2023-08-16
##             url: https://www.marinespecies.org/aphia.php?p=taxdetails&id=105838
##         string taxon_lsid[]   (Contiguous storage)  
##             standard_name: biological_taxon_lsid
##             long_name: Namespaced Taxon Identifier for the tagged animal
##             coverage_content_type: referenceInformation
##             source: Froese, R. and D. Pauly. Editors. (2023). FishBase. Carcharodon carcharias (Linnaeus, 1758). Accessed through: World Register of Marine Species at: https://www.marinespecies.org/aphia.php?p=taxdetails&id=105838 on 2023-08-16
##             url: https://www.marinespecies.org/aphia.php?p=taxdetails&id=105838
##         string comment[obs]   (Contiguous storage)  
##             long_name: Comment
##             comment: Optional text field
##             coordinates: time z lon lat
##             instrument: instrument_location
##             platform: animal
##             coverage_content_type: auxillaryInformation
## 
##      1 dimensions:
##         obs  Size:29 (no dimvar)
## 
##     89 global attributes:
##         date_created: 2023-08-16T20:00:00Z
##         featureType: trajectory
##         cdm_data_type: Trajectory
##         Conventions: CF-1.10, ACDD-1.3, IOOS-1.2
##         argos_program_number: 2414
##         creator_email: chris.lowe@csulb.edu
##         id: 5f0668a86321be13bc7ef628
##         tag_type: SPOT5
##         source: Service Argos
##         acknowledgement: NOAA IOOS, Axiom Data Science, Navy ONR, NOAA NMFS, Wildlife Computers, Argos, IOOS ATN
##         creator_name: Chris G. Lowe
##         creator_url: 
##         geospatial_lat_units: degrees_north
##         geospatial_lon_units: degrees_east
##         infoUrl: https://portal.atn.ioos.us/#metadata/6e2ba85c-2f61-4bc5-8c2b-34d6734155ed/project
##         institution: California State University Long Beach
##         keywords: EARTH SCIENCE > AGRICULTURE > ANIMAL SCIENCE > ANIMAL ECOLOGY AND BEHAVIOR, EARTH SCIENCE > BIOSPHERE > ECOLOGICAL DYNAMICS > SPECIES/POPULATION INTERACTIONS > MIGRATORY RATES/ROUTES, EARTH SCIENCE > OCEANS, EARTH SCIENCE > CLIMATE INDICATORS > BIOSPHERIC INDICATORS > SPECIES MIGRATION, EARTH SCIENCE > OCEANS, EARTH SCIENCE > BIOLOGICAL CLASSIFICATION > ANIMALS/VERTEBRATES, EARTH SCIENCE > BIOSPHERE > ECOSYSTEMS > MARINE ECOSYSTEMS, PROVIDERS > GOVERNMENT AGENCIES-U.S. FEDERAL AGENCIES > DOC > NOAA > IOOS, PROVIDERS > COMMERCIAL > Axiom Data Science
##         license: These data may be used and redistributed for free, but are not intended for legal use, since they may contain inaccuracies. No person or group associated with these data makes any warranty, expressed or implied, including warranties of merchantability and fitness for a particular purpose, or assumes any legal liability for the accuracy, completeness or usefulness of this information. This disclaimer applies to both individual use of these data and aggregate use with other data. It is strongly recommended that users read and fully comprehend associated metadata prior to use. Please acknowledge the U.S. Animal Telemetry Network (ATN) or the specified citation as the source from which these data were obtained in any publications and/or representations of these data. Communication and collaboration with dataset authors are strongly encouraged.
##         metadata_link: 
##         naming_authority: com.wildlifecomputers
##         platform_category: animal
##         platform: fish
##         platform_vocabulary: https://vocab.nerc.ac.uk/collection/L06/current/
##         processing_level: NetCDF file created from position data obtained from Wildlife Computers API.
##         project: Project White Shark: Juvenile Satellite Biotelemetry, 2001-2020
##         publisher_email: atndata@ioos.us
##         publisher_institution: US Integrated Ocean Observing System Office
##         publisher_name: US Integrated Ocean Observing System (IOOS) Animal Telemetry Network (ATN)
##         publisher_url: https://atn.ioos.us
##         publisher_country: USA
##         standard_name_vocabulary: CF-v78
##         vendor: Wildlife Computers
##         geospatial_lat_min: 23.59
##         geospatial_lat_max: 34.045
##         geospatial_lon_min: -166.18
##         geospatial_lon_max: -118.504
##         geospatial_bbox: POLYGON ((-118.504 23.59, -118.504 34.045, -166.18 34.045, -166.18 23.59, -118.504 23.59))
##         geospatial_bounds: POLYGON ((-166.18 23.59, -118.581 34.038, -118.53 34.045, -118.504 33.989, -118.534 33.972, -119.75 33.517, -166.18 23.59))
##         geospatial_bounds_crs: EPSG:4326
##         time_coverage_start: 2009-09-23T00:00:00Z
##         time_coverage_end: 2009-11-23T05:12:00Z
##         time_coverage_duration: P61DT5H12M0S
##         time_coverage_resolution: P2DT2H39M43S
##         date_issued: 2023-08-16T20:00:00Z
##         date_modified: 2023-08-16T20:00:00Z
##         history: 2023-08-07T20:24:04Z - Created by the IOOS ATN DAC from the Wildlife Computers API
##         summary: Wildlife Computers SPOT5 tag (ptt id 45866) deployed on a great white shark (Carcharodon carcharias) by Chris G. Lowe in the North Pacific Ocean from 2009-09-23 to 2009-11-23
##         title: Great white shark (Carcharodon carcharias) location data from a satellite telemetry tag (ptt id 45866) deployed in the North Pacific Ocean from 2009-09-23 to 2009-11-23, deployment id 5f0668a86321be13bc7ef628
##         uuid: ff554ebf-bf4b-5a82-8a90-9c0ceb799d96
##         platform_name: Carcharodon carcharias
##         platform_id: 105838
##         vendor_id: 5f0668a86321be13bc7ef628
##         sea_name: North Pacific Ocean
##         arbitrary_keywords: ATN, Animal Telemetry Network, IOOS, Integrated Ocean Observing System, trajectory, satellite telemetry tag
##         contributor_role_vocabulary: https://vocab.nerc.ac.uk/collection/G04/current/
##         creator_role_vocabulary: https://vocab.nerc.ac.uk/collection/G04/current/
##         creator_sector_vocabulary: https://mmisw.org/ont/ioos/sector
##         creator_type: person
##         date_metadata_modified: 20230816
##         instrument: Satellite telemetry tag
##         instrument_vocabulary: 
##         keywords_vocabulary: GCMD Science Keywords v15.1
##         ncei_template_version: NCEI_NetCDF_Trajectory_Template_v2.0
##         product_version: 
##         program: IOOS Animal Telemetry Network
##         publisher_type: institution
##         references: 
##         animal_common_name: great white shark
##         animal_id: 09_13
##         animal_scientific_name: Carcharodon carcharias
##         deployment_id: 5f0668a86321be13bc7ef628
##         deployment_start_datetime: 2009-09-23T00:00:00Z
##         deployment_end_datetime: 2009-11-23T00:00:00Z
##         wmo_platform_code: 
##         comment: 09_13-45866
##         ptt_id: 45866
##         deployment_start_lat: 34.03
##         deployment_start_lon: -118.56
##         contributor_name: Thomas Farrugia
##         contributor_email: tjfarrugia@alaska.edu
##         contributor_role: collaborator
##         contributor_institution: California State University Long Beach
##         contributor_url: 
##         creator_role: principalInvestigator
##         creator_sector: academic
##         creator_country: USA
##         creator_institution: California State University Long Beach
##         creator_institution_url: https://www.csulb.edu/shark-lab
##         citation: Lowe, Chris G.; Farrugia, Thomas. (2023) great white shark (Carcharodon carcharias) location data from a satellite telemetry tag (ptt id 45866) deployed in the North Pacific Ocean from 2009-09-23 to 2009-11-23, deployment id 5f0668a86321be13bc7ef628. [Dataset]. US Integrated Ocean Observing System Office.
\end{verbatim}

\hypertarget{collect-all-the-metadata-from-the-netcdf-file.}{%
\subsubsection{Collect all the metadata from the netCDF file.}\label{collect-all-the-metadata-from-the-netcdf-file.}}

This gathers not only the global attributes, but the variable level attributes as well. As you can see in the \textbf{variable} column the term \texttt{NC\_GLOBAL} refers to global attributes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{metadata }\OtherTok{\textless{}{-}}\NormalTok{ ncmeta}\SpecialCharTok{::}\FunctionTok{nc\_atts}\NormalTok{(fname)}
\NormalTok{metadata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 381 x 4
##       id name                  variable  value       
##    <int> <chr>                 <chr>     <named list>
##  1     0 long_name             deploy_id <chr [1]>   
##  2     1 comment               deploy_id <chr [1]>   
##  3     2 coordinates           deploy_id <chr [1]>   
##  4     3 instrument            deploy_id <chr [1]>   
##  5     4 platform              deploy_id <chr [1]>   
##  6     5 coverage_content_type deploy_id <chr [1]>   
##  7     6 _FillValue            deploy_id <dbl [1]>   
##  8     0 units                 time      <chr [1]>   
##  9     1 standard_name         time      <chr [1]>   
## 10     2 axis                  time      <chr [1]>   
## # i 371 more rows
\end{verbatim}

\hypertarget{store-the-data-as-a-tibble}{%
\subsubsection{Store the data as a tibble}\label{store-the-data-as-a-tibble}}

Collect the data dimensioned by \texttt{time} from the netCDF file as a tibble. Then, print the first ten rows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atn }\OtherTok{\textless{}{-}} \FunctionTok{tidync}\NormalTok{(fname)}

\NormalTok{atn\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ atn }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{hyper\_tibble}\NormalTok{(}\AttributeTok{force=}\ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{head}\NormalTok{(atn\_tbl, }\AttributeTok{n=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 23
##        time     z   lat   lon   ptt instrument type  location_class error_radius
##       <dbl> <int> <dbl> <dbl> <int> <chr>      <chr> <chr>                 <int>
## 1 622512000     0  34.0 -119. 45866 SPOT       User  nan                      NA
## 2 622708920     0  23.6 -166. 45866 SPOT       Argos A                        NA
## 3 622724940     0  34.0 -119. 45866 SPOT       Argos 1                        NA
## 4 622725060     0  34.0 -119. 45866 SPOT       Argos 0                        NA
## # i 14 more variables: semi_major_axis <int>, semi_minor_axis <int>,
## #   ellipse_orientation <int>, offset <int>, offset_orientation <int>,
## #   gpe_msd <dbl>, gpe_u <dbl>, count <int>, qartod_time_flag <int>,
## #   qartod_speed_flag <int>, qartod_location_flag <int>,
## #   qartod_rollup_flag <int>, comment <chr>, obs <int>
\end{verbatim}

\hypertarget{dealing-with-time}{%
\subsubsection{Dealing with time}\label{dealing-with-time}}

Notice the data in the \textbf{time} column aren't formatted as times. We need to read the metadata associated with the time variable to understand what the units are. Below, we print a tibble of all the attributes from the \textbf{time} variable.

Notice the \emph{units} attribute and it's value of \texttt{seconds\ since\ 1990-01-01\ 00:00:00Z}. We need to use that information to convert the time variable to something useful that \texttt{ggplot} can handle.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{time\_attrs }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"time"}\NormalTok{)}
\NormalTok{time\_attrs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 13 x 4
##       id name                  variable value       
##    <int> <chr>                 <chr>    <named list>
##  1     0 units                 time     <chr [1]>   
##  2     1 standard_name         time     <chr [1]>   
##  3     2 axis                  time     <chr [1]>   
##  4     3 _CoordinateAxisType   time     <chr [1]>   
##  5     4 calendar              time     <chr [1]>   
##  6     5 long_name             time     <chr [1]>   
##  7     6 actual_min            time     <chr [1]>   
##  8     7 actual_max            time     <chr [1]>   
##  9     8 ancillary_variables   time     <chr [1]>   
## 10     9 instrument            time     <chr [1]>   
## 11    10 platform              time     <chr [1]>   
## 12    11 coverage_content_type time     <chr [1]>   
## 13    12 _FillValue            time     <dbl [1]>
\end{verbatim}

So, we grab the value from the \texttt{units} attribute, split the string to collect the date information, and apply that to a time conversion function \texttt{as.POSIXct}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#library(stringr) {-} loaded with tidyverse}
\CommentTok{\# grab origin date from time variable units attribute}
\NormalTok{tunit }\OtherTok{\textless{}{-}}\NormalTok{ time\_attrs }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"units"}\NormalTok{)}
\NormalTok{lunit }\OtherTok{\textless{}{-}} \FunctionTok{str\_split}\NormalTok{(tunit}\SpecialCharTok{$}\NormalTok{value,}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)[[}\DecValTok{1}\NormalTok{]]}
\NormalTok{atn\_tbl}\SpecialCharTok{$}\NormalTok{time }\OtherTok{\textless{}{-}} \FunctionTok{as.POSIXct}\NormalTok{(atn\_tbl}\SpecialCharTok{$}\NormalTok{time, }\AttributeTok{origin=}\NormalTok{lunit[}\DecValTok{3}\NormalTok{], }\AttributeTok{tz=}\StringTok{"GMT"}\NormalTok{)}

\FunctionTok{str}\NormalTok{(atn\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [29 x 23] (S3: tbl_df/tbl/data.frame)
##  $ time                : POSIXct[1:29], format: "2009-09-23 00:00:00" "2009-09-25 06:42:00" ...
##  $ z                   : int [1:29] 0 0 0 0 0 0 0 0 0 0 ...
##  $ lat                 : num [1:29] 34 23.6 34 34 34 ...
##  $ lon                 : num [1:29] -119 -166 -119 -119 -119 ...
##  $ ptt                 : int [1:29] 45866 45866 45866 45866 45866 45866 45866 45866 45866 45866 ...
##  $ instrument          : chr [1:29] "SPOT" "SPOT" "SPOT" "SPOT" ...
##  $ type                : chr [1:29] "User" "Argos" "Argos" "Argos" ...
##  $ location_class      : chr [1:29] "nan" "A" "1" "0" ...
##  $ error_radius        : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ semi_major_axis     : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ semi_minor_axis     : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ ellipse_orientation : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ offset              : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ offset_orientation  : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ gpe_msd             : num [1:29] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
##  $ gpe_u               : num [1:29] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
##  $ count               : int [1:29] NA NA NA NA NA NA NA NA NA NA ...
##  $ qartod_time_flag    : int [1:29] 1 1 1 1 1 1 1 1 1 1 ...
##  $ qartod_speed_flag   : int [1:29] 2 4 4 4 1 1 1 1 1 1 ...
##  $ qartod_location_flag: int [1:29] 1 1 1 1 1 1 1 1 1 1 ...
##  $ qartod_rollup_flag  : int [1:29] 1 4 4 4 1 1 1 1 1 1 ...
##  $ comment             : chr [1:29] "" "" "" "" ...
##  $ obs                 : int [1:29] 1 2 3 4 5 6 7 8 9 10 ...
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{converting-to-darwin-core}{%
\subsection{Converting to Darwin Core}\label{converting-to-darwin-core}}

Now let's work through converting this netCDF file to Darwin Core. Following the guidance published at \url{https://github.com/tdwg/dwc-for-biologging/wiki/Data-guidelines} and \url{https://github.com/ocean-tracking-network/biologging_standardization/tree/master/examples/braun-blueshark/darwincore-example}

\hypertarget{occurrence-core}{%
\subsubsection{Occurrence Core}\label{occurrence-core}}

Below is the mapping table from DarwinCore to the netCDF file.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.42}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.21}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.37}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
DarwinCore Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Status
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
netCDF source
\end{minipage} \\
\midrule
\endhead
occurrenceStatus & Required & hardcoded to \texttt{present}. \\
basisOfRecord & Required & data contained in the \texttt{type} variable where \texttt{type} of \texttt{User} = \texttt{HumanObservation} and \texttt{Argos} = \texttt{MachineObservation}. \\
occurrenceID & Required & \texttt{eventDate}, plus data contained in \texttt{z} variable, plus \texttt{animal\_common\_name} global attribute. \\
organismID & Required & \texttt{platform\_id} global attribute plus the \texttt{animal\_common\_name} global attribute. \\
eventDate & Required & data contained in \texttt{time} variable. Converted to ISO8601. \\
decimalLatitude \& decimalLongitude & Required & data in \texttt{lat} and \texttt{lon} variable, respectively. \\
geodeticDatum & Required & attribute \texttt{epsg\_code} in the \texttt{crs} variable. \\
scientificName & Required & data from the variable \texttt{taxon\_name}. \\
scientificNameID & & data from the variable \texttt{taxon\_lsid}. \\
eventID & Strongly recommended & \texttt{animal\_common\_name} global attribute plus the \texttt{eventDate}. \\
samplingProtocol & Strongly recommended & \\
kingdom & Strongly recommended & \texttt{kingdom} attribute in the \texttt{animal} variable. \\
taxonRank & Strongly recommended & \texttt{rank} attribute in the \texttt{animal} variable. \\
coordinateUncertaintyInMeters & Share if available & maximum value of the data from the variables \texttt{error\_radius}, \texttt{semi\_major\_axis}, and \texttt{offset}. \\
lifeStage & Share if available & data from the variable \texttt{animal\_life\_stage}. \\
sex & Share if available & data from the variable \texttt{animal\_sex}. \\
\bottomrule
\end{longtable}

Now start working through the crosswalk. A few thoughts about some of the functions we use:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{case\_when} is a \href{https://dplyr.tidyverse.org/reference/case_when.html}{function from dplyr} that is essentially a `vectorized' ifelse function. The take-home is that it plays nice with other \texttt{tidyverse} functions, like \texttt{mutate} and IMO is a bit more readable than a complex ifelse statement.
\item
  \texttt{rename} is another nice dplyr function for renaming columns. It workes well following \texttt{mutate} because you can see the mutation applied to a column and then the column renamed, rather than a complex creation of a new column and dropping of the old column.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Defined to grab attributes in subsequent code}
\NormalTok{nc }\OtherTok{\textless{}{-}} \FunctionTok{nc\_open}\NormalTok{(fname)}

\NormalTok{occurrencedf }\OtherTok{\textless{}{-}}\NormalTok{ atn\_tbl }\SpecialCharTok{\%\textgreater{}\%}  
    \FunctionTok{select}\NormalTok{( }\CommentTok{\# Select desired columns}
        
\NormalTok{        time, }
\NormalTok{        lat,}
\NormalTok{        lon,}
\NormalTok{        type,}
\NormalTok{        location\_class,}
\NormalTok{        qartod\_time\_flag,}
\NormalTok{        qartod\_speed\_flag,}
\NormalTok{        qartod\_location\_flag,}
\NormalTok{        qartod\_rollup\_flag}
        
\NormalTok{          ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{( }\CommentTok{\# add and mutate columns.}
        
        \AttributeTok{type =} \FunctionTok{case\_when}\NormalTok{(type }\SpecialCharTok{==} \StringTok{\textquotesingle{}User\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textquotesingle{}HumanObservation\textquotesingle{}}\NormalTok{,}
\NormalTok{                         type }\SpecialCharTok{==} \StringTok{\textquotesingle{}Argos\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textquotesingle{}MachineObservation\textquotesingle{}}\NormalTok{),}
        
        \AttributeTok{time =} \FunctionTok{format}\NormalTok{(time, }\StringTok{\textquotesingle{}\%Y{-}\%m{-}\%dT\%H:\%M:\%SZ\textquotesingle{}}\NormalTok{),}
        
        \AttributeTok{kingdom =}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"animal"} \SpecialCharTok{\&}\NormalTok{ name }\SpecialCharTok{==} \StringTok{"kingdom"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(value) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(}\AttributeTok{use.names =} \ConstantTok{FALSE}\NormalTok{),}
        
        \AttributeTok{taxonRank =}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"animal"} \SpecialCharTok{\&}\NormalTok{ name }\SpecialCharTok{==} \StringTok{"rank"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(value) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(}\AttributeTok{use.names =} \ConstantTok{FALSE}\NormalTok{),}
        
        \AttributeTok{occurrenceStatus =} \StringTok{"present"}\NormalTok{,}
        
        \AttributeTok{sex =} \FunctionTok{ncvar\_get}\NormalTok{( nc, }\StringTok{\textquotesingle{}animal\_sex\textquotesingle{}}\NormalTok{),}
        
        \AttributeTok{lifeStage =} \FunctionTok{ncvar\_get}\NormalTok{( nc, }\StringTok{\textquotesingle{}animal\_life\_stage\textquotesingle{}}\NormalTok{),}
        
        \AttributeTok{scientificName =} \FunctionTok{ncvar\_get}\NormalTok{( nc, }\StringTok{\textquotesingle{}taxon\_name\textquotesingle{}}\NormalTok{),}
        
        \AttributeTok{scientificNameID =} \FunctionTok{ncvar\_get}\NormalTok{( nc, }\StringTok{"taxon\_lsid"}\NormalTok{)}
        
\NormalTok{        ) }\SpecialCharTok{\%\textgreater{}\%}

    \FunctionTok{rename}\NormalTok{(  }\CommentTok{\# rename columns to Darwin Core terms}
        
        \AttributeTok{basisOfRecord =}\NormalTok{ type,}
        \AttributeTok{eventDate =}\NormalTok{ time,}
        \AttributeTok{decimalLatitude =}\NormalTok{ lat,}
        \AttributeTok{decimalLongitude =}\NormalTok{ lon) }\SpecialCharTok{\%\textgreater{}\%} 

    \FunctionTok{arrange}\NormalTok{(eventDate) }\CommentTok{\#arrange by increasing date}

\CommentTok{\# minimumDepthInMeters = z,}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{minimumDepthInMeters }\OtherTok{=}\NormalTok{ atn\_tbl}\SpecialCharTok{$}\NormalTok{z}

\CommentTok{\# maximumDepthInMeters = z,}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{maximumDepthInMeters }\OtherTok{=}\NormalTok{ atn\_tbl}\SpecialCharTok{$}\NormalTok{z}

\CommentTok{\# organismID {-} \{platformID\}\_\{common\_name\}}
\NormalTok{common\_name\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"NC\_GLOBAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"animal\_common\_name"}\NormalTok{)}
\NormalTok{common\_name }\OtherTok{\textless{}{-}} \FunctionTok{chartr}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{, common\_name\_tbl}\SpecialCharTok{$}\NormalTok{value)}
\NormalTok{platform\_id\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"NC\_GLOBAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"platform\_id"}\NormalTok{)}
\NormalTok{platform\_id }\OtherTok{\textless{}{-}} \FunctionTok{chartr}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{, platform\_id\_tbl}\SpecialCharTok{$}\NormalTok{value)}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{organismID }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(platform\_id , common\_name, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{) }

\CommentTok{\# occurrenceID {-} \{eventDate\}\_\{depth\}\_\{common\_name\}}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{occurrenceID }\OtherTok{\textless{}{-}} \FunctionTok{sub}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{, }\FunctionTok{paste}\NormalTok{(occurrencedf}\SpecialCharTok{$}\NormalTok{eventDate, atn\_tbl}\SpecialCharTok{$}\NormalTok{z, common\_name, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{))}

\CommentTok{\# geodeticDatum}
\NormalTok{gd\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"crs"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"epsg\_code"}\NormalTok{)}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{geodeticDatum }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(gd\_tbl}\SpecialCharTok{$}\NormalTok{value)}

\CommentTok{\# eventID}
\CommentTok{\#eventID {-} \{common\_name\}\_\{dateTime\}}
\NormalTok{cname }\OtherTok{=}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"NC\_GLOBAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"animal\_common\_name"}\NormalTok{)}
\NormalTok{occurrencedf}\SpecialCharTok{$}\NormalTok{eventID }\OtherTok{\textless{}{-}} \FunctionTok{sub}\NormalTok{(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{, }\FunctionTok{paste0}\NormalTok{(cname}\SpecialCharTok{$}\NormalTok{value, }\StringTok{"\_"}\NormalTok{, occurrencedf}\SpecialCharTok{$}\NormalTok{eventDate))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(occurrencedf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [29 x 22] (S3: tbl_df/tbl/data.frame)
##  $ eventDate           : chr [1:29] "2009-09-23T00:00:00Z" "2009-09-25T06:42:00Z" "2009-09-25T11:09:00Z" "2009-09-25T11:11:00Z" ...
##  $ decimalLatitude     : num [1:29] 34 23.6 34 34 34 ...
##  $ decimalLongitude    : num [1:29] -119 -166 -119 -119 -119 ...
##  $ basisOfRecord       : chr [1:29] "HumanObservation" "MachineObservation" "MachineObservation" "MachineObservation" ...
##  $ location_class      : chr [1:29] "nan" "A" "1" "0" ...
##  $ qartod_time_flag    : int [1:29] 1 1 1 1 1 1 1 1 1 1 ...
##  $ qartod_speed_flag   : int [1:29] 2 4 4 4 1 1 1 1 1 1 ...
##  $ qartod_location_flag: int [1:29] 1 1 1 1 1 1 1 1 1 1 ...
##  $ qartod_rollup_flag  : int [1:29] 1 4 4 4 1 1 1 1 1 1 ...
##  $ kingdom             : chr [1:29] "Animalia" "Animalia" "Animalia" "Animalia" ...
##  $ taxonRank           : chr [1:29] "Species" "Species" "Species" "Species" ...
##  $ occurrenceStatus    : chr [1:29] "present" "present" "present" "present" ...
##  $ sex                 : chr [1:29] "male" "male" "male" "male" ...
##  $ lifeStage           : chr [1:29] "juvenile" "juvenile" "juvenile" "juvenile" ...
##  $ scientificName      : chr [1:29] "Carcharodon carcharias" "Carcharodon carcharias" "Carcharodon carcharias" "Carcharodon carcharias" ...
##  $ scientificNameID    : chr [1:29] "urn:lsid:marinespecies.org:taxname:105838" "urn:lsid:marinespecies.org:taxname:105838" "urn:lsid:marinespecies.org:taxname:105838" "urn:lsid:marinespecies.org:taxname:105838" ...
##  $ minimumDepthInMeters: int [1:29] 0 0 0 0 0 0 0 0 0 0 ...
##  $ maximumDepthInMeters: int [1:29] 0 0 0 0 0 0 0 0 0 0 ...
##  $ organismID          : chr [1:29] "105838_great_white_shark" "105838_great_white_shark" "105838_great_white_shark" "105838_great_white_shark" ...
##  $ occurrenceID        : chr [1:29] "2009-09-23T00:00:00Z_0_great_white_shark" "2009-09-25T06:42:00Z_0_great_white_shark" "2009-09-25T11:09:00Z_0_great_white_shark" "2009-09-25T11:11:00Z_0_great_white_shark" ...
##  $ geodeticDatum       : chr [1:29] "EPSG:4326" "EPSG:4326" "EPSG:4326" "EPSG:4326" ...
##  $ eventID             : chr [1:29] "great_white shark_2009-09-23T00:00:00Z" "great_white shark_2009-09-25T06:42:00Z" "great_white shark_2009-09-25T11:09:00Z" "great_white shark_2009-09-25T11:11:00Z" ...
\end{verbatim}

\hypertarget{add-coordinateuncertaintyinmeters-and-filter-by-location_class}{%
\paragraph{Add coordinateUncertaintyInMeters AND filter by location\_class}\label{add-coordinateuncertaintyinmeters-and-filter-by-location_class}}

When we add \texttt{coordinateUncertaintyInMeters} we are also filtering out where \texttt{location\_class} == \texttt{A},\texttt{B},or \texttt{Z}.

In these data we also have additional information about the Location Quality Code from ARGOS satellite system. Below are the codes and those meanings.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.46}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.54}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
code\_values
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
code meanings
\end{minipage} \\
\midrule
\endhead
G & estimated error less than 100m and 1+ messages received per satellite pass \\
3 & estimated error less than 250m and 4+ messages received per satellite pass \\
2 & estimated error between 250m and 500m and 4+ messages per satellite pass \\
1 & estimated error between 500m and 1500m and 4+ messages per satellite pass \\
0 & estimated error greater than 1500m and 4+ messages received per satellite pass \\
A & no least squares estimated error or unbounded kalman filter estimated error and 3 messages received per satellite pass \\
B & no least squares estimated error or unbounded kalman filter estimated error and 1 or 2 messages received per satellite pass \\
Z & invalid location (available for Service Plus or Auxilliary Location Processing) \\
\bottomrule
\end{longtable}

Since codes \texttt{A}, \texttt{B}, and \texttt{Z} are essentially bad values, I propose that we filter those out.

Also, create a mapping table for \texttt{coordinateUncertaintyInMeters} that corresponds to the ARGOS code maximum error as shown in the table below:

\begin{longtable}[]{@{}ll@{}}
\toprule
code & coordinateUncertaintyInMeters \\
\midrule
\endhead
G & 100 \\
3 & 250 \\
2 & 500 \\
1 & 1500 \\
0 & 10000 (\href{https://github.com/ioos/bio_data_guide/issues/145\#issuecomment-1805739244}{ref}) \\
\bottomrule
\end{longtable}

Below we create a lookup table for the \texttt{location\_class} values we agree are good, which contains the \texttt{coordinateUncertaintyInMeters} for the appropriate location class. When we merge that table with our raw data, the observations that don't match the location\_classes in our lookup table will not be transfered over (ie. they will be filtered out).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrencedf }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(location\_class }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}nan\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}3\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}1\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}0\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(  }\CommentTok{\# This returns NA for any other values than those defined below}
        \AttributeTok{coordinateUncertaintyInMeters =} \FunctionTok{case\_when}\NormalTok{(location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}nan\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{,}
\NormalTok{                                                     location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}G\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{200}\NormalTok{,}
\NormalTok{                                                     location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}3\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{250}\NormalTok{,}
\NormalTok{                                                     location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}2\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{500}\NormalTok{,}
\NormalTok{                                                     location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}1\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{1500}\NormalTok{,}
\NormalTok{                                                     location\_class }\SpecialCharTok{==} \StringTok{\textquotesingle{}0\textquotesingle{}} \SpecialCharTok{\textasciitilde{}} \DecValTok{10000}\NormalTok{) }\CommentTok{\# https://github.com/ioos/bio\_data\_guide/issues/145\#issuecomment{-}1805739244}
\NormalTok{          ) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{arrange}\NormalTok{(eventDate) }\CommentTok{\# arrange by increasing date}


\NormalTok{occurrencedf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 19 x 23
##    eventDate       decimalLatitude decimalLongitude basisOfRecord location_class
##    <chr>                     <dbl>            <dbl> <chr>         <chr>         
##  1 2009-09-23T00:~            34.0            -119. HumanObserva~ nan           
##  2 2009-09-25T11:~            34.0            -119. MachineObser~ 1             
##  3 2009-09-25T11:~            34.0            -119. MachineObser~ 0             
##  4 2009-09-27T17:~            34.0            -119. MachineObser~ 1             
##  5 2009-10-08T20:~            34.0            -119. MachineObser~ 2             
##  6 2009-10-15T11:~            34.0            -119. MachineObser~ 0             
##  7 2009-10-17T06:~            34.0            -119. MachineObser~ 0             
##  8 2009-10-17T09:~            34.0            -119. MachineObser~ 2             
##  9 2009-10-17T10:~            34.0            -119. MachineObser~ 3             
## 10 2009-10-18T08:~            34.0            -119. MachineObser~ 1             
## 11 2009-10-18T10:~            34.0            -119. MachineObser~ 2             
## 12 2009-10-18T11:~            34.0            -119. MachineObser~ 0             
## 13 2009-10-23T23:~            34.0            -119. MachineObser~ 2             
## 14 2009-10-24T00:~            34.0            -119. MachineObser~ 0             
## 15 2009-10-26T10:~            34.0            -119. MachineObser~ 3             
## 16 2009-10-27T16:~            34.0            -119. MachineObser~ 1             
## 17 2009-10-27T16:~            34.0            -119. MachineObser~ 2             
## 18 2009-10-29T11:~            34.0            -119. MachineObser~ 2             
## 19 2009-10-31T21:~            34.0            -119. MachineObser~ 0             
## # i 18 more variables: qartod_time_flag <int>, qartod_speed_flag <int>,
## #   qartod_location_flag <int>, qartod_rollup_flag <int>, kingdom <chr>,
## #   taxonRank <chr>, occurrenceStatus <chr>, sex <chr>, lifeStage <chr>,
## #   scientificName <chr>, scientificNameID <chr>, minimumDepthInMeters <int>,
## #   maximumDepthInMeters <int>, organismID <chr>, occurrenceID <chr>,
## #   geodeticDatum <chr>, eventID <chr>, coordinateUncertaintyInMeters <dbl>
\end{verbatim}

Notice how we went from 29 rows down to 19 rows by only selecting specific the location\_class.

\hypertarget{create-a-datageneralizations-column-to-describe-how-many-duplicates-were-found-for-each-deprecation-series}{%
\paragraph{Create a dataGeneralizations column to describe how many duplicates were found for each deprecation series}\label{create-a-datageneralizations-column-to-describe-how-many-duplicates-were-found-for-each-deprecation-series}}

Add a \texttt{dataGeneralizations} column containing a string like `first of \# records' to indicate there are more records in the raw dataset to be discovered by the super-curious.

The dataGeneralizations string is compiled by counting the number of consecutive duplicates and inserting that into a standard string. That string is ``first of {[}n{]} records'' which will make more sense once we've filtered down to keep the first occurrence of the hour.

The next step below this, we filter out only the first observation of the hour.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sort by date}
\NormalTok{occurrencedf }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(eventDate)}

\NormalTok{occurrencedf }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{eventDateHrs =} \FunctionTok{format}\NormalTok{(}\FunctionTok{as.POSIXct}\NormalTok{(eventDate, }\AttributeTok{format=}\StringTok{"\%Y{-}\%m{-}\%dT\%H:\%M:\%SZ"}\NormalTok{),}\StringTok{"\%Y{-}\%m{-}\%dT\%H"}\NormalTok{)}
\NormalTok{           ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{add\_count}\NormalTok{(eventDateHrs) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{dataGeneralizations =} \FunctionTok{case\_when}\NormalTok{(n }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\textasciitilde{}} \StringTok{""}\NormalTok{,}
                                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \FunctionTok{paste}\NormalTok{(}\StringTok{"first of "}\NormalTok{, n ,}\StringTok{"records"}\NormalTok{)}
\NormalTok{                                           )}
\NormalTok{           ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n)}

\NormalTok{occurrencedf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 19 x 25
##    eventDate       decimalLatitude decimalLongitude basisOfRecord location_class
##    <chr>                     <dbl>            <dbl> <chr>         <chr>         
##  1 2009-09-23T00:~            34.0            -119. HumanObserva~ nan           
##  2 2009-09-25T11:~            34.0            -119. MachineObser~ 1             
##  3 2009-09-25T11:~            34.0            -119. MachineObser~ 0             
##  4 2009-09-27T17:~            34.0            -119. MachineObser~ 1             
##  5 2009-10-08T20:~            34.0            -119. MachineObser~ 2             
##  6 2009-10-15T11:~            34.0            -119. MachineObser~ 0             
##  7 2009-10-17T06:~            34.0            -119. MachineObser~ 0             
##  8 2009-10-17T09:~            34.0            -119. MachineObser~ 2             
##  9 2009-10-17T10:~            34.0            -119. MachineObser~ 3             
## 10 2009-10-18T08:~            34.0            -119. MachineObser~ 1             
## 11 2009-10-18T10:~            34.0            -119. MachineObser~ 2             
## 12 2009-10-18T11:~            34.0            -119. MachineObser~ 0             
## 13 2009-10-23T23:~            34.0            -119. MachineObser~ 2             
## 14 2009-10-24T00:~            34.0            -119. MachineObser~ 0             
## 15 2009-10-26T10:~            34.0            -119. MachineObser~ 3             
## 16 2009-10-27T16:~            34.0            -119. MachineObser~ 1             
## 17 2009-10-27T16:~            34.0            -119. MachineObser~ 2             
## 18 2009-10-29T11:~            34.0            -119. MachineObser~ 2             
## 19 2009-10-31T21:~            34.0            -119. MachineObser~ 0             
## # i 20 more variables: qartod_time_flag <int>, qartod_speed_flag <int>,
## #   qartod_location_flag <int>, qartod_rollup_flag <int>, kingdom <chr>,
## #   taxonRank <chr>, occurrenceStatus <chr>, sex <chr>, lifeStage <chr>,
## #   scientificName <chr>, scientificNameID <chr>, minimumDepthInMeters <int>,
## #   maximumDepthInMeters <int>, organismID <chr>, occurrenceID <chr>,
## #   geodeticDatum <chr>, eventID <chr>, coordinateUncertaintyInMeters <dbl>,
## #   eventDateHrs <chr>, dataGeneralizations <chr>
\end{verbatim}

\hypertarget{decimate-occurrences-down-to-the-first-detectionlocation-per-hour}{%
\paragraph{Decimate occurrences down to the first detection/location per hour}\label{decimate-occurrences-down-to-the-first-detectionlocation-per-hour}}

Here we've done the decimation in Python: \url{https://gist.github.com/MathewBiddle/d434ac2b538b2728aa80c6a7945f94be}

Essentially we build a new colum that is the date plus the two digit hour. Then we find where that column has duplicates and keep the first entry.

In R, we do something slightly different as we only keep the distinct (ie. unique) rows and if there are duplicates, pick the first row of the duplicate.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sort by date}
\NormalTok{occurrencedf\_dec }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(eventDate)}

\CommentTok{\# filter table to only unique date + hour and pick the first row.}
\NormalTok{occurrencedf\_dec }\OtherTok{\textless{}{-}} \FunctionTok{distinct}\NormalTok{(occurrencedf\_dec,eventDateHrs,}\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{eventDateHrs)}

\NormalTok{occurrencedf\_dec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 17 x 24
##    eventDate       decimalLatitude decimalLongitude basisOfRecord location_class
##    <chr>                     <dbl>            <dbl> <chr>         <chr>         
##  1 2009-09-23T00:~            34.0            -119. HumanObserva~ nan           
##  2 2009-09-25T11:~            34.0            -119. MachineObser~ 1             
##  3 2009-09-27T17:~            34.0            -119. MachineObser~ 1             
##  4 2009-10-08T20:~            34.0            -119. MachineObser~ 2             
##  5 2009-10-15T11:~            34.0            -119. MachineObser~ 0             
##  6 2009-10-17T06:~            34.0            -119. MachineObser~ 0             
##  7 2009-10-17T09:~            34.0            -119. MachineObser~ 2             
##  8 2009-10-17T10:~            34.0            -119. MachineObser~ 3             
##  9 2009-10-18T08:~            34.0            -119. MachineObser~ 1             
## 10 2009-10-18T10:~            34.0            -119. MachineObser~ 2             
## 11 2009-10-18T11:~            34.0            -119. MachineObser~ 0             
## 12 2009-10-23T23:~            34.0            -119. MachineObser~ 2             
## 13 2009-10-24T00:~            34.0            -119. MachineObser~ 0             
## 14 2009-10-26T10:~            34.0            -119. MachineObser~ 3             
## 15 2009-10-27T16:~            34.0            -119. MachineObser~ 1             
## 16 2009-10-29T11:~            34.0            -119. MachineObser~ 2             
## 17 2009-10-31T21:~            34.0            -119. MachineObser~ 0             
## # i 19 more variables: qartod_time_flag <int>, qartod_speed_flag <int>,
## #   qartod_location_flag <int>, qartod_rollup_flag <int>, kingdom <chr>,
## #   taxonRank <chr>, occurrenceStatus <chr>, sex <chr>, lifeStage <chr>,
## #   scientificName <chr>, scientificNameID <chr>, minimumDepthInMeters <int>,
## #   maximumDepthInMeters <int>, organismID <chr>, occurrenceID <chr>,
## #   geodeticDatum <chr>, eventID <chr>, coordinateUncertaintyInMeters <dbl>,
## #   dataGeneralizations <chr>
\end{verbatim}

Notice that we have gone from 19 rows to 17 rows. Removing rows observed on \texttt{2009-09-25T11:11:00Z} and \texttt{2009-10-27T16:22:00Z} as they were the second points within that specifc hour.

\hypertarget{filter-on-qartod-flags}{%
\paragraph{Filter on QARTOD flags?}\label{filter-on-qartod-flags}}

We also have QARTOD flags and they are as follows:

\begin{longtable}[]{@{}ll@{}}
\toprule
value & meaning \\
\midrule
\endhead
1 & PASS \\
2 & NOT\_EVALUATED \\
3 & SUSPECT \\
4 & FAIL \\
9 & MISSING \\
\bottomrule
\end{longtable}

The QARTOD tests are:

\begin{longtable}[]{@{}ll@{}}
\toprule
variable & long\_name \\
\midrule
\endhead
qartod\_time\_flag & Time QC test - gross range test \\
qartod\_speed\_flag & Speed QC test - gross range test \\
qartod\_location\_flag & Location QC test - Location test \\
qartod\_rollup\_flag & Aggregate QC value \\
\bottomrule
\end{longtable}

I'm not sure what to do here. My preference would be to include all rows where \texttt{qartod\_rollup\_flag} == 1 and drop the rest. But I'm open to suggestions.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# perform filter but don\textquotesingle{}t save it.}
\FunctionTok{filter}\NormalTok{(occurrencedf\_dec, qartod\_rollup\_flag }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 16 x 24
##    eventDate       decimalLatitude decimalLongitude basisOfRecord location_class
##    <chr>                     <dbl>            <dbl> <chr>         <chr>         
##  1 2009-09-23T00:~            34.0            -119. HumanObserva~ nan           
##  2 2009-09-27T17:~            34.0            -119. MachineObser~ 1             
##  3 2009-10-08T20:~            34.0            -119. MachineObser~ 2             
##  4 2009-10-15T11:~            34.0            -119. MachineObser~ 0             
##  5 2009-10-17T06:~            34.0            -119. MachineObser~ 0             
##  6 2009-10-17T09:~            34.0            -119. MachineObser~ 2             
##  7 2009-10-17T10:~            34.0            -119. MachineObser~ 3             
##  8 2009-10-18T08:~            34.0            -119. MachineObser~ 1             
##  9 2009-10-18T10:~            34.0            -119. MachineObser~ 2             
## 10 2009-10-18T11:~            34.0            -119. MachineObser~ 0             
## 11 2009-10-23T23:~            34.0            -119. MachineObser~ 2             
## 12 2009-10-24T00:~            34.0            -119. MachineObser~ 0             
## 13 2009-10-26T10:~            34.0            -119. MachineObser~ 3             
## 14 2009-10-27T16:~            34.0            -119. MachineObser~ 1             
## 15 2009-10-29T11:~            34.0            -119. MachineObser~ 2             
## 16 2009-10-31T21:~            34.0            -119. MachineObser~ 0             
## # i 19 more variables: qartod_time_flag <int>, qartod_speed_flag <int>,
## #   qartod_location_flag <int>, qartod_rollup_flag <int>, kingdom <chr>,
## #   taxonRank <chr>, occurrenceStatus <chr>, sex <chr>, lifeStage <chr>,
## #   scientificName <chr>, scientificNameID <chr>, minimumDepthInMeters <int>,
## #   maximumDepthInMeters <int>, organismID <chr>, occurrenceID <chr>,
## #   geodeticDatum <chr>, eventID <chr>, coordinateUncertaintyInMeters <dbl>,
## #   dataGeneralizations <chr>
\end{verbatim}

Drop the quality flag columns to align with DarwinCore standard.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrencedf\_dec }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf\_dec }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}
        \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(location\_class,}
\NormalTok{           qartod\_time\_flag,}
\NormalTok{           qartod\_speed\_flag,}
\NormalTok{           qartod\_location\_flag,}
\NormalTok{           qartod\_rollup\_flag}
\NormalTok{           ))}
        
\FunctionTok{names}\NormalTok{(occurrencedf\_dec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "eventDate"                     "decimalLatitude"              
##  [3] "decimalLongitude"              "basisOfRecord"                
##  [5] "kingdom"                       "taxonRank"                    
##  [7] "occurrenceStatus"              "sex"                          
##  [9] "lifeStage"                     "scientificName"               
## [11] "scientificNameID"              "minimumDepthInMeters"         
## [13] "maximumDepthInMeters"          "organismID"                   
## [15] "occurrenceID"                  "geodeticDatum"                
## [17] "eventID"                       "coordinateUncertaintyInMeters"
## [19] "dataGeneralizations"
\end{verbatim}

\hypertarget{add-ncei-url-to-references}{%
\subsubsection{Add NCEI URL to references}\label{add-ncei-url-to-references}}

For full transparency, we will add the Darwin Core term references to provide the URL to the NCEI landing page, where the full dataset can be accessed by curious users.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{occurrencedf\_dec}\SpecialCharTok{$}\NormalTok{references }\OtherTok{\textless{}{-}} \StringTok{"https://www.ncei.noaa.gov/archive/accession/0282699"}

\NormalTok{occurrencedf\_dec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 17 x 20
##    eventDate    decimalLatitude decimalLongitude basisOfRecord kingdom taxonRank
##    <chr>                  <dbl>            <dbl> <chr>         <chr>   <chr>    
##  1 2009-09-23T~            34.0            -119. HumanObserva~ Animal~ Species  
##  2 2009-09-25T~            34.0            -119. MachineObser~ Animal~ Species  
##  3 2009-09-27T~            34.0            -119. MachineObser~ Animal~ Species  
##  4 2009-10-08T~            34.0            -119. MachineObser~ Animal~ Species  
##  5 2009-10-15T~            34.0            -119. MachineObser~ Animal~ Species  
##  6 2009-10-17T~            34.0            -119. MachineObser~ Animal~ Species  
##  7 2009-10-17T~            34.0            -119. MachineObser~ Animal~ Species  
##  8 2009-10-17T~            34.0            -119. MachineObser~ Animal~ Species  
##  9 2009-10-18T~            34.0            -119. MachineObser~ Animal~ Species  
## 10 2009-10-18T~            34.0            -119. MachineObser~ Animal~ Species  
## 11 2009-10-18T~            34.0            -119. MachineObser~ Animal~ Species  
## 12 2009-10-23T~            34.0            -119. MachineObser~ Animal~ Species  
## 13 2009-10-24T~            34.0            -119. MachineObser~ Animal~ Species  
## 14 2009-10-26T~            34.0            -119. MachineObser~ Animal~ Species  
## 15 2009-10-27T~            34.0            -119. MachineObser~ Animal~ Species  
## 16 2009-10-29T~            34.0            -119. MachineObser~ Animal~ Species  
## 17 2009-10-31T~            34.0            -119. MachineObser~ Animal~ Species  
## # i 14 more variables: occurrenceStatus <chr>, sex <chr>, lifeStage <chr>,
## #   scientificName <chr>, scientificNameID <chr>, minimumDepthInMeters <int>,
## #   maximumDepthInMeters <int>, organismID <chr>, occurrenceID <chr>,
## #   geodeticDatum <chr>, eventID <chr>, coordinateUncertaintyInMeters <dbl>,
## #   dataGeneralizations <chr>, references <chr>
\end{verbatim}

\hypertarget{write-decimated-occurrence-file-as-csv}{%
\paragraph{Write decimated occurrence file as csv}\label{write-decimated-occurrence-file-as-csv}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tag\_id }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"NC\_GLOBAL"} \SpecialCharTok{\&}\NormalTok{ name }\SpecialCharTok{==} \StringTok{"ptt\_id"}\NormalTok{)}

\NormalTok{file\_name\_occur }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}data/dwc/atn\_\textquotesingle{}}\NormalTok{,tag\_id}\SpecialCharTok{$}\NormalTok{value,}\StringTok{\textquotesingle{}\_occurrence.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{)}

\FunctionTok{write.csv}\NormalTok{(occurrencedf\_dec, }\AttributeTok{file=}\NormalTok{file\_name\_occur, }\AttributeTok{row.names=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{fileEncoding=}\StringTok{"UTF{-}8"}\NormalTok{, }\AttributeTok{quote=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{na=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{measurement-or-fact}{%
\subsubsection{Measurement or Fact}\label{measurement-or-fact}}

Since we do have any additional observations, we can create a measurement or fact file to include those data. Might be worthwhile to include tag/device metadata, some of the animal measurements, and the detachment information. Each term should have a definition URI.

The measurementOrFact file will only contain information referencing the \texttt{basisOfRecord} = \texttt{HumanObservation} as these observations were made when the animal was directly tagged, in person (ie. when \texttt{basisOfRecord} == \texttt{HumanObservation}).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.52}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.26}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.23}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
DarwinCore Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Status
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
netCDF
\end{minipage} \\
\midrule
\endhead
organismID & & The \texttt{platform\_id} global attribute plus the \texttt{animal\_common\_name} global attribute. \\
occurrenceID & Required & \texttt{eventDate}, plus data contained in \texttt{z} variable, plus \texttt{animal\_common\_name} global attribute. \\
measurementType & Required & \texttt{long\_name} attribute of the \texttt{animal\_weight}, \texttt{animal\_length}, \texttt{animal\_length\_2} variables. \\
measurementValue & Required & The data from the \texttt{animal\_weight}, \texttt{animal\_length}, \texttt{animal\_length\_2} variables. \\
eventID & Strongly Recommended & \texttt{animal\_common\_name} global attribute plus the \texttt{eventDate}. \\
measurementUnit & Strongly Recommended & \texttt{unit} attribute of the \texttt{animal\_weight}, \texttt{animal\_length}, \texttt{animal\_length\_2} variables. \\
measurementMethod & Strongly Recommended & \texttt{animal\_weight}, \texttt{animal\_length}, \texttt{animal\_length\_2} attributes of their respective variables. \\
measurementTypeID & Strongly Recommended & mapping table somewhere? \\
measurementMethodID & Strongly Recommended & mapping table somewhere? \\
measurementUnitID & Strongly Recommended & mapping table somewhere? \\
measurementAccuracy & Share if available & \\
measurementDeterminedDate & Share if available & \\
measurementDeterminedBy & Share if available & \\
measurementRemarks & Share if available & \\
measurementValueID & Share if available & \\
\bottomrule
\end{longtable}

\hypertarget{extracting-variables-for-extended-measurement-or-fact-emof}{%
\paragraph{Extracting variables for Extended Measurement Or Fact (eMOF)}\label{extracting-variables-for-extended-measurement-or-fact-emof}}

Here there are two approaches to transforming a variable to the eMOF Darwin Core extension. The goal is to collapse the measurement name, value, unit, related identifiers and remarks into a generalized long format that can be linked to occurrences and events. For more info see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://manual.obis.org/format_emof.html}{The OBIS manual}
\item
  The \href{https://ioos.github.io/bio_mobilization_workshop/04-create-schema/index.html}{Marine Biological Data Mobilization Workshop 2023} (SF:Not sure if it's cool to reference the workshop like this)
\end{enumerate}

The first several lines of the below code show an example of pulling out the variable attributes and individually mapping them to the eMOF terms. However, this can be done more efficiently (although less readable) via this chunk of code:

\begin{verbatim}
# Supply vector of variable names
c("animal_length",
  "animal_length_2",
  "animal_weight") %>%

      # Create a named list of the variable attributes and convert it into a data frame, for each name in the above vector.
      purrr::map_df(function(x) {
        0list(measurementValue = ncvar_get( nc, x),
             measurementType = ncatt_get( nc, x)$long_name,
             measurementUnit = ncatt_get( nc, x)$units,
             measurementMethod = ncatt_get( nc, x)[[paste0(x,'_type')]])
        })
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \# Measurement or Fact extension}
\CommentTok{\# \# Need to find the occurrence where basisOfRecord == HumanObservation, then pull the organism.}

\NormalTok{emof\_data }\OtherTok{\textless{}{-}} \CommentTok{\#var\_names \%\textgreater{}\%}
    \CommentTok{\#filter(str\_starts(name, pattern = "animal\_[lw]e")) \%\textgreater{}\% \#example using regex to parse names}
    \CommentTok{\#    pull(name) \%\textgreater{}\%}

    \CommentTok{\# Example using vector of variables}
    \FunctionTok{c}\NormalTok{(}\StringTok{"animal\_length"}\NormalTok{,}
      \StringTok{"animal\_length\_2"}\NormalTok{,}
      \StringTok{"animal\_weight"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    purrr}\SpecialCharTok{::}\FunctionTok{map\_df}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) \{}
        \FunctionTok{list}\NormalTok{(}\AttributeTok{measurementValue =} \FunctionTok{ncvar\_get}\NormalTok{( nc, x),}
             \AttributeTok{measurementType =} \FunctionTok{ncatt\_get}\NormalTok{( nc, x)}\SpecialCharTok{$}\NormalTok{long\_name,}
             \AttributeTok{measurementUnit =} \FunctionTok{ncatt\_get}\NormalTok{( nc, x)}\SpecialCharTok{$}\NormalTok{units,}
             \AttributeTok{measurementMethod =} \FunctionTok{ncatt\_get}\NormalTok{( nc, x)[[}\FunctionTok{paste0}\NormalTok{(x,}\StringTok{\textquotesingle{}\_type\textquotesingle{}}\NormalTok{)]])}
\NormalTok{    \}) }\SpecialCharTok{\%\textgreater{}\%}
    
    \FunctionTok{filter}\NormalTok{(measurementValue }\SpecialCharTok{!=} \StringTok{"NaN"}\NormalTok{)}


\NormalTok{emofdf }\OtherTok{\textless{}{-}}\NormalTok{ occurrencedf }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(basisOfRecord }\SpecialCharTok{==} \StringTok{\textquotesingle{}HumanObservation\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(organismID, eventID, occurrenceID) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{cbind}\NormalTok{(emof\_data)}

\FunctionTok{str}\NormalTok{(emofdf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1 obs. of  7 variables:
##  $ organismID       : chr "105838_great_white_shark"
##  $ eventID          : chr "great_white shark_2009-09-23T00:00:00Z"
##  $ occurrenceID     : chr "2009-09-23T00:00:00Z_0_great_white_shark"
##  $ measurementValue : num 213
##  $ measurementType  : chr "length of the animal as measured or estimated at deployment"
##  $ measurementUnit  : chr "cm"
##  $ measurementMethod: chr "total length"
\end{verbatim}

\hypertarget{write-emof-file-as-csv}{%
\paragraph{Write emof file as csv}\label{write-emof-file-as-csv}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tag\_id }\OtherTok{\textless{}{-}}\NormalTok{ metadata }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"NC\_GLOBAL"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(name }\SpecialCharTok{==} \StringTok{"ptt\_id"}\NormalTok{)}

\NormalTok{file\_name\_emof }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}data/dwc/atn\_\textquotesingle{}}\NormalTok{,tag\_id}\SpecialCharTok{$}\NormalTok{value,}\StringTok{\textquotesingle{}\_emof.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{)}

\FunctionTok{write.csv}\NormalTok{(emofdf, }\AttributeTok{file=}\NormalTok{file\_name\_emof, }\AttributeTok{row.names=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{fileEncoding=}\StringTok{"UTF{-}8"}\NormalTok{, }\AttributeTok{quote=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{na=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{metadata-creation}{%
\subsubsection{Metadata creation}\label{metadata-creation}}

Now that we know our data are aligned to Darwin Core, we can start collecting metadata. Using the R package \href{https://docs.ropensci.org/EML/}{EML} we can create the EML metadata to associate with the data above.

Some good sources to help identify what requirements we need in the EML metadata can be found at:

\begin{itemize}
\item
  \url{https://github.com/gbif/ipt/wiki/GMPHowToGuide}
\item
  \url{https://github.com/gbif/ipt/wiki/GMPHowToGuide\#dataset-resource}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(EML)}
\end{Highlighting}
\end{Shaded}

The first thing we need to do is collect all of the relevant pieces of metadata for our EML record.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# me \textless{}{-} list(individualName = list(givenName = "Matt", surName = "Biddle"))}

\CommentTok{\# my\_eml \textless{}{-} list(dataset = list(}

\CommentTok{\#                           title = "A Minimal Valid EML Dataset",}

\CommentTok{\#                           creator = me,}

\CommentTok{\#                           contact = me}

\CommentTok{\#                             )}

\CommentTok{\#                 )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# geographicDescription \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "sea\_name")}

\CommentTok{\# west \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_lon\_min")}

\CommentTok{\# east \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_lon\_max")}

\CommentTok{\# north \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_lat\_max")}

\CommentTok{\# south \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_lat\_min")}

\CommentTok{\# altitudeMin \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_vertical\_min")}

\CommentTok{\# altitudeMax \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_vertical\_max")}

\CommentTok{\# altitudeUnits \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "geospatial\_vertical\_units")}


\CommentTok{\# coverage \textless{}{-}}

\CommentTok{\#   set\_coverage(begin = format(min(atn\_tbl$time),\textquotesingle{}\%Y{-}\%m{-}\%d\textquotesingle{}), end = format(max(atn\_tbl$time), \textquotesingle{}\%Y{-}\%m{-}\%d\textquotesingle{}),}

\CommentTok{\#                sci\_names = RNetCDF::var.get.nc(RNetCDF::open.nc("atn\_trajectory\_template.nc"), "taxon\_name"),}

\CommentTok{\#                geographicDescription = paste(geographicDescription$value),}

\CommentTok{\#                west = paste(west$value),}

\CommentTok{\#                east = paste(east$value) ,}

\CommentTok{\#                north = paste(north$value) ,}

\CommentTok{\#                south = paste(south$value) ,}

\CommentTok{\#                altitudeMin = paste(altitudeMin$value),}

\CommentTok{\#                altitudeMaximum = paste(altitudeMax$value),}

\CommentTok{\#                altitudeUnits = ifelse (paste(altitudeUnits$value) == \textquotesingle{}m\textquotesingle{}, "meter", "?"))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# creator\_name \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "creator\_name")}

\CommentTok{\# creator\_email \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "creator\_email")}

\CommentTok{\# creator\_sector \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "creator\_sector")}

\CommentTok{\# creator \textless{}{-} eml$creator(}

\CommentTok{\#             eml$individualName(}

\CommentTok{\#                 givenName = paste(creator\_name$value),}

\CommentTok{\#                 surName = paste(creator\_name$value)}

\CommentTok{\#                 ),}

\CommentTok{\#             position = paste(creator\_sector$value),}

\CommentTok{\#             electronicMailAddress = paste(creator\_email$value)}

\CommentTok{\#             )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \#contact\_name = metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "contact\_name")}

\CommentTok{\# contact \textless{}{-} eml$contact(}

\CommentTok{\#             eml$individualName(}

\CommentTok{\#             givenName = paste(creator\_name$value),}

\CommentTok{\#             surName = paste(creator\_name$value)),}

\CommentTok{\#             position = paste(creator\_sector$value),}

\CommentTok{\#             electronicMailAddress = paste(creator\_email$value)}

\CommentTok{\#             )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \#metadata\_name}

\CommentTok{\# metadataProvider \textless{}{-} eml$metadataProvider(}

\CommentTok{\#             eml$individualName(}

\CommentTok{\#                 givenName = paste(creator\_name$value),}

\CommentTok{\#                 surName = paste(creator\_name$value)),}

\CommentTok{\#             position = paste(creator\_sector$value),}

\CommentTok{\#             electronicMailAddress = paste(creator\_email$value)}

\CommentTok{\#             )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \#\# these are the entries in contributor, need to iterate since comma separated list.}

\CommentTok{\# contrib\_name \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "contributor\_name")}

\CommentTok{\# contrib\_position \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "contributor\_role")}

\CommentTok{\# contrib\_email \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "contributor\_email")}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# associatedParty \textless{}{-} eml$associatedParty(}

\CommentTok{\#                     eml$individualName(}

\CommentTok{\#                     givenName = paste(contrib\_name$value),}

\CommentTok{\#                     surName = paste(contrib\_name$value)),}

\CommentTok{\#                     position = paste(contrib\_position$value),}

\CommentTok{\#                     electronicMailAddress = paste(contrib\_email$value)}

\CommentTok{\#                     )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# abstract \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "summary")}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \# keywords}

\CommentTok{\# keywords \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "keywords")}

\CommentTok{\# kw\_vocab \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "keywords\_vocabulary")}

\CommentTok{\# keywordSet \textless{}{-} list(}

\CommentTok{\#     list(}

\CommentTok{\#         keywordThesaurus = kw\_vocab$value$keywords\_vocabulary,}

\CommentTok{\#         keyword = as.list(strsplit(keywords$value$keywords, ", "))}

\CommentTok{\#         ))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# title \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "title")}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# methods \textless{}{-} "NEED TO MAP FROM NCFILE"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# license \textless{}{-} metadata \%\textgreater{}\% dplyr::filter(variable == "NC\_GLOBAL") \%\textgreater{}\% dplyr::filter(name == "license")}
\end{Highlighting}
\end{Shaded}

Now build the eml file.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(uuid)}


\CommentTok{\# physical \textless{}{-} set\_physical(file\_name\_occur)}


\CommentTok{\# \# attributeList \textless{}{-}}

\CommentTok{\# \#   set\_attributes(attributes,}

\CommentTok{\# \#                  factors,}

\CommentTok{\# \#                  col\_classes = c("character",}

\CommentTok{\# \#                                  "Date",}

\CommentTok{\# \#                                  "Date",}

\CommentTok{\# \#                                  "Date",}

\CommentTok{\# \#                                  "factor",}

\CommentTok{\# \#                                  "factor",}

\CommentTok{\# \#                                  "factor",}

\CommentTok{\# \#                                  "numeric"))}


\CommentTok{\# my\_eml \textless{}{-} eml$eml(}

\CommentTok{\#            packageId = paste(uuid\_tbl$value),}

\CommentTok{\#            system = "uuid",}

\CommentTok{\#            dataset = eml$dataset(}

\CommentTok{\#                alternateIdentifier = UUIDgenerate(use.time = TRUE),}

\CommentTok{\#                title = title$value,}

\CommentTok{\#                creator = creator,}

\CommentTok{\#                metadataProvider = metadataProvider,}

\CommentTok{\#                \#associatedParty = associatedParty,}

\CommentTok{\#                contact = contact,}

\CommentTok{\#                pubDate = format(Sys.time(),\textquotesingle{}\%Y{-}\%m{-}\%d\textquotesingle{}),}

\CommentTok{\#                language = "English",}

\CommentTok{\#                intellectualRights = eml$intellectualRights(}

\CommentTok{\#                                     para = "To the extent possible under law, the publisher has waived all rights to these data and has dedicated them to the \textless{}ulink url=\textbackslash{}"http://creativecommons.org/publicdomain/zero/1.0/legalcode\textbackslash{}"\textgreater{}\textless{}citetitle\textgreater{}Public Domain (CC0 1.0)\textless{}/citetitle\textgreater{}\textless{}/ulink\textgreater{}. Users may copy, modify, distribute and use the work, including for commercial purposes, without restriction."}

\CommentTok{\#                                     \#para = paste(license$value),}

\CommentTok{\#                                                            ),}

\CommentTok{\#                abstract = eml$abstract(}

\CommentTok{\#                                para = abstract$value$summary,}

\CommentTok{\#                                        ),}

\CommentTok{\#                keywordSet = keywordSet,}

\CommentTok{\#                coverage = coverage,}

\CommentTok{\# \#                license = eml$license(}

\CommentTok{\# \#                            licenseName = "CC0 1.0",}

\CommentTok{\# \#                            \#licenseName = paste(license$value),}

\CommentTok{\# \#                            ),}

\CommentTok{\#                \#dataTable = eml$dataTable(}

\CommentTok{\#                \#  entityName = file\_name\_occur,}

\CommentTok{\#                \#  entityDescription = "Occurrences",}

\CommentTok{\#                \#  physical = physical)}

\CommentTok{\#                ))}
\end{Highlighting}
\end{Shaded}

Validate EML

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# val \textless{}{-} eml\_validate(my\_eml)}

\CommentTok{\# attr(val,"errors")}
\end{Highlighting}
\end{Shaded}

Write eml to file.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# file\_name\_eml \textless{}{-} \textquotesingle{}eml.xml\textquotesingle{}}

\CommentTok{\# write\_eml(my\_eml, file\_name\_eml)}
\end{Highlighting}
\end{Shaded}

Raw EML

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# my\_eml}
\end{Highlighting}
\end{Shaded}

\hypertarget{create-meta.xml}{%
\paragraph{Create meta.xml}\label{create-meta.xml}}

Below is an example of the contents of meta.xml:

\begin{verbatim}
<archive xmlns="http://rs.tdwg.org/dwc/text/" metadata="eml.xml">

  <core encoding="UTF-8" fieldsTerminatedBy="\t" linesTerminatedBy="\n" fieldsEnclosedBy="" ignoreHeaderLines="1" rowType="http://rs.tdwg.org/dwc/terms/Occurrence">

    <files>

      <location>occurrence.txt</location>

    </files>

    <id index="0" />

    <field index="1" term="http://rs.tdwg.org/dwc/terms/datasetID"/>

    <field index="2" term="http://rs.tdwg.org/dwc/terms/institutionCode"/>

    <field index="3" term="http://rs.tdwg.org/dwc/terms/collectionCode"/>

    <field index="4" term="http://rs.tdwg.org/dwc/terms/basisOfRecord"/>

    <field index="5" term="http://rs.tdwg.org/dwc/terms/occurrenceID"/>

    <field index="6" term="http://rs.tdwg.org/dwc/terms/catalogNumber"/>

    <field index="7" term="http://rs.tdwg.org/dwc/terms/occurrenceRemarks"/>

    <field index="8" term="http://rs.tdwg.org/dwc/terms/individualCount"/>

    <field index="9" term="http://rs.tdwg.org/dwc/terms/sex"/>

    <field index="10" term="http://rs.tdwg.org/dwc/terms/occurrenceStatus"/>

    <field index="11" term="http://rs.tdwg.org/dwc/terms/eventDate"/>

    <field index="12" term="http://rs.tdwg.org/dwc/terms/year"/>

    <field index="13" term="http://rs.tdwg.org/dwc/terms/decimalLatitude"/>

    <field index="14" term="http://rs.tdwg.org/dwc/terms/decimalLongitude"/>

    <field index="15" term="http://rs.tdwg.org/dwc/terms/coordinateUncertaintyInMeters"/>

    <field index="16" term="http://rs.tdwg.org/dwc/terms/scientificNameID"/>

    <field index="17" term="http://rs.tdwg.org/dwc/terms/scientificName"/>

  </core>

  <extension encoding="UTF-8" fieldsTerminatedBy="\t" linesTerminatedBy="\n" fieldsEnclosedBy="" ignoreHeaderLines="1" rowType="http://rs.iobis.org/obis/terms/ExtendedMeasurementOrFact">

    <files>

      <location>extendedmeasurementorfact.txt</location>

    </files>

    <coreid index="0" />

    <field index="1" term="http://rs.tdwg.org/dwc/terms/occurrenceID"/>

    <field index="2" term="http://rs.tdwg.org/dwc/terms/measurementType"/>

    <field index="3" term="http://rs.tdwg.org/dwc/terms/measurementValue"/>

    <field index="4" term="http://rs.tdwg.org/dwc/terms/measurementUnit"/>

    <field index="5" term="http://rs.iobis.org/obis/terms/measurementUnitID"/>

    <field index="6" term="http://rs.tdwg.org/dwc/terms/measurementDeterminedDate"/>

  </extension>

</archive>
\end{verbatim}

Checkout \href{https://cran.r-project.org/web/packages/XML/index.html}{XML package for R}.

\texttt{conda\ install\ -c\ conda-forge\ r-xml}

Another example in this \href{https://github.com/EDIorg/ecocomDP/blob/372c293c9e597c64db22c027debe18528d44f53b/inst/extdata/dwca_event_core/meta.xml}{github repository}.

Or use the \href{http://tools.gbif.org/dwca-assistant/}{gui here} to create meta.xml.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(XML)}


\CommentTok{\# doc = newXMLDoc()}

\CommentTok{\# archiveNode = newXMLNode("archive", attrs = c(metadata=file\_name\_eml), namespaceDefinitions=c("http://rs.tdwg.org/dwc/text/"), doc=doc )}


\CommentTok{\# \#\# For the core occurrence}

\CommentTok{\# coreNode = newXMLNode("core", attrs = c(encoding="UTF{-}8", linesTerminatedBy="\textbackslash{}\textbackslash{}r\textbackslash{}\textbackslash{}n", fieldsTerminatedBy=",", fieldsEnclosedBy=\textquotesingle{}\textbackslash{}"\textquotesingle{}, ignoreHeaderLines="1", rowType="http://rs.tdwg.org/dwc/terms/Occurrence"), parent = archiveNode)}

\CommentTok{\# filesNode = newXMLNode("files", parent = coreNode)}

\CommentTok{\# locationNode = newXMLNode("location", file\_name\_occur, parent = filesNode)}

\CommentTok{\# idnode = newXMLNode("id", attrs = c(index="9"), parent = coreNode)}


\CommentTok{\# \# iterate over the columns in occurrence file to create field elements}

\CommentTok{\# i=0}

\CommentTok{\# for (col in colnames(occurrencedf))}

\CommentTok{\#     \{}

\CommentTok{\#     termstr = paste("http://rs.tdwg.org/dwc/terms/",col, sep="")}

\CommentTok{\#     i=i+1}

\CommentTok{\#     fieldnode = newXMLNode("field", attrs = c(index=i, term=termstr), parent=coreNode)}

\CommentTok{\# \}}



\CommentTok{\# \#\# for the extensions}

\CommentTok{\# extensionNode = newXMLNode("extension", attrs = c(encoding="UTF{-}8", linesTerminatedBy="\textbackslash{}\textbackslash{}r\textbackslash{}\textbackslash{}n", fieldsTerminatedBy=",", fieldsEnclosedBy=\textquotesingle{}\textbackslash{}"\textquotesingle{}, ignoreHeaderLines="1", rowType="http://rs.tdwg.org/dwc/terms/Event"), parent = archiveNode)}

\CommentTok{\# filesNode = newXMLNode("files", parent = extensionNode)}

\CommentTok{\# locationNode = newXMLNode("location", file\_name\_event, parent = filesNode)}

\CommentTok{\# idnode = newXMLNode("id", attrs = c(index="0"), parent = extensionNode)}


\CommentTok{\# \# iterate over the columns in occurrence file to create field elements}

\CommentTok{\# i=0}

\CommentTok{\# for (col in colnames(eventdf))}

\CommentTok{\#     \{}

\CommentTok{\#     if (col == \textquotesingle{}modified\textquotesingle{})\{}

\CommentTok{\#         termstr = paste("http://purl.org/dc/terms/", col, sep="")}

\CommentTok{\#     \} else \{}

\CommentTok{\#         termstr = paste("http://rs.tdwg.org/dwc/terms/",col, sep="")}

\CommentTok{\#         \}}


\CommentTok{\#     i=i+1}


\CommentTok{\#     fieldnode = newXMLNode("field", attrs = c(index=i, term=termstr), parent=extensionNode)}

\CommentTok{\# \}}



\CommentTok{\# print(doc)}



\CommentTok{\# saveXML(doc, file="meta.xml")}
\end{Highlighting}
\end{Shaded}

\hypertarget{build-the-darwincore-archive-zip-package}{%
\subsubsection{Build the DarwinCore-Archive zip package}\label{build-the-darwincore-archive-zip-package}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(zip)}


\CommentTok{\# files = c(file\_name\_occur, file\_name\_event, file\_name\_eml, "meta.xml")}

\CommentTok{\# zip::zip(}

\CommentTok{\#     "atn.zip",}

\CommentTok{\#     files,}

\CommentTok{\#     root = ".",}

\CommentTok{\#     mode = "mirror",}

\CommentTok{\# )}


\CommentTok{\# zip\_list("atn.zip")}
\end{Highlighting}
\end{Shaded}

\hypertarget{sessioninfo}{%
\subsection{sessionInfo()}\label{sessioninfo}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## R version 4.1.1 (2021-08-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] mapdata_2.3.1   maps_3.4.1      ncdf4_1.21      obistools_0.1.0
##  [5] tidync_0.3.0    worrms_0.4.3    magrittr_2.0.3  knitr_1.42     
##  [9] here_1.0.1      lubridate_1.9.3 forcats_1.0.0   stringr_1.5.0  
## [13] dplyr_1.1.2     purrr_1.0.1     readr_2.1.5     tidyr_1.3.0    
## [17] tibble_3.2.1    ggplot2_3.4.2   tidyverse_2.0.0
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.10       rprojroot_2.0.4   digest_0.6.31     utf8_1.2.3       
##  [5] R6_2.5.1          cellranger_1.1.0  evaluate_0.21     pillar_1.9.0     
##  [9] rlang_1.1.1       curl_5.0.0        readxl_1.4.3      ncmeta_0.3.5     
## [13] rstudioapi_0.16.0 rmarkdown_2.21    urltools_1.7.3    htmlwidgets_1.6.2
## [17] bit_4.0.5         triebeard_0.4.1   munsell_0.5.0     compiler_4.1.1   
## [21] xfun_0.39         pkgconfig_2.0.3   htmltools_0.5.5   tidyselect_1.2.1 
## [25] httpcode_0.3.0    bookdown_0.40     fansi_1.0.4       crayon_1.5.2     
## [29] tzdb_0.3.0        withr_2.5.0       rappdirs_0.3.3    crul_1.5.0       
## [33] grid_4.1.1        jsonlite_1.8.4    gtable_0.3.3      lifecycle_1.0.3  
## [37] scales_1.2.1      cli_3.6.1         stringi_1.7.12    vroom_1.6.3      
## [41] leaflet_2.1.2     xml2_1.3.6        generics_0.1.3    vctrs_0.6.5      
## [45] data.tree_1.1.0   tools_4.1.1       bit64_4.0.5       glue_1.6.2       
## [49] RNetCDF_2.6-2     crosstalk_1.2.0   hms_1.1.3         parallel_4.1.1   
## [53] fastmap_1.1.1     yaml_2.3.7        timechange_0.3.0  colorspace_2.1-0
\end{verbatim}

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{frequently-asked-questions}{%
\chapter{Frequently Asked Questions}\label{frequently-asked-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Q.} What data structure does OBIS recommend?

  \textbf{A.} The OBIS-ENV Darwin Core Archive Data Structure. \href{https://manual.obis.org/data_format.html\#obis-holds-more-than-just-species-occurrences-the-env-data-approach}{OBIS manual}
\item
  \textbf{Q.} What is a controlled vocabulary, why use them?

  \textbf{A.} There are a number of controlled vocabularies that are used to describe parameters commonly used in specific research domains. Using terms defined in a controlled vocabulary allows for greater interoperability of data sets within the domain, and ideally between domains by ensuring that variables that are the same can be identified.
\item
  \textbf{Q.} What controlled vocabularies does OBIS rely on?

  \textbf{A.} \href{https://www.marinespecies.org/}{WoRMS}, \href{http://vocab.nerc.ac.uk/}{NERC Vocabulary Server} inlcuding:

  \begin{itemize}
  \tightlist
  \item
    \href{http://vocab.nerc.ac.uk/collection/L05/current/}{Device categories} using the SeaDataNet device categories
  \item
    \href{http://vocab.nerc.ac.uk/collection/L22/current/}{Device make/model using the SeaVoX Device Catalogue}
  \item
    \href{http://vocab.nerc.ac.uk/collection/L06/current/}{Platform categories using SeaVoX Platform Categories}
  \item
    \href{http://vocab.nerc.ac.uk/collection/C17/current/}{Platform instances using the ICES Platform Codes}
  \item
    \href{http://vocab.nerc.ac.uk/collection/P06/current/}{Unit of measure}
  \end{itemize}
\item
  \textbf{Q.} How can I find out which common measurementTypes are used in measurement or facts tables in existing OBIS datasets?

  \textbf{A.} See \href{https://mof.obis.org/}{Measurement Types in OBIS}
\item
  \textbf{Q.} What is an ontology?

  \textbf{A.} An ontology is a classification system for establishing a hierarchically related set of concepts. Concepts are often terms from controlled vocabularies. Ontologies can include all of the following, but are not required to include them.

  \begin{itemize}
  \tightlist
  \item
    Classes (general things, types of things)
  \item
    Instances (individual things)
  \item
    Relationships among things
  \item
    Properties of things
  \item
    Functions, processes, constraints, and rules relating to things
  \end{itemize}
\item
  \textbf{Q.} What is ERDDAP?

  \textbf{A.} \href{https://coastwatch.pfeg.noaa.gov/erddap/index.html}{ERDDAP} is a data server. It provides `easier access to scientific data' by providing a consistent interface that aggregates many disparate data sources. It does this by providing translation services between many common file types for gridded arrarys (`net CDF' files) and tabular data (spreadsheets). Data access is also made easier because it unifies different types of data servers and access protocols.
\item
  \textbf{Q.} What metadata profile does OBIS use?

  \textbf{A.} OBIS uses the \href{http://rs.gbif.org/schema/eml-gbif-profile/1.1/eml-gbif-profile.xsd}{GBIF EML profile} (version 1.1)
\item
  \textbf{Q.} Can Darwin Core be used in the Semantic Web/Resrouce Description Framework?

  \textbf{A.} See \href{https://dwc.tdwg.org/rdf/}{Darwin Core Resource Description Framework Guide} and \href{http://www.semantic-web-journal.net/system/files/swj1093.pdf}{Lessons learned from adapting the Darwin Core vocabulary standard for use in RDF}
\end{enumerate}

\hypertarget{tools}{%
\chapter{Tools}\label{tools}}

Below are some of the tools and packages used in workflows. R and Python package ``Type'' is BIO for packages specifically for biological applications, and GEN for generic packages.

\hypertarget{r}{%
\section{R}\label{r}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.28}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.39}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Package
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule
\endhead
\href{https://bdverse.org/}{bdveRse} & BIO & A family of R packages for biodiversity data. \\
\href{https://cran.r-project.org/web/packages/ecocomDP/index.html}{ecocomDP} & BIO & Work with the Ecological Community Data Design Pattern. `ecocomDP' is a flexible data model for harmonizing ecological community surveys, in a research question agnostic format, from source data published across repositories, and with methods that keep the derived data up-to-date as the underlying sources change. \\
\href{https://ediorg.github.io/EMLassemblyline/}{EDIorg/EMLasseblyline} & BIO & For scientists and data managers to create high quality EML metadata for dataset publication. \\
\href{https://cran.r-project.org/web/packages/finch/index.html}{finch} & BIO & Parse Darwin Core Files \\
\href{https://iobis.github.io/obistools/}{iobis/obistools} & BIO & Tools for data enhancement and quality control. \\
\href{https://cran.r-project.org/web/packages/robis/index.html}{robis} & BIO & R client for the OBIS API \\
\href{https://docs.ropensci.org/EML/}{ropensci/EML} & BIO & Provides support for the serializing and parsing of all low-level EML concepts \\
\href{https://cran.r-project.org/web/packages/taxize/index.html}{taxize} & BIO & Interacts with a suite of web `APIs' for taxonomic tasks, such as getting database specific taxonomic identifiers, verifying species names, getting taxonomic hierarchies, fetching downstream and upstream taxonomic names, getting taxonomic synonyms, converting scientific to common names and vice versa, and more. \\
\href{https://cran.r-project.org/web/packages/worrms/index.html}{worrms} & BIO & Client for \href{http://www.marinespecies.org/}{World Register of Marine Species}. Includes functions for each of the API methods, including searching for names by name, date and common names, searching using external identifiers, fetching synonyms, as well as fetching taxonomic children and taxonomic classification. \\
\href{https://www.rdocumentation.org/packages/Hmisc/versions/4.6-0}{Hmisc} & GEN & Contains many functions useful for data analysis, high-level graphics, utility operations, functions for computing sample size and power, simulation, importing and annotating datasets, imputing missing values, advanced table making, variable clustering, character string manipulation, conversion of R objects to LaTeX and html code, and recoding variables. Particularly check out the \href{https://www.rdocumentation.org/packages/Hmisc/versions/4.6-0/topics/describe}{describe()} function. \\
\href{https://cran.r-project.org/web/packages/lubridate/index.html}{lubridate} & GEN & Functions to work with date-times and time-spans: fast and user friendly parsing of date-time data, extraction and updating of components of a date-time (years, months, days, hours, minutes, and seconds), algebraic manipulation on date-time and time-span objects. \\
\href{https://cran.r-project.org/web/packages/stringr/index.html}{stringr} & GEN & Simple, Consistent Wrappers for Common String Operations \\
\href{https://cran.r-project.org/web/packages/tidyverse/index.html}{tidyverse} & GEN & The `tidyverse' is a set of packages that work in harmony because they share common data representations and `API' design. This package is designed to make it easy to install and load multiple `tidyverse' packages in a single step. \\
\href{https://cran.r-project.org/web/packages/uuid/index.html}{uuid} & GEN & Tools for generating and handling of UUIDs (Universally Unique Identifiers). \\
\bottomrule
\end{longtable}

\hypertarget{python}{%
\section{Python}\label{python}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.28}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.39}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Package
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule
\endhead
\href{https://pypi.org/project/metapype/}{metapype} & BIO & A lightweight Python 3 library for generating EML metadata \\
\href{https://python-dwca-reader.readthedocs.io/en/latest/index.html}{python-dwca-reader} & BIO & A simple Python package to read and parse Darwin Core Archive (DwC-A) files, as produced by the GBIF website, the IPT and many other biodiversity informatics tools. \\
\href{https://github.com/iobis/pyobis}{pyobis} & BIO & Pyobis is an interesting python package that helps users fetch data from OBIS API which harvests occurrence records from thousands of datasets and makes them available as a single integrated dataset. \\
\href{https://github.com/iobis/pyworms}{pyworms} & BIO & Python client for the World Register of Marine Species (WoRMS) REST service. \\
\href{https://numpy.org/}{numpy} & GEN & NumPy (Numerical Python) is an open source Python library that's used in almost every field of science and engineering. It's the universal standard for working with numerical data in Python, and it's at the core of the scientific Python and PyData ecosystems. \\
\href{https://pandas.pydata.org/}{pandas} & GEN & pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. Super helpful when manipulating tabular data! \\
\href{https://docs.python.org/3/library/uuid.html}{uuid} & GEN & This module provides immutable UUID objects (class UUID) and the functions uuid1(), uuid3(), uuid4(), uuid5() for generating version 1, 3, 4, and 5 UUIDs as specified in RFC 4122. Built in -- part of the Python standard library. \\
\href{https://github.com/iobis/obis-qc}{obis-qc} & BIO & Quality checks on occurrence records. Checks \texttt{occurrenceStatus}, \texttt{individualCount}, \texttt{eventDate}, \texttt{decimalLatitude}, \texttt{decimalLongitude}, \texttt{coordinateUncertaintyInMeters}, \texttt{minimumDepthInMeters}, \texttt{maximumDepthInMeters}, \texttt{scientificName}, \texttt{scientificNameID}. Checks from \href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4309024/pdf/bau125.pdf}{Vandepitte et al.} flags not implemented: 3, 9, 14, 15, 16, 10, 17, 21-30. \\
\href{https://biopython.org/}{biopython} & BIO & Biopython is a set of freely available tools for biological computation written in Python by an international team of developers. It is a distributed collaborative effort to develop Python libraries and applications which address the needs of current and future work in bioinformatics. \\
\bottomrule
\end{longtable}

\hypertarget{google-sheets}{%
\section{Google Sheets}\label{google-sheets}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.40}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.60}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Package
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule
\endhead
\href{https://dwcaassistant.com/}{Google Sheet DarwinCore Archive Assistant add-on} & Google Sheet add-on which assists the creation of Darwin Core Archives (DwCA) and publising to Zenodo. DwCA's are stored into user's Google Drive and can be downloaded for upload into IPT installations or other software which is able to read DwC-archives. \\
\bottomrule
\end{longtable}

\hypertarget{validators}{%
\section{Validators}\label{validators}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.29}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.71}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule
\endhead
\href{https://tools.gbif.org/dwca-validator/}{Darwin Core Archive Validator} & This validator verifies the structural integrity of a Darwin Core Archive. It does not check the data values, such as coordinates, dates or scientific names. \\
\href{https://www.gbif.org/tools/data-validator}{GBIF DATA VALIDATOR} & The GBIF data validator is a service that allows anyone with a GBIF-relevant dataset to receive a report on the syntactical correctness and the validity of the content contained within the dataset. \\
\href{https://www.lifewatch.be/data-services/}{LifeWatch Belgium} & Through this interactive section of the LifeWatch.be portal users can upload their own data using a standard data format, and choose from several web services, models and applications to process the data. \\
\bottomrule
\end{longtable}

\hypertarget{extras}{%
\chapter{Extras}\label{extras}}

Below is some more in-depth information into specific areas associated with standardizing your data to Darwin Core and uploading it through the IPT.

\hypertarget{ecological-metadata-language-eml}{%
\section{Ecological Metadata Language (EML)}\label{ecological-metadata-language-eml}}

The Ecological Metadata Language (EML) is a community developed and maintained metadata standard that is typically associated with ecological-, and earth and environmental data. The purpose of EML is to provide the ecological community with an extensible, flexible, metadata standard used in data analysis and archiving, which will allow automated machine processing, searching and retrieval. EML has been around since 2003, and can be considered a ``dialect'' or specification to XML to describe tables and other data objects. The XML Schema provides a framework for the metadata, with defined ``rules'' on how to organize the metadata without any stipulations (another way to put it, \emph{XML is the language that defines the rules that govern the EML syntax}). The XML Schema defines the structure of some information in a document (e.g.~elements and attributes names and relationships), but does not provide any specific details the information included within. An EML document or file (eml.xml) is used to provide detailed description of metadata related to data objects, including tables (and other data objects), their columns, typing etc, and how data tables are linked or grouped. EML is widely used for datasets about ecosystem level observations, and can be used to detail data table information to a high granularity, which allows data users to arrange data tables in any way they need to. EML is particularly useful for wide data tables as table level details are entirely contained within the metadata document, meaning that there is not necessarily a need for external definitions such as a code list. However, if you have a long table arrangement, like the Darwin Core Archive (DwC-A), you can define the allowable values for the column in the metadata as well.

EML is excellent at describing the details of a column of data so that the data values in the tables can be read into analysis systems or an analysis environment using the metadata, or even into a relational database. EML allows for tables to be easily reusable, and read into workflows, translated or reformatted. A drawback to EML is that, compared to the ISO standard, EML is a community standard, adopting a more `bottom-up' approach. This is contrary to the ISO standard, which are internationally agreed upon standards by experts (`top-down'). However, at the time of EML development in the early 2000's there was a gap in metadata options to describe ecological data tables, with ISO standards typically being more applicable to geographic data. EML can cover almost anything and is particularly good at tabular data. But at the same time, due to the self-contained nature, there can be little control from outside lists, which means that the description is left to the EML constructor (data provider/manager) and consequently, individual datasets can look quite different from each other, even when they contain similar measurements. As such, it will be important to document best practices and clear mapping of fields between different metadata schemas (e.g.~cross-walks between ISO.xml and EML.xml). As of version 2.2, EML can link to external ontologies, and there is capacity for annotation with external terms (e.g.~through their URIs). Code lists and external dictionaries can help as they sometimes contain additional information that might not fit into EML (e.g.~protocols, or code lists stored in ontologies). Having these external code lists and exporting them as EML snippets could go a long way in reducing that heterogeneity, because the constructors can then select measurements from lists when developing EML documents.

EML is implemented as a series of XML document types (modules) that can be used in an extensible manner to document ecological data. Each EML module is designed to describe one logical part of the total metadata that should be included with any ecological dataset. The architecture of EML was designed to serve the needs of the ecological community, and has benefitted from previous work in other related metadata standards. Using this format can facilitate future growth of the metadata language, and EML supports an active developer community (see e.g.~NCEAS EML GitHub). EML adopts much of its syntax from the other metadata standards that have evolved from the expertise of groups in other disciplines. Whenever possible, EML adopted entire trees of information in order to facilitate conversion of EML documents into other metadata languages. The GBIF IPT is a tool used to create a single eml.xml file format inside the DwC-A data package. However, the IPT does not use any of the EML's built-in table description modules, and perhaps primarily uses one EML module (resource module) for high-level metadata.

However, it is important to know how both OBIS and GBIF use EML, as often a higher granularity of the metadata can be found in the original data tables. An example of this is spatial coverage. The IPT only allows for either a bounding box to be documented (populating North, South, East, and West coordinates), or a single polygon. The EML document however would be able to capture multiple polygons worth of spatial coverage (i.e.~a polygon for each transect surveyed). This more detailed information however is often captured in the data (in an OBIS record). Additionally, not all fields that can be populated in an EML document can be translated to the IPT, or harvested by OBIS and GBIF. The GBIF IPT only produces a select number of fields or attributes available in EML.

\emph{Important}: When reading the EML section in the \href{https://obis.org/manual/eml/}{OBIS manual}, you'll notice that it reads that OBIS uses the GBIF EML profile (version 1.1). However, the current EML version is 2.2.0, as per \href{https://eml.ecoinformatics.org/}{EcoInformatics}. This does not mean that these versions are not compatible, rather, it means that the GBIF IPT currently uses a subset of available EML 2.2.0 fields and attributes, the subset of which they have versioned 1.1.

If you are interested in creating an EML metadata file, it is possible to upload those into the IPT. There are R packages that can help in developing an EML.xml file. These packages are e.g.~\href{https://github.com/ropensci/EML}{EML}, \href{https://github.com/ropensci/emld}{emld} or \href{https://ediorg.github.io/EMLassemblyline/articles/overview.html}{EMLassemblyline}.

\hypertarget{example-using-github-to-resolve-errors}{%
\section{Example using GitHub to resolve errors}\label{example-using-github-to-resolve-errors}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Dataset sent to OBIS-USA via email.
\item
  OBIS-USA uploaded to IPT.
\item
  Once the data were uploaded, the IPT identified there was an issue with the \texttt{occurrenceID} field. The issue was then
  presented and discussed in a GitHub ticket:
  \href{https://github.com/ioos/bio_data_guide/issues/78}{\includegraphics{./figs/issue_78.png}}
\item
  The data manager uploaded the raw data and code to GitHub through the pull request below. This included a fix for
  the \texttt{occurrenceID} issue.
  \href{https://github.com/ioos/bio_data_guide/pull/77}{\includegraphics{./figs/PR_77.png}}
\item
  The OBIS node manager was notified of the availability of a revised dataset by pointing directly to the appropriate
  commit in GitHub:
  \href{https://github.com/ioos/bio_data_guide/commit/ef17f89f23316a6227fdf58de509582bd9854a55}{\includegraphics{./figs/commit_ef17f89.png}}
\item
  The OBIS node manager downloaded the data from the commit above and uploaded them to the IPT.
\item
  The IPT returned a summary of the dataset including that 434 records had invalid \texttt{scientificNameID} records in the
  occurrence file.
\item
  After some data sleuthing, the data manager noticed that the code accidentally removed trailing zeros from
  \texttt{scientificNameID} that ended in \texttt{0}:
  \href{https://nbviewer.org/github/ioos/bio_data_guide/blob/ef17f89f23316a6227fdf58de509582bd9854a55/datasets/AMBON_zooplankton/2017zooplanton_to_dwc\%282\%29_mmb.ipynb\#END-of-ID-generation}{\includegraphics{./figs/code_snippet.png}}
\item
  So, the data manager updated the code to resolve the issue and generate a new occurrence file.
  \href{https://github.com/ioos/bio_data_guide/pull/82}{\includegraphics{./figs/PR_82.png}}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Here is fixing the \texttt{scientificNameID} generation: \includegraphics{./figs/code_change1.png}
  \item
    Here is removing the problematic code: \includegraphics{./figs/code_change2.png} \includegraphics{./figs/code_change3.png}
  \end{enumerate}
\item
  The revised occurrence file was then resubmitted to the OBIS node manager by pointing them at the appropriate commit
  record:
  \href{https://github.com/ioos/bio_data_guide/commit/a0919e5b788b0737fc4c8e2c4b874c2e287769dd}{\includegraphics{./figs/commit_a0919e.png}}
\item
  The OBIS node manager downloaded the data from the commit above and uploaded them to the IPT.
\item
  The IPT and OBIS landing page now indicated that no more issues with these data are present:
  \href{https://obis.org/dataset/bc01451e-d990-4ad1-8315-e3fb6e9cf461}{\includegraphics{./figs/obis_dataset.png}}
\end{enumerate}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}

\noindent

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-R-rmarkdown}{}}%
Allaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2023. \emph{Rmarkdown: Dynamic Documents for r}. \url{https://CRAN.R-project.org/package=rmarkdown}.

\leavevmode\vadjust pre{\hypertarget{ref-Barbier2017}{}}%
Barbier, Edward B. 2017. {``Marine Ecosystem Services.''} \emph{Current Biology}. Cell Press. \url{https://doi.org/10.1016/j.cub.2017.03.020}.

\leavevmode\vadjust pre{\hypertarget{ref-Benson2018}{}}%
Benson, Abigail, Cassandra M. Brooks, Gabrielle Canonico, Emmett Duffy, Frank Muller-Karger, Heidi M. Sosik, Patricia Miloslavich, and Eduardo Klein. 2018. {``Integrated Observations and Informatics Improve Understanding of Changing Marine Ecosystems.''} \emph{Frontiers in Marine Science}. Frontiers Media S.A. \url{https://doi.org/10.3389/fmars.2018.00428}.

\leavevmode\vadjust pre{\hypertarget{ref-benson_lascala-gruenewald_mcguinn_satterthwaite_beaulieu_biddle_dewitt_mckinzie_montes_moustahfid_etal_2021}{}}%
Benson, Abigail, Diana LaScala-Gruenewald, Robert McGuinn, Erin Satterthwaite, Stace Beaulieu, Mathew Biddle, Lynn deWitt, et al. 2021. {``Biological Observation Data Standardization - a Primer for Data Managers.''} ESIP. \url{https://doi.org/10.6084/m9.figshare.16806712.v1}.

\leavevmode\vadjust pre{\hypertarget{ref-article}{}}%
Benson, Abigail, Tylar Murray, Gabrielle Canonico, Enrique Montes, Frank Muller-Karger, Maria T. Kavanaugh, Joaquin Trinanes, and Lynn M. deWitt. 2021. {``Data Management and Interactive Visualizations for the Evolving Marine Biodiversity Observation Network.''} \emph{Oceanography}. \url{https://doi.org/10.5670/oceanog.2021.220}.

\leavevmode\vadjust pre{\hypertarget{ref-Borer2009}{}}%
Borer, Elizabeth T., Eric W. Seabloom, Matthew B. Jones, and Mark Schildhauer. 2009. {``Some Simple Guidelines for Effective Data Management.''} \emph{Bulletin of the Ecological Society of America} 90 (April). \url{https://doi.org/10.1890/0012-9623-90.2.205}.

\leavevmode\vadjust pre{\hypertarget{ref-Canonico2019}{}}%
Canonico, Gabrielle, Pier Luigi Buttigieg, Enrique Montes, Frank E. Muller-Karger, Carol Stepien, Dawn Wright, Abigail Benson, et al. 2019. {``Global Observational Needs and Resources for Marine Biodiversity.''} \emph{Frontiers in Marine Science}. Frontiers Media S.A. \url{https://doi.org/10.3389/fmars.2019.00367}.

\leavevmode\vadjust pre{\hypertarget{ref-Crystal-Ornela2021}{}}%
Crystal-Ornelas, Robert, Charuleka Varadharajan, Ben Bond-Lamberty, Kristin Boye, Madison Burrus, Shreyas Cholia, Michael Crow, et al. 2021. {``A Guide to Using GitHub for Developing and Versioning Data Standards and Reporting Formats.''} \emph{Earth and Space Science}, July, e2021EA001797. \url{https://doi.org/10.1029/2021EA001797}.

\leavevmode\vadjust pre{\hypertarget{ref-Davies2021}{}}%
Davies, Neil, John Deck, Eric C Kansa, Sarah Whitcher Kansa, John Kunze, Christopher Meyer, Thomas Orrell, et al. 2021. {``Internet of Samples (iSamples): Toward an Interdisciplinary Cyberinfrastructure for Material Samples.''} \emph{GigaScience} 10: 1--5. \url{https://doi.org/10.1093/gigascience/giab028}.

\leavevmode\vadjust pre{\hypertarget{ref-Djurhuus2020}{}}%
Djurhuus, Anni, Collin J. Closek, Ryan P. Kelly, Kathleen J. Pitz, Reiko P. Michisaki, Hilary A. Starks, Kristine R. Walz, et al. 2020. {``Environmental DNA Reveals Seasonal Shifts and Potential Interactions in a Marine Community.''} \emph{Nature Communications} 11 (December): 1--9. \url{https://doi.org/10.1038/s41467-019-14105-1}.

\leavevmode\vadjust pre{\hypertarget{ref-Duffy2013}{}}%
Duffy, J. Emmett, Linda A. Amaral-Zettler, Daphne G. Fautin, Gustav Paulay, Tatiana A. Rynearson, Heidi M. Sosik, and John J. Stachowicz. 2013. {``Envisioning a Marine Biodiversity Observation Network.''} \emph{BioScience} 63 (May): 350--61. \url{https://doi.org/10.1525/bio.2013.63.5.8}.

\leavevmode\vadjust pre{\hypertarget{ref-Fornwall2012}{}}%
Fornwall, M, R Gisiner, S E Simmons, H Moustahfid, G Canonico, P Halpin, P Goldstein, et al. 2012. {``Expanding Biological Data Standards Development Processes for US IOOS: Visual Line Transect Observing Community for Mammal, Bird, and Turtle Data.''} IOOS. \url{https://www.researchgate.net/publication/255681522}.

\leavevmode\vadjust pre{\hypertarget{ref-Hardisty2019}{}}%
Hardisty, Alex R., William K. Michener, Donat Agosti, Enrique Alonso García, Lucy Bastin, Lee Belbin, Anne Bowser, et al. 2019. {``The Bari Manifesto: An Interoperability Framework for Essential Biodiversity Variables.''} \emph{Ecological Informatics} 49 (January): 22--31. \url{https://doi.org/10.1016/j.ecoinf.2018.11.003}.

\leavevmode\vadjust pre{\hypertarget{ref-Heberling2021}{}}%
Heberling, J Mason, Joseph T Miller, Daniel Noesgaard, Scott B Weingart C, Dmitry Schigel, and Douglas E Soltis. 2021. {``Data Integration Enables Global Biodiversity Synthesis.''} \emph{Proceedings of the National Academy of Sciences of the United States of America}. \url{https://doi.org/10.1073/pnas.2018093118/-/DCSupplemental}.

\leavevmode\vadjust pre{\hypertarget{ref-Hare2016PLOS}{}}%
Jonathan A. Hare, Mark W. Nelson, Wendy E. Morrison. n.d. {``A Vulnerability Assessment of Fish and Invertebrates to Climate Change on the Northeast u.s. Continental Shelf.''} \emph{PLoS ONE} 11 (2): e0146756. \url{https://doi.org/10.1371/journal.pone.0146756}.

\leavevmode\vadjust pre{\hypertarget{ref-Jones2006}{}}%
Jones, Matthew B., Mark P. Schildhauer, O. J. Reichman, and Shawn Bowers. 2006. {``The New Bioinformatics: Integrating Ecological Data from the Gene to the Biosphere.''} \emph{Annual Review of Ecology, Evolution, and Systematics}. \url{https://doi.org/10.1146/annurev.ecolsys.37.091305.110031}.

\leavevmode\vadjust pre{\hypertarget{ref-Kavanaugh2016}{}}%
Kavanaugh, Maria T., Matthew J. Oliver, Francisco P. Chavez, Ricardo M. Letelier, Frank E. Muller-Karger, and Scott C. Doney. 2016. {``Seascapes as a New Vernacular for Pelagic Ocean Monitoring, Management and Conservation.''} \emph{ICES Journal of Marine Science} 73 (July): 1839--50. \url{https://doi.org/10.1093/icesjms/fsw086}.

\leavevmode\vadjust pre{\hypertarget{ref-Kot2010}{}}%
Kot, Connie Y., Ei Fujioka, Lucie J. Hazen, Benjamin D. Best, Andrew J. Read, and Patrick N. Halpin. 2010. {``Spatio-Temporal Gap Analysis of OBIS-SEAMAP Project Data: Assessment and Way Forward.''} \emph{PLoS ONE} 5 (September): 12990. \url{https://doi.org/10.1371/journal.pone.0012990}.

\leavevmode\vadjust pre{\hypertarget{ref-OceanAdapt}{}}%
Lab, Malin Pinksy. n.d. {``OceanAdapt.''} \emph{GitHub}. \url{https://oceanadapt.rutgers.edu/}.

\leavevmode\vadjust pre{\hypertarget{ref-Lamprecht2019}{}}%
Lamprecht, Anna-Lena, Leyla Garcia, Mateusz Kuzak, Carlos Martinez, Ricardo Arcila, Eva Martin Del Pico, Victoria Dominguez Del Angel, et al. 2019. {``Towards FAIR Principles for Research Software.''} Edited by Paul Groth. \emph{Data Science}, 1--23. \url{https://doi.org/10.3233/DS-190026}.

\leavevmode\vadjust pre{\hypertarget{ref-Dornelas2014Science}{}}%
Maria Dornelas, Brian McGill, Nicholas J. Gotelli. 2014. {``Assemblage Time Series Reveal Biodiversity Change but Not Systematic Loss.''} \emph{Science} 344 (6181): 296--99. \url{https://doi.org/10.1126/science.1248484}.

\leavevmode\vadjust pre{\hypertarget{ref-McKenna2021}{}}%
McKenna, Megan F., Simone Baumann-Pickering, Annebelle C. M. Kok, William K. Oestreich, Jeffrey D. Adams, Jack Barkowski, Kurt M. Fristrup, et al. 2021. {``Advancing the Interpretation of Shallow Water Marine Soundscapes.''} \emph{Frontiers in Marine Science} 0 (September): 1426. \url{https://doi.org/10.3389/FMARS.2021.719258}.

\leavevmode\vadjust pre{\hypertarget{ref-Miloslavich2018}{}}%
Miloslavich, Patricia, Nicholas J. Bax, Samantha E. Simmons, Eduardo Klein, Ward Appeltans, Octavio Aburto-Oropeza, Melissa Andersen Garcia, et al. 2018. {``Essential Ocean Variables for Global Sustained Observations of Biodiversity and Ecosystem Changes.''} \emph{Global Change Biology} 24 (June): 2416--33. \url{https://doi.org/10.1111/gcb.14108}.

\leavevmode\vadjust pre{\hypertarget{ref-Montes2020}{}}%
Montes, Enrique, Anni Djurhuus, Frank E. Muller-Karger, Daniel Otis, Christopher R. Kelble, and Maria T. Kavanaugh. 2020. {``Dynamic Satellite Seascapes as a Biogeographic Framework for Understanding Phytoplankton Assemblages in the Florida Keys National Marine Sanctuary, United States.''} \emph{Frontiers in Marine Science} 7 (July): 575. \url{https://doi.org/10.3389/fmars.2020.00575}.

\leavevmode\vadjust pre{\hypertarget{ref-Moustahfid2014}{}}%
Moustahfid, Hassan, and Philip Goldstein. 2014. {``IOOS Biological Data Services Enrollment Procedures.''}

\leavevmode\vadjust pre{\hypertarget{ref-Moustahfid2011}{}}%
Moustahfid, Hassan, Jim Potemra, Philip Goldstein, Roy Mendelssohn, and Annette Desrochers. 2011. {``Making United States Integrated Ocean Observing System (u.s. IOOS) Inclusive of Marine Biological Resources.''} \url{https://www.researchgate.net/publication/254013004}.

\leavevmode\vadjust pre{\hypertarget{ref-Muller-Karger2018b}{}}%
Muller-Karger, Frank E., Erin Hestir, Christiana Ade, Kevin Turpie, Dar A. Roberts, David Siegel, Robert J. Miller, et al. 2018. {``Satellite Sensor Requirements for Monitoring Essential Biodiversity Variables of Coastal Ecosystems.''} \emph{Ecological Applications} 28 (April): 749--60. \url{https://doi.org/10.1002/eap.1682}.

\leavevmode\vadjust pre{\hypertarget{ref-Muller-Karger2018a}{}}%
Muller-Karger, Frank E., Patricia Miloslavich, Nicholas J. Bax, Samantha Simmons, Mark J. Costello, Isabel Sousa Pinto, Gabrielle Canonico, et al. 2018. {``Advancing Marine Biological Observations and Data Requirements of the Complementary Essential Ocean Variables (EOVs) and Essential Biodiversity Variables (EBVs) Frameworks.''} \emph{Frontiers in Marine Science}. Frontiers Media S.A. \url{https://doi.org/10.3389/fmars.2018.00211}.

\leavevmode\vadjust pre{\hypertarget{ref-Neeley2021}{}}%
Neeley, Aimee, Stace E. Beaulieu, Chris Proctor, Ivona Cetinić, Joe Futrelle, Inia Soto Ramos, Heidi M. Sosik, et al. 2021. {``Standards and Practices for Reporting Plankton and Other Particle Observations from Images.''} \url{https://doi.org/10.1575/1912/27377}.

\leavevmode\vadjust pre{\hypertarget{ref-Obrien2021}{}}%
O'Brien, Margaret, Colin A. Smith, Eric R. Sokol, Corinna Gries, Nina Lany, Sydne Record, and Max C. N. Castorani. 2021. {``ecocomDP: A Flexible Data Design Pattern for Ecological Community Survey Data.''} \emph{Ecological Informatics} 64 (September): 101374. \url{https://doi.org/10.1016/J.ECOINF.2021.101374}.

\leavevmode\vadjust pre{\hypertarget{ref-Pooter2017}{}}%
Pooter, Daphnis De, Ward Appeltans, Nicolas Bailly, Sky Bristol, Klaas Deneudt, Menashè Eliezer, Ei Fujioka, et al. 2017. {``Toward a New Data Standard for Combined Marine Biological and Environmental Datasets - Expanding OBIS Beyond Species Occurrences.''} \emph{Biodiversity Data Journal} 5 (January): 10989. \url{https://doi.org/10.3897/BDJ.5.e10989}.

\leavevmode\vadjust pre{\hypertarget{ref-iobis_ebsa}{}}%
Provoost, Pieter. n.d. {``Iobis/Ebsa.''} \emph{GitHub}. \url{https://github.com/iobis/ebsa}.

\leavevmode\vadjust pre{\hypertarget{ref-R-base}{}}%
R Core Team. 2021. \emph{R: A Language and Environment for Statistical Computing}. Vienna, Austria: R Foundation for Statistical Computing. \url{https://www.R-project.org/}.

\leavevmode\vadjust pre{\hypertarget{ref-Ruxfccknagel2015}{}}%
Rücknagel, J., P. Vierkant, R. Ulrich, G. Kloska, E. Schnepf, D. Fichtmüller, E. Reuter, et al. 2015. {``Metadata Schema for the Description of Research Data Repositories. Version 3.0.''} \url{https://doi.org/10.2312/re3.008}.

\leavevmode\vadjust pre{\hypertarget{ref-Rule2019}{}}%
Rule, Adam, Amanda Birmingham, Cristal Zuniga, Ilkay Altintas, Shih-Cheng Huang, Rob Knight, Niema Moshiri, et al. 2019. {``Ten Simple Rules for Writing and Sharing Computational Analyses in Jupyter Notebooks.''} \emph{PLOS Computational Biology} 15 (July): e1007007. \url{https://doi.org/10.1371/JOURNAL.PCBI.1007007}.

\leavevmode\vadjust pre{\hypertarget{ref-Santora2017}{}}%
Santora, Jarrod A., Elliott L. Hazen, Isaac D. Schroeder, Steven J. Bograd, Keith M. Sakuma, and John C. Field. 2017. {``Impacts of Ocean Climate Variability on Biodiversity of Pelagic Forage Species in an Upwelling Ecosystem.''} \emph{Marine Ecology Progress Series} 580 (September): 205--20. \url{https://doi.org/10.3354/meps12278}.

\leavevmode\vadjust pre{\hypertarget{ref-Schmid_Daprano_Jacobson_Sullivan_Briseuxf1o-Avena_Luo_Cowen_2021}{}}%
Schmid, Moritz S, Dominic Daprano, Kyler M Jacobson, Christopher Sullivan, Christian Briseño-Avena, Jessica Y Luo, and Robert K Cowen. 2021. \emph{A Convolutional Neural Network Based High-Throughput Image Classification Pipeline - Code and Documentation to Process Plankton Underwater Imagery Using Local HPC Infrastructure and NSF's XSEDE}. Zenodo. \url{https://doi.org/10.5281/ZENODO.4641158}.

\leavevmode\vadjust pre{\hypertarget{ref-Taylor2012}{}}%
Taylor, Gordon T., Frank E. Muller-Karger, Robert C. Thunell, Mary I. Scranton, Yrene Astor, Ramon Varela, Luis Troccoli Ghinaglia, et al. 2012. {``Ecosystem Responses in the Southern Caribbean Sea to Global Climate Change.''} \emph{Proceedings of the National Academy of Sciences of the United States of America} 109 (November): 19315--20. \url{https://doi.org/10.1073/pnas.1207514109}.

\leavevmode\vadjust pre{\hypertarget{ref-tittensor2010global}{}}%
Tittensor, Derek P, Camilo Mora, Walter Jetz, Heike K Lotze, Daniel Ricard, Edward Vanden Berghe, and Boris Worm. 2010. {``Global Patterns and Predictors of Marine Biodiversity Across Taxa.''} \emph{Nature} 466 (7310): 1098.

\leavevmode\vadjust pre{\hypertarget{ref-Warren2018}{}}%
Warren, R., J. Price, E. Graham, N. Forstenhaeusler, and J. VanDerWal. 2018. {``The Projected Effect on Insects, Vertebrates, and Plants of Limiting Global Warming to 1.5°c Rather Than 2°c.''} \emph{Science} 360 (May): 791--95. \url{https://doi.org/10.1126/science.aar3646}.

\leavevmode\vadjust pre{\hypertarget{ref-Wieczorek2012}{}}%
Wieczorek, John, David Bloom, Robert Guralnick, Stan Blum, Markus Döring, Renato Giovanni, Tim Robertson, and David Vieglais. 2012. {``Darwin Core: An Evolving Community-Developed Biodiversity Data Standard.''} \emph{PLoS ONE} 7 (January): 29715. \url{https://doi.org/10.1371/journal.pone.0029715}.

\leavevmode\vadjust pre{\hypertarget{ref-Wilkinson2016}{}}%
Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. {``The FAIR Guiding Principles for Scientific Data Management and Stewardship.''} \emph{Scientific Data} 3 (March): 1--9. \url{https://doi.org/10.1038/sdata.2016.18}.

\leavevmode\vadjust pre{\hypertarget{ref-knitr2014}{}}%
Xie, Yihui. 2014. {``Knitr: A Comprehensive Tool for Reproducible Research in {R}.''} In \emph{Implementing Reproducible Computational Research}, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC.

\leavevmode\vadjust pre{\hypertarget{ref-xie2015}{}}%
---------. 2015b. \emph{Dynamic Documents with {R} and Knitr}. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. \url{http://yihui.name/knitr/}.

\leavevmode\vadjust pre{\hypertarget{ref-knitr2015}{}}%
---------. 2015a. \emph{Dynamic Documents with {R} and Knitr}. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. \url{https://yihui.org/knitr/}.

\leavevmode\vadjust pre{\hypertarget{ref-bookdown2016}{}}%
---------. 2016. \emph{Bookdown: Authoring Books and Technical Documents with {R} Markdown}. Boca Raton, Florida: Chapman; Hall/CRC. \url{https://bookdown.org/yihui/bookdown}.

\leavevmode\vadjust pre{\hypertarget{ref-R-knitr}{}}%
---------. 2023. \emph{Knitr: A General-Purpose Package for Dynamic Report Generation in r}. \url{https://yihui.org/knitr/}.

\leavevmode\vadjust pre{\hypertarget{ref-R-bookdown}{}}%
---------. 2024. \emph{Bookdown: Authoring Books and Technical Documents with r Markdown}. \url{https://CRAN.R-project.org/package=bookdown}.

\leavevmode\vadjust pre{\hypertarget{ref-rmarkdown2018}{}}%
Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. \emph{R Markdown: The Definitive Guide}. Boca Raton, Florida: Chapman; Hall/CRC. \url{https://bookdown.org/yihui/rmarkdown}.

\leavevmode\vadjust pre{\hypertarget{ref-rmarkdown2020}{}}%
Xie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. \emph{R Markdown Cookbook}. Boca Raton, Florida: Chapman; Hall/CRC. \url{https://bookdown.org/yihui/rmarkdown-cookbook}.

\end{CSLReferences}

\end{document}
