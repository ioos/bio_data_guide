{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxGSbpxdStLu"
      },
      "source": [
        "Gemini prompt:\n",
        "\n",
        "> Using python, can you download the .nc files found at https://www.ncei.noaa.gov/data/oceans/ioos/atn/california_state_university_long_beach/ and convert them to the Darwin Core standard? Assign an occurrence as the first detection per location per hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0JvPXasXc432"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import xarray as xr\n",
        "import netCDF4\n",
        "from geopy.geocoders import Nominatim\n",
        "import re\n",
        "from jinja2 import Template\n",
        "import codecs\n",
        "#import pyobistools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtUi2y_3cwZq"
      },
      "source": [
        "## Create a function to recursively download files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "puONkrPNceM5"
      },
      "outputs": [],
      "source": [
        "def recursive_wget(url, output_dir):\n",
        "    \"\"\"\n",
        "    Recursively downloads files from a given URL to a specified output directory,\n",
        "    mirroring the directory structure of the website.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to start downloading from.\n",
        "        output_dir (str): The local directory to save files to.\n",
        "    \"\"\"\n",
        "    print(f\"Accessing: {url}\")\n",
        "    try:\n",
        "        # --- Create the output directory if it doesn't exist ---\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "            print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "        # --- Send a GET request and parse the HTML ---\n",
        "        response = requests.get(url)\n",
        "        # Raise an exception for bad status codes (like 404 Not Found)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # --- Find all links on the page ---\n",
        "        for link in soup.find_all('a'):\n",
        "            href = link.get('href')\n",
        "\n",
        "            # --- Skip invalid or parent directory links ---\n",
        "            if not href or href.startswith('?') or href.startswith('/') or '..' in href:\n",
        "                continue\n",
        "\n",
        "            # --- Construct the full, absolute URL for the link ---\n",
        "            absolute_url = urljoin(url, href)\n",
        "\n",
        "            # Get the path component of the URL to create local directories/files\n",
        "            path = urlparse(absolute_url).path\n",
        "            # Create a valid local path from the last part of the URL path\n",
        "            local_path = os.path.join(output_dir, os.path.basename(path))\n",
        "\n",
        "            # --- If the link points to a directory, recurse into it ---\n",
        "            if href.endswith('/'):\n",
        "                print(f\"\\nEntering directory: {absolute_url}\")\n",
        "                # Call the function again for the new directory\n",
        "                recursive_wget(absolute_url, local_path)\n",
        "            # --- If the link points to a file, download it ---\n",
        "            else:\n",
        "                download_file(absolute_url, local_path)\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP Error accessing URL {url}: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing URL {url}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "def download_file(url, local_path):\n",
        "    \"\"\"\n",
        "    Downloads a single file from a URL and saves it to a local path.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        local_path (str): The local path where the file will be saved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"  Downloading file: {os.path.basename(local_path)}\")\n",
        "        # Use stream=True to efficiently download large files\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            # Open the file in binary write mode\n",
        "            with open(local_path, 'wb') as f:\n",
        "                # Write the file in chunks\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "        # print(f\"  Successfully downloaded {os.path.basename(local_path)}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"  Failed to download {url}: {e}\")\n",
        "    except IOError as e:\n",
        "        print(f\"  Failed to write file {local_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCEbQSINcjQm"
      },
      "source": [
        "## Execute download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W39rehjcioS",
        "outputId": "b1730911-fc6e-481a-c079-977dbaf17f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Recursive Download ---\n",
            "Source URL: https://www.ncei.noaa.gov/data/oceans/ioos/atn/\n",
            "Local Directory: data/src/\n",
            "\n",
            "Accessing: https://www.ncei.noaa.gov/data/oceans/ioos/atn/\n",
            "  Downloading file: ACCESSION_UPDATE_LOG.TXT\n",
            "\n",
            "Entering directory: https://www.ncei.noaa.gov/data/oceans/ioos/atn/california_state_university_long_beach/\n",
            "Accessing: https://www.ncei.noaa.gov/data/oceans/ioos/atn/california_state_university_long_beach/\n",
            "  Downloading file: atn_45866_great-white-shark_trajectory_20090923-20091123.nc\n",
            "  Downloading file: atn_45869_great-white-shark_trajectory_20090923-20091213.nc\n",
            "\n",
            "Entering directory: https://www.ncei.noaa.gov/data/oceans/ioos/atn/cascadia_research_collective/\n",
            "Accessing: https://www.ncei.noaa.gov/data/oceans/ioos/atn/cascadia_research_collective/\n",
            "  Downloading file: atn_53631_false-killer-whale_trajectory_20100927-20101001.nc\n",
            "  Downloading file: atn_53644_false-killer-whale_trajectory_20100927-20101118.nc\n",
            "  Downloading file: atn_53652_false-killer-whale_trajectory_20101023-20101213.nc\n",
            "  Downloading file: atn_77250_false-killer-whale_trajectory_20070816-20070830.nc\n",
            "  Downloading file: atn_77250_false-killer-whale_trajectory_20080422-20080513.nc\n",
            "  Downloading file: atn_77251_false-killer-whale_trajectory_20070816-20070818.nc\n",
            "  Downloading file: atn_77252_false-killer-whale_trajectory_20070816-20070917.nc\n",
            "  Downloading file: atn_77252_false-killer-whale_trajectory_20080727-20080915.nc\n",
            "  Downloading file: atn_77253_false-killer-whale_trajectory_20080727-20080824.nc\n",
            "  Downloading file: atn_85567_false-killer-whale_trajectory_20081211-20090203.nc\n",
            "  Downloading file: atn_85568_short-finned-pilot-whale_trajectory_20080705-20080802.nc\n",
            "  Downloading file: atn_85586_false-killer-whale_trajectory_20080717-20080821.nc\n",
            "  Downloading file: atn_85587_false-killer-whale_trajectory_20080717-20080806.nc\n",
            "  Downloading file: atn_85588_false-killer-whale_trajectory_20080717-20080911.nc\n",
            "  Downloading file: atn_85589_false-killer-whale_trajectory_20080717-20080723.nc\n",
            "  Downloading file: atn_85590_false-killer-whale_trajectory_20080717-20081001.nc\n",
            "  Downloading file: atn_94793_false-killer-whale_trajectory_20091018-20091227.nc\n",
            "  Downloading file: atn_94804_false-killer-whale_trajectory_20101016-20101029.nc\n",
            "  Downloading file: atn_94808_false-killer-whale_trajectory_20091014-20091025.nc\n",
            "  Downloading file: atn_94811_false-killer-whale_trajectory_20091006-20100103.nc\n",
            "  Downloading file: atn_94812_false-killer-whale_trajectory_20091015-20100122.nc\n",
            "  Downloading file: atn_94813_false-killer-whale_trajectory_20091017-20091117.nc\n",
            "  Downloading file: atn_94818_false-killer-whale_trajectory_20091211-20100320.nc\n",
            "  Downloading file: atn_94819_false-killer-whale_trajectory_20091211-20091227.nc\n",
            "  Downloading file: atn_94820_false-killer-whale_trajectory_20091219-20100403.nc\n",
            "  Downloading file: atn_94821_blainvilles-beaked-whale_trajectory_20091221-20100111.nc\n",
            "  Downloading file: atn_94822_false-killer-whale_trajectory_20091219-20100129.nc\n",
            "  Downloading file: atn_98364_false-killer-whale_trajectory_20131023-20140223.nc\n",
            "  Downloading file: atn_98365_false-killer-whale_trajectory_20131023-20131107.nc\n",
            "\n",
            "Entering directory: https://www.ncei.noaa.gov/data/oceans/ioos/atn/marine_mammal_laboratory_noaa_alaska_fisheries_science_center/\n",
            "Accessing: https://www.ncei.noaa.gov/data/oceans/ioos/atn/marine_mammal_laboratory_noaa_alaska_fisheries_science_center/\n",
            "  Downloading file: atn_37515_spotted-seal_trajectory_20100522-20110423.nc\n",
            "  Downloading file: atn_37909_spotted-seal_trajectory_20140427-20140921.nc\n",
            "  Downloading file: atn_38549_spotted-seal_trajectory_20140429-20140613.nc\n",
            "  Downloading file: atn_39482_spotted-seal_trajectory_20140427-20141022.nc\n",
            "  Downloading file: atn_39486_ribbon-seal_trajectory_20100517-20100917.nc\n",
            "  Downloading file: atn_39490_ribbon-seal_trajectory_20140426-20140526.nc\n",
            "  Downloading file: atn_39491_ribbon-seal_trajectory_20100516-20100518.nc\n",
            "  Downloading file: atn_39496_ribbon-seal_trajectory_20100523-20101216.nc\n",
            "  Downloading file: atn_39498_ribbon-seal_trajectory_20140427-20140509.nc\n",
            "  Downloading file: atn_39499_ribbon-seal_trajectory_20140419-20140428.nc\n",
            "  Downloading file: atn_40857_ribbon-seal_trajectory_20100523-20110408.nc\n",
            "  Downloading file: atn_40858_ribbon-seal_trajectory_20140421-20140426.nc\n",
            "  Downloading file: atn_40862_ribbon-seal_trajectory_20140420-20140428.nc\n",
            "  Downloading file: atn_57998_ribbon-seal_trajectory_20050525-20060508.nc\n",
            "  Downloading file: atn_57999_spotted-seal_trajectory_20050925-20060521.nc\n",
            "  Downloading file: atn_58000_ribbon-seal_trajectory_20050601-20060403.nc\n",
            "  Downloading file: atn_58001_spotted-seal_trajectory_20050926-20051215.nc\n",
            "  Downloading file: atn_58002_spotted-seal_trajectory_20050926-20051223.nc\n",
            "  Downloading file: atn_58003_spotted-seal_trajectory_20050928-20060428.nc\n",
            "  Downloading file: atn_58005_ribbon-seal_trajectory_20050601-20060508.nc\n",
            "  Downloading file: atn_58006_ribbon-seal_trajectory_20050602-20060220.nc\n",
            "  Downloading file: atn_58007_ribbon-seal_trajectory_20050602-20050603.nc\n",
            "  Downloading file: atn_58008_ribbon-seal_trajectory_20050602-20060508.nc\n",
            "  Downloading file: atn_58009_ribbon-seal_trajectory_20050606-20051215.nc\n",
            "  Downloading file: atn_58010_ribbon-seal_trajectory_20050607-20051213.nc\n",
            "  Downloading file: atn_58011_ribbon-seal_trajectory_20050602-20050604.nc\n",
            "  Downloading file: atn_58012_ribbon-seal_trajectory_20050607-20060421.nc\n",
            "  Downloading file: atn_58014_spotted-seal_trajectory_20050929-20060329.nc\n",
            "  Downloading file: atn_62755_spotted-seal_trajectory_20060424-20060506.nc\n",
            "  Downloading file: atn_62756_spotted-seal_trajectory_20060427-20060513.nc\n",
            "  Downloading file: atn_64451_spotted-seal_trajectory_20090518-20090612.nc\n",
            "  Downloading file: atn_64452_spotted-seal_trajectory_20090528-20090612.nc\n",
            "  Downloading file: atn_64453_ribbon-seal_trajectory_20090606-20090612.nc\n",
            "  Downloading file: atn_64455_spotted-seal_trajectory_20090517-20100430.nc\n",
            "  Downloading file: atn_64457_ribbon-seal_trajectory_20090603-20090613.nc\n",
            "  Downloading file: atn_64460_spotted-seal_trajectory_20090518-20090618.nc\n",
            "  Downloading file: atn_64461_ribbon-seal_trajectory_20090607-20100524.nc\n",
            "  Downloading file: atn_64463_spotted-seal_trajectory_20090528-20090620.nc\n",
            "  Downloading file: atn_64464_ribbon-seal_trajectory_20090531-20100506.nc\n",
            "  Downloading file: atn_64465_ribbon-seal_trajectory_20090602-20090607.nc\n",
            "  Downloading file: atn_64467_ribbon-seal_trajectory_20090606-20100531.nc\n",
            "  Downloading file: atn_64469_ribbon-seal_trajectory_20090607-20110526.nc\n",
            "  Downloading file: atn_64471_ribbon-seal_trajectory_20090605-20100522.nc\n",
            "  Downloading file: atn_64472_ribbon-seal_trajectory_20090602-20090607.nc\n",
            "  Downloading file: atn_64473_spotted-seal_trajectory_20090518-20090618.nc\n",
            "  Downloading file: atn_64476_ribbon-seal_trajectory_20090528-20100603.nc\n",
            "  Downloading file: atn_64477_spotted-seal_trajectory_20090528-20100422.nc\n",
            "  Downloading file: atn_64478_ribbon-seal_trajectory_20090531-20091230.nc\n",
            "  Downloading file: atn_64479_ribbon-seal_trajectory_20090607-20100126.nc\n",
            "  Downloading file: atn_64481_ribbon-seal_trajectory_20090604-20091221.nc\n",
            "  Downloading file: atn_64482_ribbon-seal_trajectory_20090603-20100514.nc\n",
            "  Downloading file: atn_64483_ribbon-seal_trajectory_20100505-20100928.nc\n",
            "  Downloading file: atn_64484_ribbon-seal_trajectory_20090530-20100326.nc\n",
            "  Downloading file: atn_64485_spotted-seal_trajectory_20090603-20091023.nc\n",
            "  Downloading file: atn_64486_ribbon-seal_trajectory_20090601-20100426.nc\n",
            "  Downloading file: atn_64488_spotted-seal_trajectory_20090606-20100310.nc\n",
            "  Downloading file: atn_64489_ribbon-seal_trajectory_20090529-20100502.nc\n",
            "  Downloading file: atn_64490_ribbon-seal_trajectory_20090531-20100105.nc\n",
            "  Downloading file: atn_64491_ribbon-seal_trajectory_20090529-20090617.nc\n",
            "  Downloading file: atn_64492_ribbon-seal_trajectory_20090602-20100116.nc\n",
            "  Downloading file: atn_64706_ribbon-seal_trajectory_20060427-20060520.nc\n",
            "  Downloading file: atn_64707_ribbon-seal_trajectory_20060502-20060505.nc\n",
            "  Downloading file: atn_64708_ribbon-seal_trajectory_20060503-20060527.nc\n",
            "  Downloading file: atn_64709_ribbon-seal_trajectory_20060502-20060511.nc\n",
            "  Downloading file: atn_64710_ribbon-seal_trajectory_20060503-20060520.nc\n",
            "  Downloading file: atn_64712_spotted-seal_trajectory_20060503-20060506.nc\n",
            "  Downloading file: atn_64713_spotted-seal_trajectory_20060503-20060518.nc\n",
            "  Downloading file: atn_64714_spotted-seal_trajectory_20060501-20060513.nc\n",
            "  Downloading file: atn_64715_ribbon-seal_trajectory_20060503-20060527.nc\n",
            "  Downloading file: atn_64717_spotted-seal_trajectory_20060503-20060516.nc\n",
            "  Downloading file: atn_64899_ribbon-seal_trajectory_20090604-20090612.nc\n",
            "  Downloading file: atn_65922_ribbon-seal_trajectory_20060506-20060508.nc\n",
            "  Downloading file: atn_65924_ribbon-seal_trajectory_20060502-20060618.nc\n",
            "  Downloading file: atn_65925_ribbon-seal_trajectory_20060505-20060525.nc\n",
            "  Downloading file: atn_65926_ribbon-seal_trajectory_20060503-20060516.nc\n",
            "  Downloading file: atn_65927_ribbon-seal_trajectory_20070522-20080107.nc\n",
            "  Downloading file: atn_65928_ribbon-seal_trajectory_20070517-20080402.nc\n",
            "  Downloading file: atn_65931_ribbon-seal_trajectory_20070522-20080130.nc\n",
            "  Downloading file: atn_65932_spotted-seal_trajectory_20060506-20060620.nc\n",
            "  Downloading file: atn_65933_spotted-seal_trajectory_20060427-20060511.nc\n",
            "  Downloading file: atn_66928_ribbon-seal_trajectory_20140426-20140518.nc\n",
            "  Downloading file: atn_66949_ribbon-seal_trajectory_20140415-20140503.nc\n",
            "  Downloading file: atn_66973_spotted-seal_trajectory_20140427-20141222.nc\n",
            "  Downloading file: atn_66978_spotted-seal_trajectory_20140429-20141201.nc\n",
            "  Downloading file: atn_66989_ribbon-seal_trajectory_20140428-20140518.nc\n",
            "  Downloading file: atn_66990_ribbon-seal_trajectory_20140428-20140501.nc\n",
            "  Downloading file: atn_67000_spotted-seal_trajectory_20140429-20140721.nc\n",
            "  Downloading file: atn_67003_ribbon-seal_trajectory_20140428-20140519.nc\n",
            "  Downloading file: atn_67026_ribbon-seal_trajectory_20140427-20141108.nc\n",
            "  Downloading file: atn_74629_ribbon-seal_trajectory_20070529-20080404.nc\n",
            "  Downloading file: atn_74631_spotted-seal_trajectory_20090606-20100504.nc\n",
            "  Downloading file: atn_74633_spotted-seal_trajectory_20090518-20090731.nc\n",
            "  Downloading file: atn_74634_ribbon-seal_trajectory_20090602-20100222.nc\n",
            "  Downloading file: atn_74635_spotted-seal_trajectory_20090523-20091028.nc\n",
            "  Downloading file: atn_74636_ribbon-seal_trajectory_20090528-20100209.nc\n",
            "  Downloading file: atn_74637_spotted-seal_trajectory_20100506-20110410.nc\n",
            "  Downloading file: atn_74638_ribbon-seal_trajectory_20100510-20100605.nc\n",
            "  Downloading file: atn_74639_ribbon-seal_trajectory_20070524-20070902.nc\n",
            "  Downloading file: atn_74640_ribbon-seal_trajectory_20070529-20071022.nc\n",
            "  Downloading file: atn_74641_ribbon-seal_trajectory_20070527-20071103.nc\n",
            "  Downloading file: atn_74642_spotted-seal_trajectory_20070508-20071123.nc\n",
            "  Downloading file: atn_74643_ribbon-seal_trajectory_20070525-20080502.nc\n",
            "  Downloading file: atn_74644_spotted-seal_trajectory_20070507-20080303.nc\n",
            "  Downloading file: atn_74645_ribbon-seal_trajectory_20070524-20070605.nc\n",
            "  Downloading file: atn_74646_ribbon-seal_trajectory_20070528-20100529.nc\n",
            "  Downloading file: atn_74647_ribbon-seal_trajectory_20070520-20080612.nc\n",
            "  Downloading file: atn_74648_ribbon-seal_trajectory_20070523-20080402.nc\n",
            "  Downloading file: atn_74649_ribbon-seal_trajectory_20070524-20070614.nc\n",
            "  Downloading file: atn_74650_ribbon-seal_trajectory_20070525-20080617.nc\n",
            "  Downloading file: atn_74651_ribbon-seal_trajectory_20070516-20080613.nc\n",
            "  Downloading file: atn_74652_ribbon-seal_trajectory_20070523-20080502.nc\n",
            "  Downloading file: atn_74653_ribbon-seal_trajectory_20070518-20100426.nc\n",
            "  Downloading file: atn_74654_spotted-seal_trajectory_20070520-20070713.nc\n",
            "  Downloading file: atn_74655_spotted-seal_trajectory_20070526-20080619.nc\n",
            "  Downloading file: atn_74656_spotted-seal_trajectory_20070524-20070613.nc\n",
            "  Downloading file: atn_74657_ribbon-seal_trajectory_20070518-20070608.nc\n",
            "  Downloading file: atn_74658_spotted-seal_trajectory_20070520-20070613.nc\n",
            "  Downloading file: atn_74662_ribbon-seal_trajectory_20070527-20070626.nc\n",
            "  Downloading file: atn_74664_ribbon-seal_trajectory_20070518-20080621.nc\n",
            "  Downloading file: atn_74665_ribbon-seal_trajectory_20070522-20080614.nc\n",
            "  Downloading file: atn_74666_spotted-seal_trajectory_20070524-20070629.nc\n",
            "  Downloading file: atn_74670_ribbon-seal_trajectory_20090609-20100607.nc\n",
            "  Downloading file: atn_74672_ribbon-seal_trajectory_20070527-20080622.nc\n",
            "  Downloading file: atn_74673_ribbon-seal_trajectory_20070510-20070611.nc\n",
            "  Downloading file: atn_74674_spotted-seal_trajectory_20070521-20090601.nc\n",
            "  Downloading file: atn_74677_ribbon-seal_trajectory_20070523-20090522.nc\n",
            "  Downloading file: atn_74679_ribbon-seal_trajectory_20070523-20070613.nc\n",
            "  Downloading file: atn_74681_spotted-seal_trajectory_20070424-20070701.nc\n",
            "  Downloading file: atn_74682_ribbon-seal_trajectory_20070526-20080610.nc\n",
            "  Downloading file: atn_74685_spotted-seal_trajectory_20070424-20070625.nc\n",
            "  Downloading file: atn_74688_ribbon-seal_trajectory_20070527-20071115.nc\n",
            "  Downloading file: atn_74689_spotted-seal_trajectory_20070507-20070901.nc\n",
            "  Downloading file: atn_74690_ribbon-seal_trajectory_20070505-20070521.nc\n",
            "  Downloading file: atn_74693_spotted-seal_trajectory_20070526-20080301.nc\n",
            "  Downloading file: atn_74698_ribbon-seal_trajectory_20070522-20070605.nc\n",
            "  Downloading file: atn_83881_ribbon-seal_trajectory_20080429-20080514.nc\n",
            "  Downloading file: atn_83885_spotted-seal_trajectory_20090606-20100612.nc\n",
            "  Downloading file: atn_83901_spotted-seal_trajectory_20090531-20090707.nc\n",
            "  Downloading file: atn_83902_ribbon-seal_trajectory_20090602-20100101.nc\n",
            "  Downloading file: atn_83905_ribbon-seal_trajectory_20090602-20090607.nc\n",
            "  Downloading file: atn_83908_spotted-seal_trajectory_20090414-20100507.nc\n",
            "  Downloading file: atn_83912_ribbon-seal_trajectory_20090530-20100520.nc\n",
            "  Downloading file: atn_83913_spotted-seal_trajectory_20090606-20090902.nc\n",
            "  Downloading file: atn_83916_spotted-seal_trajectory_20090529-20090707.nc\n",
            "  Downloading file: atn_83918_ribbon-seal_trajectory_20090606-20100308.nc\n",
            "  Downloading file: atn_83922_spotted-seal_trajectory_20090414-20120528.nc\n",
            "  Downloading file: atn_83923_ribbon-seal_trajectory_20090604-20090609.nc\n",
            "  Downloading file: atn_83926_spotted-seal_trajectory_20090414-20100512.nc\n",
            "  Downloading file: atn_85853_ribbon-seal_trajectory_20090605-20100318.nc\n",
            "  Downloading file: atn_85854_ribbon-seal_trajectory_20090607-20090926.nc\n",
            "  Downloading file: atn_85855_spotted-seal_trajectory_20100508-20101031.nc\n",
            "  Downloading file: atn_85857_spotted-seal_trajectory_20090607-20100130.nc\n",
            "  Downloading file: atn_85858_spotted-seal_trajectory_20100505-20110214.nc\n",
            "  Downloading file: atn_85859_spotted-seal_trajectory_20090531-20100201.nc\n",
            "  Downloading file: atn_85860_ribbon-seal_trajectory_20090604-20090801.nc\n",
            "  Downloading file: atn_85861_ribbon-seal_trajectory_20090602-20090925.nc\n",
            "  Downloading file: atn_85862_spotted-seal_trajectory_20090519-20090810.nc\n",
            "  Downloading file: atn_85863_ribbon-seal_trajectory_20090602-20100127.nc\n",
            "  Downloading file: atn_85864_spotted-seal_trajectory_20090519-20091216.nc\n",
            "  Downloading file: atn_85865_ribbon-seal_trajectory_20100517-20110204.nc\n",
            "  Downloading file: atn_85866_spotted-seal_trajectory_20090529-20090704.nc\n",
            "  Downloading file: atn_85867_spotted-seal_trajectory_20090609-20090929.nc\n",
            "  Downloading file: atn_85868_ribbon-seal_trajectory_20090603-20100223.nc\n",
            "  Downloading file: atn_85869_spotted-seal_trajectory_20100506-20110108.nc\n",
            "  Downloading file: atn_85870_ribbon-seal_trajectory_20090609-20091228.nc\n",
            "  Downloading file: atn_85871_spotted-seal_trajectory_20090523-20100228.nc\n",
            "  Downloading file: atn_85872_ribbon-seal_trajectory_20090607-20091204.nc\n",
            "  Downloading file: atn_85873_ribbon-seal_trajectory_20100503-20100601.nc\n",
            "  Downloading file: atn_85874_ribbon-seal_trajectory_20090602-20090812.nc\n",
            "  Downloading file: atn_85875_spotted-seal_trajectory_20090531-20090921.nc\n",
            "  Downloading file: atn_85876_ribbon-seal_trajectory_20090527-20100325.nc\n",
            "  Downloading file: atn_85877_spotted-seal_trajectory_20100506-20100626.nc\n",
            "  Downloading file: atn_85878_spotted-seal_trajectory_20090608-20100320.nc\n",
            "  Downloading file: atn_85879_ribbon-seal_trajectory_20100509-20100630.nc\n",
            "  Downloading file: atn_85880_ribbon-seal_trajectory_20100514-20101224.nc\n",
            "  Downloading file: atn_85881_ribbon-seal_trajectory_20090604-20100330.nc\n",
            "  Downloading file: atn_99277_ribbon-seal_trajectory_20140412-20140503.nc\n",
            "  Downloading file: atn_99279_ribbon-seal_trajectory_20140426-20140513.nc\n",
            "  Downloading file: atn_99280_ribbon-seal_trajectory_20140428-20140506.nc\n",
            "  Downloading file: atn_99282_ribbon-seal_trajectory_20140428-20140514.nc\n",
            "  Downloading file: atn_99283_ribbon-seal_trajectory_20100509-20110518.nc\n",
            "  Downloading file: atn_99288_spotted-seal_trajectory_20100522-20100901.nc\n",
            "  Downloading file: atn_99292_ribbon-seal_trajectory_20100523-20100612.nc\n",
            "  Downloading file: atn_99293_ribbon-seal_trajectory_20100509-20100801.nc\n",
            "  Downloading file: atn_99295_spotted-seal_trajectory_20100523-20110730.nc\n",
            "  Downloading file: atn_99297_ribbon-seal_trajectory_20100515-20100530.nc\n",
            "  Downloading file: atn_99298_ribbon-seal_trajectory_20100517-20120530.nc\n",
            "  Downloading file: atn_99299_ribbon-seal_trajectory_20100505-20100605.nc\n",
            "  Downloading file: atn_99300_ribbon-seal_trajectory_20100517-20110513.nc\n",
            "  Downloading file: atn_99301_ribbon-seal_trajectory_20100523-20110201.nc\n",
            "  Downloading file: atn_99305_spotted-seal_trajectory_20100522-20100730.nc\n",
            "  Downloading file: atn_99306_ribbon-seal_trajectory_20100523-20100530.nc\n",
            "  Downloading file: atn_99308_ribbon-seal_trajectory_20100517-20110607.nc\n",
            "  Downloading file: atn_99309_ribbon-seal_trajectory_20100514-20101215.nc\n",
            "  Downloading file: atn_99312_ribbon-seal_trajectory_20100516-20100718.nc\n",
            "  Downloading file: atn_131373_ribbon-seal_trajectory_20140428-20141213.nc\n",
            "  Downloading file: atn_137487_ribbon-seal_trajectory_20140412-20140413.nc\n",
            "  Downloading file: atn_137490_spotted-seal_trajectory_20160414-20160414.nc\n",
            "  Downloading file: atn_137491_spotted-seal_trajectory_20180418-20180526.nc\n",
            "  Downloading file: atn_137494_ribbon-seal_trajectory_20140426-20140426.nc\n",
            "  Downloading file: atn_137495_ribbon-seal_trajectory_20140426-20140427.nc\n",
            "  Downloading file: atn_137495_spotted-seal_trajectory_20170809-20180607.nc\n",
            "  Downloading file: atn_137497_spotted-seal_trajectory_20160412-20170721.nc\n",
            "  Downloading file: atn_137500_ribbon-seal_trajectory_20140426-20140427.nc\n",
            "  Downloading file: atn_137506_ribbon-seal_trajectory_20140421-20140421.nc\n",
            "  Downloading file: atn_137514_ribbon-seal_trajectory_20140419-20140420.nc\n",
            "  Downloading file: atn_137516_ribbon-seal_trajectory_20140420-20140420.nc\n",
            "  Downloading file: atn_141929_spotted-seal_trajectory_20160425-20160514.nc\n",
            "  Downloading file: atn_143947_spotted-seal_trajectory_20160414-20160623.nc\n",
            "  Downloading file: atn_143956_spotted-seal_trajectory_20180410-20180901.nc\n",
            "  Downloading file: atn_143966_ribbon-seal_trajectory_20160416-20160430.nc\n",
            "  Downloading file: atn_143979_spotted-seal_trajectory_20160414-20160422.nc\n",
            "  Downloading file: atn_143982_ribbon-seal_trajectory_20160423-20160510.nc\n",
            "  Downloading file: atn_143991_spotted-seal_trajectory_20160415-20160509.nc\n",
            "  Downloading file: atn_143994_spotted-seal_trajectory_20160423-20160516.nc\n",
            "  Downloading file: atn_144001_ribbon-seal_trajectory_20160413-20160427.nc\n",
            "  Downloading file: atn_144004_ribbon-seal_trajectory_20160421-20160424.nc\n",
            "  Downloading file: atn_144006_spotted-seal_trajectory_20160412-20160420.nc\n",
            "  Downloading file: atn_144009_spotted-seal_trajectory_20160414-20160510.nc\n",
            "  Downloading file: atn_144015_ribbon-seal_trajectory_20160416-20160418.nc\n",
            "  Downloading file: atn_144017_ribbon-seal_trajectory_20160425-20160512.nc\n",
            "  Downloading file: atn_160948_ribbon-seal_trajectory_20160421-20170519.nc\n",
            "  Downloading file: atn_160951_spotted-seal_trajectory_20160817-20170828.nc\n",
            "  Downloading file: atn_160954_spotted-seal_trajectory_20160814-20161219.nc\n",
            "  Downloading file: atn_160955_ribbon-seal_trajectory_20160413-20170605.nc\n",
            "  Downloading file: atn_160956_spotted-seal_trajectory_20160415-20160622.nc\n",
            "  Downloading file: atn_160957_spotted-seal_trajectory_20170816-20171125.nc\n",
            "  Downloading file: atn_160960_spotted-seal_trajectory_20160817-20170729.nc\n",
            "  Downloading file: atn_160965_ribbon-seal_trajectory_20160416-20160725.nc\n",
            "  Downloading file: atn_160966_spotted-seal_trajectory_20160423-20170120.nc\n",
            "  Downloading file: atn_160968_ribbon-seal_trajectory_20160425-20160726.nc\n",
            "  Downloading file: atn_160969_ribbon-seal_trajectory_20160416-20161230.nc\n",
            "  Downloading file: atn_160972_spotted-seal_trajectory_20170816-20171121.nc\n",
            "  Downloading file: atn_160973_ribbon-seal_trajectory_20160423-20170615.nc\n",
            "  Downloading file: atn_160975_ribbon-seal_trajectory_20160426-20170513.nc\n",
            "  Downloading file: atn_160977_spotted-seal_trajectory_20160425-20161009.nc\n",
            "  Downloading file: atn_164869_spotted-seal_trajectory_20180420-20180514.nc\n",
            "  Downloading file: atn_174785_spotted-seal_trajectory_20180420-20180605.nc\n",
            "  Downloading file: atn_174786_spotted-seal_trajectory_20180414-20180511.nc\n",
            "  Downloading file: atn_174787_spotted-seal_trajectory_20180410-20180610.nc\n",
            "  Downloading file: atn_174790_spotted-seal_trajectory_20180418-20180527.nc\n",
            "  Downloading file: atn_174805_spotted-seal_trajectory_20180420-20180523.nc\n",
            "  Downloading file: atn_174821_spotted-seal_trajectory_20180420-20180618.nc\n",
            "  Downloading file: atn_174822_spotted-seal_trajectory_20180414-20181103.nc\n",
            "\n",
            "Entering directory: https://www.ncei.noaa.gov/data/oceans/ioos/atn/noaa_alaska_fisheries_science_center/\n",
            "Accessing: https://www.ncei.noaa.gov/data/oceans/ioos/atn/noaa_alaska_fisheries_science_center/\n",
            "  Downloading file: atn_38553_bearded-seal_trajectory_20110618-20120314.nc\n",
            "  Downloading file: atn_39489_bearded-seal_trajectory_20110616-20120401.nc\n",
            "  Downloading file: atn_64459_bearded-seal_trajectory_20090626-20120518.nc\n",
            "  Downloading file: atn_64462_bearded-seal_trajectory_20090623-20120612.nc\n",
            "  Downloading file: atn_66971_bearded-seal_trajectory_20110617-20120131.nc\n",
            "  Downloading file: atn_66983_bearded-seal_trajectory_20110618-20140626.nc\n",
            "  Downloading file: atn_67004_bearded-seal_trajectory_20120704-20130618.nc\n",
            "  Downloading file: atn_67007_bearded-seal_trajectory_20110616-20120813.nc\n",
            "  Downloading file: atn_74626_bearded-seal_trajectory_20090625-20100128.nc\n",
            "  Downloading file: atn_74627_bearded-seal_trajectory_20090623-20100318.nc\n",
            "  Downloading file: atn_74630_bearded-seal_trajectory_20090626-20100213.nc\n",
            "  Downloading file: atn_83904_bearded-seal_trajectory_20090625-20120612.nc\n",
            "  Downloading file: atn_99287_bearded-seal_trajectory_20120704-20130312.nc\n",
            "  Downloading file: atn_99310_bearded-seal_trajectory_20110617-20120606.nc\n",
            "\n",
            "--- Recursive Download Finished ---\n"
          ]
        }
      ],
      "source": [
        "# --- Main execution block ---\n",
        "start_url = \"https://www.ncei.noaa.gov/data/oceans/ioos/atn/\"\n",
        "# Create a base directory for all the downloads\n",
        "download_directory = \"data/src/\"\n",
        "\n",
        "print(\"--- Starting Recursive Download ---\")\n",
        "print(f\"Source URL: {start_url}\")\n",
        "print(f\"Local Directory: {download_directory}\\n\")\n",
        "\n",
        "recursive_wget(start_url, download_directory)\n",
        "\n",
        "print(\"\\n--- Recursive Download Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c9G3a6N2bMh2"
      },
      "outputs": [],
      "source": [
        "def create_dwc_occurrence(ds, output_csv):\n",
        "\n",
        "  dwc_df = pd.DataFrame()\n",
        "  dwc_df['occurrenceID'] = \"ioos_atn_\"+ds.ptt_id+\"_\"+ds['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')+\"_\"+ds['z'].astype(str)+\"_\"+ds.animal_common_name.replace(\" \",\"_\")\n",
        "  dwc_df['eventID'] = ds.ptt_id+\"_\"+ds.animal_common_name.replace(\" \",\"_\") +\"_\"+ds['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "  dwc_df['organismID'] = ds.platform_id+\"_\"+ds.animal_common_name.replace(\" \",\"_\")\n",
        "  dwc_df['occurrenceStatus'] = 'present'\n",
        "  dwc_df['basisOfRecord'] = ds['type']\n",
        "  dwc_df['eventDate'] = ds['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "  dwc_df['decimalLatitude'] = ds['lat']\n",
        "  dwc_df['decimalLongitude'] = ds['lon']\n",
        "  dwc_df['geodeticDatum'] = ds.crs.epsg_code\n",
        "  dwc_df['scientificName'] = ds['taxon_name'].values.tolist()\n",
        "  dwc_df['scientificNameID'] = ds['taxon_lsid'].values.tolist()\n",
        "  dwc_df['samplingProtocol'] = 'satellite telemetry'\n",
        "  dwc_df['kingdom'] = ds['animal'].attrs['kingdom']\n",
        "  dwc_df['taxonRank'] = ds['animal'].attrs['rank']\n",
        "  dwc_df['lifeStage'] = ds['animal_life_stage'].values.tolist()\n",
        "  dwc_df['sex'] = ds['animal_sex'].values.tolist()\n",
        "  dwc_df['associatedReferences'] = \"https://doi.org/10.25921/wp4e-ph20\"\n",
        "  dwc_df['minimumDepthInMeters'] = ds['z'].values.tolist()\n",
        "  dwc_df['maximumDepthInMeters'] = ds['z'].values.tolist()\n",
        "\n",
        "  # set basisOfRecord\n",
        "  dwc_df.loc[dwc_df['basisOfRecord'] == 'User','basisOfRecord'] = 'HumanObservation'\n",
        "  dwc_df.loc[dwc_df['basisOfRecord'] == 'Argos','basisOfRecord'] = 'MachineObservation'\n",
        "\n",
        "  # filter to respectable locations\n",
        "  dwc_df['location_class'] = ds['location_class'].to_series()\n",
        "\n",
        "  dwc_df.drop(dwc_df.loc[\n",
        "      (dwc_df['location_class'] == 'A') |\n",
        "      (dwc_df['location_class'] == 'B') |\n",
        "      (dwc_df['location_class'] == 'Z')].index, inplace=True)\n",
        "\n",
        "  # test using xarray\n",
        "  # ds['time'].where((ds['location_class'] != 'A') &\n",
        "  #     (ds['location_class'] != 'B') &\n",
        "  #     (ds['location_class'] != 'Z'),drop=True).values\n",
        "\n",
        "  print(f\"  Extracted {len(dwc_df)} occurrences with valid locations.\")\n",
        "\n",
        "  # assign value to codes\n",
        "  dwc_df.loc[dwc_df['location_class'] == 'nan','location_class'] = 0\n",
        "  dwc_df.loc[dwc_df['location_class'] == 'G','location_class'] = 200\n",
        "  dwc_df.loc[dwc_df['location_class'] == '3','location_class'] = 250\n",
        "  dwc_df.loc[dwc_df['location_class'] == '2','location_class'] = 500\n",
        "  dwc_df.loc[dwc_df['location_class'] == '1','location_class'] = 1500\n",
        "  dwc_df.loc[dwc_df['location_class'] == '0','location_class'] = 10000\n",
        "\n",
        "  # --- Define Occurrences: First detection per location per hour ---\n",
        "  dwc_df['event_hour'] = pd.to_datetime(dwc_df['eventDate']).dt.strftime('%Y-%m-%dT%H')\n",
        "  dwc_df.sort_values('event_hour', inplace=True)\n",
        "  duplicate_counts = dwc_df.groupby(by='event_hour').transform('size')\n",
        "  dwc_df['dataGeneralizations'] = f'first of ' + duplicate_counts.astype(str) + ' records.'\n",
        "  dwc_df.loc[dwc_df['dataGeneralizations']=='first of 1 records.','dataGeneralizations'] = ''\n",
        "  dwc_df = dwc_df.drop_duplicates(subset=['event_hour'], keep='first').copy()\n",
        "\n",
        "  print(f\"  Extracted {len(dwc_df)} occurrences to first row in hour.\")\n",
        "\n",
        "  # --- Rename a and drop few columns --\n",
        "  dwc_df.rename(columns={'location_class': 'coordinateUncertaintyInMeters',\n",
        "                          },\n",
        "                inplace=True)\n",
        "\n",
        "  dwc_df.drop(columns=['event_hour'], inplace=True)\n",
        "\n",
        "  # only pick specific columns to save\n",
        "  cols = ['occurrenceID', 'occurrenceStatus', 'basisOfRecord',\n",
        "          'organismID', 'eventDate', 'decimalLatitude',\n",
        "          'decimalLongitude', 'geodeticDatum',\n",
        "          'scientificName', 'scientificNameID', 'eventID',\n",
        "          'samplingProtocol', 'kingdom', 'taxonRank', 'lifeStage',\n",
        "          'sex', 'associatedReferences',\n",
        "          'coordinateUncertaintyInMeters', 'dataGeneralizations']\n",
        "  \n",
        "  # Save the individual CSV\n",
        "  dwc_df.to_csv(output_csv, columns=cols, index=False)\n",
        "  print(f\"  Saved data to '{output_csv}'\")\n",
        "\n",
        "  return dwc_df\n",
        "\n",
        "\n",
        "def create_dwc_event(dwc_df, output_csv):\n",
        "\n",
        "  # --- Processing for Event ---\n",
        "  event_df = dwc_df.loc[dwc_df['basisOfRecord']=='HumanObservation',\n",
        "  ['eventID','eventDate','decimalLatitude','decimalLongitude','geodeticDatum',\n",
        "    'minimumDepthInMeters','maximumDepthInMeters']]\n",
        "  \n",
        "  if event_df.empty:\n",
        "      print(\"No HumanObservations found in the dataset.\")\n",
        "      return pd.DataFrame()  # Return an empty DataFrame if no observations are found\n",
        "  else:  \n",
        "    print(f\"  found {len(event_df)} HumanObservations.\")\n",
        "    event_df['countryCode'] = 'US'\n",
        "    event_df['samplingProtocol'] = 'satellite telemetry'\n",
        "    \n",
        "    # # initialize Nominatim API - not trusted enough yet\n",
        "    # # see https://nominatim.org/release-docs/develop/api/Reverse/\n",
        "    # geolocator = Nominatim(user_agent=\"my_geopy_app\")\n",
        "\n",
        "    # lat = event_df['decimalLatitude'][0].astype(str)\n",
        "    # lon = event_df['decimalLongitude'][0].astype(str)\n",
        "\n",
        "    # location = geolocator.reverse(lat+\",\"+lon)\n",
        "\n",
        "    # event_df['countryCode'] = location.raw['address'].get('country_code').upper()\n",
        "    event_df.to_csv(output_csv.replace(\"occurrence\",\"event\"), index=False)\n",
        "    print(f\"  Created {len(event_df)} events.\")\n",
        "    print(f\"  Saved data to {output_csv.replace('occurrence','event')}\")\n",
        "\n",
        "    return event_df\n",
        "\n",
        "\n",
        "def create_dwc_emof(ds, dwc_df, output_csv):\n",
        "  \n",
        "  # --- Processing for emof ---\n",
        "  vars = list(ds.keys())\n",
        "  animal_vars = [x for x in vars if re.match(r'animal_(?!life_stage\\b|sex\\b).*',x)]\n",
        "  new_rows = pd.DataFrame()\n",
        "\n",
        "  for animal_var in animal_vars:\n",
        "    row = pd.DataFrame({\n",
        "        'measurementValue': ds[animal_var].values.tolist(),\n",
        "        'measurementType': [f'{animal_var}: {ds[animal_var].long_name}'],\n",
        "        'measurementMethod': ds[animal_var].attrs[animal_var],\n",
        "        'measurementUnit': [ds[animal_var].units if 'units' in ds[animal_var].attrs else ''],\n",
        "    })\n",
        "    new_rows = pd.concat([new_rows,\n",
        "                          row])\n",
        "\n",
        "  emof_df = dwc_df.loc[dwc_df['basisOfRecord']=='HumanObservation',\n",
        "                      ['organismID','occurrenceID','eventID']\n",
        "                      ].merge(\n",
        "                          new_rows,\n",
        "                          left_index=True,\n",
        "                          right_index=True)\n",
        "\n",
        "  emof_df.dropna(axis=0, subset=['measurementValue'], inplace=True)\n",
        "\n",
        "  if emof_df.empty:\n",
        "    print(f'  no emof data found')\n",
        "    return pd.DataFrame()  # Return an empty DataFrame if no observations are found\n",
        "  else:\n",
        "    emof_df.to_csv(output_csv.replace(\"occurrence\",\"emof\"), index=False)\n",
        "    print(f\"  Created {len(emof_df)} emofs.\")\n",
        "    print(f\"  Saved data to {output_csv.replace('occurrence','emof')}\")\n",
        "    return emof_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EML generation\n",
        "\n",
        "# borrowed from https://gitlab.oceantrack.org/otn-partner-nodes/ipython-utilities/-/blob/main/dbtools/publish_to_obis.py?ref_type=heads\n",
        "\n",
        "\n",
        "\n",
        "def save_eml_file(eml_metadata:dict) -> str:\n",
        "    \"\"\"\n",
        "    Save EML dictionary in a file\n",
        "    Author: Jon Pye, Angela Dini\n",
        "    Maintainer: Angela Dini\n",
        "    :param eml_metadata: dictionary of EML metadata\n",
        "    :return: filepath of where the EML filepath will be\n",
        "    \"\"\"\n",
        "    # Write it out to the package\n",
        "    template_file = codecs.open('templates/eml.xml.j2', 'r', 'UTF-8').read()\n",
        "    template = Template(template_file)\n",
        "    result_string = template.render(eml_metadata)\n",
        "    eml_file = 'data/dwc/{ptt_id}/eml.xml'.format(**eml_metadata)\n",
        "    fh = codecs.open(eml_file, 'wb+', 'UTF-8')\n",
        "    fh.write(result_string)\n",
        "    fh.close()\n",
        "    eml_full_path = os.path.abspath(eml_file)\n",
        "    print(f\"  EML metadata has been written to '{eml_full_path}'.\")\n",
        "    return eml_full_path\n",
        "\n",
        "def create_eml(ds):\n",
        "    eml_metadata = ds.attrs\n",
        "\n",
        "    contributors = dict()\n",
        "    for attr in [x for x in ds.attrs if re.match(r'contributor_(?!role_vocabulary\\b).*',x)]:\n",
        "        contributors[attr] = ds.attrs[attr].split(\",\")\n",
        "\n",
        "    contributors_list = [\n",
        "        {key: contributors[key][i] for key in contributors}\n",
        "        for i in range(len(next(iter(contributors.values()))))\n",
        "    ]\n",
        "\n",
        "    other_meta = {\n",
        "        'dataset_ipt_id': None,\n",
        "        'dataset_short_name': ds.encoding.get('source').split(\"\\\\\")[-1].replace(\".nc\",\"\"),\n",
        "        'data_manager_firstname': 'Megan',\n",
        "        'data_manager_lastname': 'McKinzie',\n",
        "        'data_manager_title': 'Data Manager',\n",
        "        'data_manager_phone': '',\n",
        "        'data_manager_email': 'mmckinzie@mbari.org',\n",
        "        'contributors': contributors_list,\n",
        "    }\n",
        "\n",
        "    eml_metadata.update(other_meta)\n",
        "\n",
        "    save_eml_file(eml_metadata)\n",
        "    \n",
        "    return eml_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_meta_xml(dwc_df, emof_df, event_df, output_csv):\n",
        "    \"\"\"\n",
        "    Create meta.xml file for the Darwin Core dataset.\n",
        "    \n",
        "    Args:\n",
        "        dwc_df (DataFrame): DataFrame containing Darwin Core occurrence data.\n",
        "        emof_df (DataFrame): DataFrame containing eMoF data.\n",
        "        event_df (DataFrame): DataFrame containing event data.\n",
        "        output_csv (str): Path to the output CSV file.\n",
        "        dir (str): Directory where the meta.xml will be saved.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    try:\n",
        "        os.path.exists(output_csv)\n",
        "    except:\n",
        "        print(f\"Missing directory: {output_csv}\")\n",
        "\n",
        "    # create and include the meta.xml and eml.xml\n",
        "    # set the meta.xml paramaters by hand, using the format of the dataframes above\n",
        "    meta_xml_vars = {}\n",
        "\n",
        "    # when writing dwc occurrence file, we only save some columns\n",
        "    dwc_df = dwc_df[['occurrenceID', 'occurrenceStatus', 'basisOfRecord',\n",
        "          'organismID', 'eventDate', 'decimalLatitude',\n",
        "          'decimalLongitude', 'geodeticDatum',\n",
        "          'scientificName', 'scientificNameID', 'eventID',\n",
        "          'samplingProtocol', 'kingdom', 'taxonRank', 'lifeStage',\n",
        "          'sex', 'associatedReferences',\n",
        "          'coordinateUncertaintyInMeters', 'dataGeneralizations']].copy()\n",
        "    \n",
        "    meta_xml_vars['cols_list'] = dwc_df.columns.tolist()\n",
        "    meta_xml_vars['occurrence_filename'] = output_csv\n",
        "\n",
        "    if not emof_df.empty:\n",
        "        meta_xml_vars ['emof_cols_list'] = emof_df.columns.tolist()\n",
        "        meta_xml_vars['emof_filename'] = output_csv.replace(\"occurrence\",\"emof\")\n",
        "\n",
        "    if not event_df.empty:\n",
        "        meta_xml_vars['event_cols_list'] = event_df.columns.tolist()\n",
        "        meta_xml_vars['event_filename'] = output_csv.replace(\"occurrence\",\"event\")\n",
        "\n",
        "    # grab the template file for making meta.xml\n",
        "    meta_template_file = codecs.open('templates/meta.xml.j2', 'r', 'UTF-8').read()\n",
        "    meta_template = Template(meta_template_file)\n",
        "    meta_result_string = meta_template.render(meta_xml_vars)\n",
        "    dir = os.path.join(*output_csv.split(\"\\\\\")[:-1])\n",
        "    meta_file = f'{dir}/meta.xml'\n",
        "\n",
        "    fh = codecs.open(meta_file, 'wb+', 'UTF-8')\n",
        "    fh.write(meta_result_string)\n",
        "    fh.close()\n",
        "    meta_full_path = os.path.abspath(meta_file)\n",
        "    print(f\"  Meta XML has been written to '{meta_full_path}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aD62GgzSS0zu"
      },
      "outputs": [],
      "source": [
        "def convert_to_dwc_individual(file_paths, output_dir=\"data/dwc\"):\n",
        "    \"\"\"\n",
        "    Converts a list of NetCDF files to individual Darwin Core Occurrence CSVs.\n",
        "\n",
        "    An \"occurrence\" is the first detection of an animal at a specific\n",
        "    location within a given hour.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): A list of paths to the .nc files.\n",
        "        output_dir (str): The directory to save the individual CSV files.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- 2. Starting Darwin Core Conversion (Individual Files) ---\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        print(f\"Created output directory: {output_dir}\")\n",
        "\n",
        "    processed_count = 0\n",
        "\n",
        "    for nc_file in file_paths:\n",
        "\n",
        "        base_filename = os.path.basename(nc_file)\n",
        "\n",
        "        if not os.path.exists(f\"{output_dir}/{base_filename.split('_')[1]}\"):\n",
        "          os.makedirs(f\"{output_dir}/{base_filename.split('_')[1]}\")\n",
        "          print(f\"Created output directory: {output_dir}/{base_filename.split('_')[1]}\")\n",
        "\n",
        "        output_csv = os.path.join(output_dir, f\"{base_filename.split('_')[1]}/{os.path.splitext(base_filename)[0]}_occurrence.csv\")\n",
        "        output_csv = os.path.normpath(output_csv)\n",
        "        #output_dir = os.path.join(*output_csv.split(\"\\\\\")[:-1])\n",
        "        print(f\"Processing {base_filename}...\")\n",
        "\n",
        "        try:\n",
        "            with xr.open_dataset(nc_file, engine='netcdf4') as ds:\n",
        "                df = ds.to_dataframe().reset_index()\n",
        "\n",
        "                print(f\"Found {len(df)} records.\")\n",
        "\n",
        "                # --- Data Cleaning and Preparation ---\n",
        "                if 'lat' not in df.columns or 'lon' not in df.columns:\n",
        "                    print(f\"  Skipping {base_filename}: missing location data.\")\n",
        "                    continue\n",
        "\n",
        "                df.dropna(subset=['lat', 'lon', 'time'], inplace=True)\n",
        "                if df.empty:\n",
        "                    print(f\"  Skipping {base_filename}: no valid records.\")\n",
        "                    continue\n",
        "\n",
        "                # --- Map to Darwin Core Occurrence Terms ---\n",
        "                dwc_df = create_dwc_occurrence(ds, output_csv)\n",
        "\n",
        "                # Create and save eml\n",
        "                create_eml(ds)\n",
        "\n",
        "                # --- Event and eMoF (as needed) ---\n",
        "                event_df = create_dwc_event(dwc_df, output_csv)\n",
        "                emof_df = create_dwc_emof(ds, dwc_df, output_csv)\n",
        "\n",
        "                # --- Create meta.xml file ---\n",
        "                create_meta_xml(dwc_df, emof_df, event_df, output_csv)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Could not process {base_filename}: {e}\")\n",
        "\n",
        "    print(f\"\\n--- 3. Conversion Complete ---\")\n",
        "    print(f\"✅ Success! Processed {processed_count} files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHCDd3D4dSFv"
      },
      "source": [
        "Convert data to DarwinCore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VByr8WDedRja",
        "outputId": "d210d9a1-2f5e-4059-89e7-c5fa080226f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 2. Starting Darwin Core Conversion (Individual Files) ---\n",
            "Processing atn_137491_spotted-seal_trajectory_20180418-20180526.nc...\n",
            "Found 107 records.\n",
            "  Extracted 12 occurrences with valid locations.\n",
            "  Extracted 5 occurrences to first row in hour.\n",
            "  Saved data to 'data\\dwc\\137491\\atn_137491_spotted-seal_trajectory_20180418-20180526_occurrence.csv'\n",
            "  EML metadata has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\137491\\eml.xml'.\n",
            "  found 1 HumanObservations.\n",
            "  Created 1 events.\n",
            "  Saved data to data\\dwc\\137491\\atn_137491_spotted-seal_trajectory_20180418-20180526_event.csv\n",
            "  Created 2 emofs.\n",
            "  Saved data to data\\dwc\\137491\\atn_137491_spotted-seal_trajectory_20180418-20180526_emof.csv\n",
            "  Meta XML has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\137491\\meta.xml'.\n",
            "Processing atn_137494_ribbon-seal_trajectory_20140426-20140426.nc...\n",
            "Found 23 records.\n",
            "  Extracted 11 occurrences with valid locations.\n",
            "  Extracted 4 occurrences to first row in hour.\n",
            "  Saved data to 'data\\dwc\\137494\\atn_137494_ribbon-seal_trajectory_20140426-20140426_occurrence.csv'\n",
            "  EML metadata has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\137494\\eml.xml'.\n",
            "No HumanObservations found in the dataset.\n",
            "  no emof data found\n",
            "  Meta XML has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\137494\\meta.xml'.\n",
            "Processing atn_38553_bearded-seal_trajectory_20110618-20120314.nc...\n",
            "Found 10197 records.\n",
            "  Extracted 1871 occurrences with valid locations.\n",
            "  Extracted 1218 occurrences to first row in hour.\n",
            "  Saved data to 'data\\dwc\\38553\\atn_38553_bearded-seal_trajectory_20110618-20120314_occurrence.csv'\n",
            "  EML metadata has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\38553\\eml.xml'.\n",
            "  found 1 HumanObservations.\n",
            "  Created 1 events.\n",
            "  Saved data to data\\dwc\\38553\\atn_38553_bearded-seal_trajectory_20110618-20120314_event.csv\n",
            "  no emof data found\n",
            "  Meta XML has been written to 'c:\\Users\\Mathew.Biddle\\Documents\\GitProjects\\bio_data_guide\\datasets\\atn_satellite_telemetry\\data\\dwc\\38553\\meta.xml'.\n",
            "\n",
            "--- 3. Conversion Complete ---\n",
            "✅ Success! Processed 3 files.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# Step 1: Download all .nc files from the URL\n",
        "#local_files = glob.glob('data\\\\src\\\\*.nc')#[:10]\n",
        "\n",
        "local_files = ['data\\\\src\\\\atn_137491_spotted-seal_trajectory_20180418-20180526.nc',\n",
        "               'data\\\\src\\\\atn_137494_ribbon-seal_trajectory_20140426-20140426.nc',\n",
        "               'data\\\\src\\\\atn_38553_bearded-seal_trajectory_20110618-20120314.nc'\n",
        "             ]\n",
        "# Step 2: Convert the downloaded files to individual Darwin Core CSVs\n",
        "if local_files:\n",
        "    convert_to_dwc_individual(local_files)\n",
        "else:\n",
        "    print(\"No files were downloaded, so conversion cannot proceed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTB7xe4ESri4"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLbEYyfXeF_U",
        "outputId": "e442e372-c592-4957-8b9e-2f9b28fba37d"
      },
      "outputs": [],
      "source": [
        "# import xarray as xr\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# ds = xr.open_dataset('data/src/atn_74626_bearded-seal_trajectory_20090625-20100128.nc', engine='netcdf4')\n",
        "# #ds = xr.open_dataset('data/src/atn_174787_spotted-seal_trajectory_20180410-20180610.nc', engine='netcdf4')\n",
        "\n",
        "# dwc_df = create_dwc_occurrence(ds)\n",
        "\n",
        "# event_df = create_dwc_event(dwc_df)\n",
        "\n",
        "# emof_df = create_dwc_emof(ds, dwc_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert_to_dwc_individual(['data/src/atn_137491_spotted-seal_trajectory_20180418-20180526.nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IOOS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
